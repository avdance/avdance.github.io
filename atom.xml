<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>音视跳动科技</title>
  
  <subtitle>传播最前沿的科技知识！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://blog.avdancedu.com/"/>
  <updated>2022-12-03T01:33:10.559Z</updated>
  <id>https://blog.avdancedu.com/</id>
  
  <author>
    <name>音视跳动</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Windows下编译FFmpeg5.0</title>
    <link href="https://blog.avdancedu.com/38b88453/"/>
    <id>https://blog.avdancedu.com/38b88453/</id>
    <published>2022-11-29T22:41:00.000Z</published>
    <updated>2022-12-03T01:33:10.559Z</updated>
    
    <content type="html"><![CDATA[<p><img data-src="https://cdn.avdancedu.com/image/article/windows_ffmpeg/FFmpeg_logo.jpeg" alt=""></p><p>在我的FFmpeg课程中，我总是推荐大家使用 <strong>Linux(Ubuntu)系统</strong> 或 <strong>Mac系统</strong> 来学习FFmpeg。其原因，是在Windows下编译FFmpeg太麻烦了，这大大增加了我们学习FFmpeg的成本。</p><p>不光如此，在Windows下编译FFmpeg所需要的依赖库也很麻烦，比如我们经常使用的fdk-aac、x264等在Windows下都要单独编译才可以使用。</p><p>不过，总还是有一些同学需要在Windows下使用FFmpeg，而FFmpeg官网上介绍的Windows下编译FFmpeg的<a href="https://visualstudio.microsoft.com/zh-hans/thank-you-downloading-visual-studio/?sku=Community&channel=Release&version=VS2022&source=VSLandingPage&cid=2030&passive=false" target="_blank" rel="noopener">文章</a>实在是太老了，基本不可用。为了解决这部分同学的难题，这里我总结了一份Windows下编译和使用FFmpeg的方法，希望能帮助到大家！</p><a id="more"></a><h2 id="准备编译环境"><a href="#准备编译环境" class="headerlink" title="准备编译环境"></a>准备编译环境</h2><p>首先，我们要准备好编译环境，一台装有Windows10系统的电脑是必须的（没有比这再正确的废话了：））。</p><p>同时，要将Visual Studio安装好，比如 VS2019 社区版或 VS2022社区版（VS2019可以到<a href="https://visualstudio.microsoft.com/zh-hans/thank-you-downloading-visual-studio/?sku=Community&channel=Release&version=VS2022&source=VSLandingPage&cid=2030&passive=false" target="_blank" rel="noopener">这里下载</a>，VS2022可以到<a href="https://visualstudio.microsoft.com/zh-hans/thank-you-downloading-visual-studio/?sku=Community&channel=Release&version=VS2022&source=VSLandingPage&cid=2030&passive=false" target="_blank" rel="noopener">这里下载</a>）。这两个版本你用哪个都行，根据自己的需要选择吧。如果不是工作中必须要使用VS2019，那我建议你使用最新版的VS2022。</p><p>除了需要安装VS之外，还要安装<strong>MSYS2</strong>，这是一款Windows下模拟Linux的软件。FFmpeg的编译就是在该软件中进行的，而编译时使用的<strong>编译器</strong>(cl.exe)和<strong>链接器</strong>(link.exe)则是由Visual Studio提供的。MSYS2可以到<a href="https://github.com/msys2/msys2-installer/releases/download/2022-10-28/msys2-x86_64-20221028.exe" target="_blank" rel="noopener">这里下载</a></p><p>需要注意的是，在下载MSYS2时可能需要有网络代理才行。考虑到有些同学没有网络代理软件，我将MSYS2的一个备份放到了百度盘上，你也可以到<a href="https://pan.baidu.com/s/1xOpcbJV1mKMCCaNgMBO90g?pwd=8888" target="_blank" rel="noopener">这里下载</a>。不过当你去百度盘下载这个软件时，它的版本可能已经比较老了，建议有条件的同学还是到官网上下载。</p><blockquote><p>顺便说一下，对于刚学习Linux的同学来说，在Windows上装MSYS2学习Linux是个不错的选择，它比PowerShell要好用得多</p></blockquote><h2 id="下载源码"><a href="#下载源码" class="headerlink" title="下载源码"></a>下载源码</h2><p>编译环境准备好之后，接下来我们需要下载一份最新的FFmpeg源码，你可以从<a href="https://ffmpeg.org/releases/ffmpeg-snapshot.tar.bz2" target="_blank" rel="noopener">这里下载</a>，也可以使用Git下载。Git下载的方法如下：</p><ul><li>先将Git命令安装好</li><li>然后执行下面的命令<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /d</span><br><span class="line">git <span class="built_in">clone</span> https://git.ffmpeg.org/ffmpeg.git ffmpeg</span><br></pre></td></tr></table></figure>此时，代码就被下载到<code>D:</code>盘的ffmpeg目录下了</li></ul><h2 id="Windows下编译FFmpeg的方法"><a href="#Windows下编译FFmpeg的方法" class="headerlink" title="Windows下编译FFmpeg的方法"></a>Windows下编译FFmpeg的方法</h2><p>当 FFmpeg 源码准备就绪后，我们就可以编译FFmpeg了。</p><p>首先，进入MSYS2的安装目录，比如我这里将MSYS2安装到了<code>D:\MSYS64</code>目录下。在该目录下打开 <strong>msys2_shell.cmd</strong> 文件，将该文件第 <strong>17</strong> 行代码的注释打开，即去掉 <strong>rem</strong> 关键字，如下所示：</p><figure class="highlight bat"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="built_in">setlocal</span> EnableDelayedExpansion</span><br><span class="line"></span><br><span class="line"><span class="built_in">set</span> "WD=<span class="variable">%__CD__%</span>"</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">NOT</span> <span class="keyword">EXIST</span> "<span class="variable">%WD%</span>msys-<span class="number">2</span>.<span class="number">0</span>.dll" <span class="built_in">set</span> "WD=%~dp0usr\bin\"</span><br><span class="line"><span class="built_in">set</span> "LOGINSHELL=bash"</span><br><span class="line"><span class="built_in">set</span> /a msys2_shiftCounter=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment">rem To activate windows native symlinks uncomment next line</span></span><br><span class="line"><span class="comment">rem set MSYS=winsymlinks:nativestrict</span></span><br><span class="line"></span><br><span class="line"><span class="comment">rem Set debugging program for errors</span></span><br><span class="line"><span class="comment">rem set MSYS=error_start:%WD%../../mingw64/bin/qtcreator.exe^|-debug^|^&lt;process-id^&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">rem To export full current PATH from environment into MSYS2 use '-use-full-path' parameter</span></span><br><span class="line"><span class="comment">rem or uncomment next line</span></span><br><span class="line"><span class="built_in">set</span> MSYS2_PATH_TYPE=inherit</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>之所以要打开该注释，是为了让MSYS2可以继承Windows控制台的环境变量。</p><p>之后，通过面的方法找到<code>x64 Native Tools Command Prompt for VS 2019</code>命令窗口:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Windows开始菜单 -&gt; Visual Studio 2022 -&gt; x64 Native Tools Command Prompt <span class="keyword">for</span> VS 2019</span><br></pre></td></tr></table></figure><p>在该命令窗口中输入下面的命令启动 MSYS2 软件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入到MSYS2 目录下</span></span><br><span class="line"><span class="built_in">cd</span> D:\MSYS64</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动MSYS2</span></span><br><span class="line">msys2_shell.cmd</span><br></pre></td></tr></table></figure><p>此时，会弹出MSYS2的命令窗口。接下来，在该窗口中输入下面命令，安装必要的编译工具：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pacman -S diffutils make pkg-config yasm</span><br></pre></td></tr></table></figure><p>其中 <strong>pacman</strong> 是MSYS2的 <strong>包安装工具</strong>；而 diffutils、make……都是编译FFmpeg时需要用的 <strong>编译工具</strong>。</p><p>当编译工具安装好后，曳光弹在MSYS2命令窗中执行下面命令，进入到FFmpeg源码目录下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /d/ffmpeg</span><br></pre></td></tr></table></figure><p>紧接着，运行 FFmpeg 源码目录中的 <code>configure</code> 脚本生成 <strong>Makefile</strong> 文件，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>/ffmpeg--<span class="built_in">enable</span>-gpl --<span class="built_in">enable</span>-nonfree --<span class="built_in">enable</span>-shared --<span class="built_in">disable</span>-ffprobe --toolchain=msvc</span><br></pre></td></tr></table></figure><p>上述命令的含义是使用mscv作为FFmpeg的编译工具链；编译出的FFmpeg库被放到<code>/usr/local/ffmpeg</code> 目录下；编译的库是动态库，在Windows下就是 <strong>DLL</strong> 库；编译时不生成 <strong>ffprobe</strong> 程序。</p><p>上述脚本执行完成后，你可以在 FFmpeg 源码目录下发现多了一个 Makefile 文件。有了这个文件我们就可以编译FFmpeg了，编译命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make -j 4 &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>当执行完这条命令后，在 <code>/usr/local/ffmpeg/bin</code> 目录下就可以找到编译好的FFmpeg库和FFmpeg命令了。</p><p>需要注意的是，編译时有你有可能会遇到到如下错误：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">...... error C2065: “slib”: 未声明的标识符</span><br><span class="line">...... error C2296: “%”: 非法，左操作数包含“char [138]”类型</span><br></pre></td></tr></table></figure><p>该问题是因为在Windows下无法识别 <strong>CC_IDENT</strong> 导致的，只需将包括 <strong>CC_IDENT</strong>关键字的那行代码注释掉即可。</p><h2 id="在Windows上找到编译好的FFmpeg库"><a href="#在Windows上找到编译好的FFmpeg库" class="headerlink" title="在Windows上找到编译好的FFmpeg库"></a>在Windows上找到编译好的FFmpeg库</h2><p>上面我将编译好的FFmpeg库安装到了<code>/usr/local/ffmpeg</code>目录下，但在Windows下如何找到这个目录呢？</p><p>其实非常简单，你只需确定好MSYS2的根目录是哪儿就可以找到编译好的FFmpeg库了。以我的环境为例，我将MSYS2安装到了<code>D:\MSYS64</code>这个目录下，那么<code>D:\MSYS64</code>这个目录就是MSYS2的根目录。</p><p>因此，我编译好的FFmpeg库就存放在<code>D:\MSYS64\usr\local\ffmpeg</code>目录下。</p><h2 id="VS项目中引用FFmpeg库"><a href="#VS项目中引用FFmpeg库" class="headerlink" title="VS项目中引用FFmpeg库"></a>VS项目中引用FFmpeg库</h2><p>编译好FFmpeg库后，下面我们就可以在VS中引用它了。</p><p>首先你要创建一个新的VS项目，具体方法如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">打开VS -&gt; 创建新项目 -&gt; 创建控制台项目 -&gt; 填写项目名</span><br></pre></td></tr></table></figure><p>项目创建好后你会发现它里边只有一个<code>testffmpeg.cpp</code>文件，该文件特别简单，只有一个<code>main(...)</code>函数和一条<code>cout &lt;&lt; ...</code>语句。现在我们就可以在这个<code>main(...)</code>函数中调用<strong>FFmpeg API</strong> 了。</p><p>但在开始编码之前，我们需要将用到的FFmpeg库和头文件引入到VS工程中，这样后面VS才能正确的将程序编译出来。下面咱们来看看该如何在VS中引入FFmpeg库头文件、库文件：</p><ul><li><p>引入FFmpeg头文件</p><p>在</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">项目右键 -&gt; 属性 -&gt; C/C++ -&gt; 常规 -&gt; 附加包含目录</span><br></pre></td></tr></table></figure><p>中添加FFmpeg头文件所在路径。</p></li><li><p>指定库文件位置</p><p>在</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">项目右键 -&gt; 属性 -&gt; 链接器 -&gt; 常规 -&gt; 附加库目录</span><br></pre></td></tr></table></figure><p>中添加FFmpeg库所在路径。</p></li><li><p>指定使用哪个库<br>在</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">项目右键 -&gt; 属性 -&gt; 链接器 -&gt; 输入 -&gt; 附加依赖项</span><br></pre></td></tr></table></figure><p>中指定你所用到的FFmpeg库，如avutil.lib</p></li></ul><p>当上面这此工作完成后，我们就可以在<code>main(...)</code>函数中调用FFmpeg API了，如调用FFmpeg库中的日志函数：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="keyword">extern</span> <span class="string">"C"</span> </span><br><span class="line">&#123;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;libavtuil/log.h&gt;</span></span></span><br><span class="line">&#125;</span><br><span class="line">...</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(...)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    av_log_set_level(AV_LOG_DEBUG);</span><br><span class="line">    av_log(<span class="literal">NULL</span>, AV_LOG_INFO, <span class="string">"Hello World!\n);</span></span><br><span class="line"><span class="string">    ...</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><p>上述代码中，调用了FFmpeg中的两个API，分别是 <code>av_log_set_level(...)</code>以及<code>av_log(...)</code>，这两个函数都是FFmpeg avutil库中的API。所以在使用这两个API之前，我们要在main.c中需要通过<code>#include</code>关键字将 <strong>libavtuil/log.h</strong> 这个头文件引入进来。</p><p>此外，由于FFmpeg是C语言库，而我们用VS创建的是C++工程，所以在引入头文件时需要加上<code>extern &quot;C&quot;</code>关键字，否则的话VS无法将其成功编译。</p><h2 id="运行编译好的程序"><a href="#运行编译好的程序" class="headerlink" title="运行编译好的程序"></a>运行编译好的程序</h2><p>上面当我们运行编译好的程序时你会发现，它弹出了报错窗口，显示 <strong>“无法找到xxx.dll库”</strong> 的出错信息，其原因是在运行时无法找到需要的动态库。</p><p>解决办法很简单，只需将我们之前编译好的FFmpeg库，即提示的无法找到的<code>.dll</code>库，拷贝到执行程序的同一目录下，这样执行程序就可以找到该库并正确执行了。</p><h2 id="编译FFmpeg依赖库"><a href="#编译FFmpeg依赖库" class="headerlink" title="编译FFmpeg依赖库"></a>编译FFmpeg依赖库</h2><p>很多时候我们在编译FFmpeg库时还要增加一些其它库，如SDL、x264等，如何能将这些库添加到FFmpeg中呢？</p><p>要想将这些库编译到FFmpeg中，首先我们要编译出Windows下可用的对应库，下面咱们就来看一下如何在Windows系统下将它们编译出来。</p><h3 id="编译SDL"><a href="#编译SDL" class="headerlink" title="编译SDL"></a>编译SDL</h3><p>首先从github上获取SDL源码，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/libsdl-org/SDL.git</span><br><span class="line">git checkout release-2.26.x</span><br></pre></td></tr></table></figure><blockquote><p>需要注意的是，SDL现在已经发布了3.0版本，而ffmpeg目前只能用SDL2版本，所以在拉取代码后，需要切换到2.26这个版本</p></blockquote><p>下载好 SDL2 源码后，我们需要使用 <strong>CMake</strong> 为其生成VS工程，所以我们首先到这里<a href="https://github.com/Kitware/CMake/releases/download/v3.25.0/cmake-3.25.0-windows-x86_64.msi" target="_blank" rel="noopener">下载CMake</a>，并将其安装到Windows系统上。</p><p>之后打开 CMake-GUI，在 CMake-GUI 中指定SDL2源码所在路径以及编译后的输出路径，随后执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Configure -&gt; Generate</span><br></pre></td></tr></table></figure><p>生成VS工程。有了VS工程，我们就可以通过VS2019或VS2022来编译SDL了。</p><p>需要指出的是，编译好的SDL会保存到指定输出目录的 <strong>Release</strong> 或 <strong>Debug</strong> 目录下（例如指定的输出目录为<code>/usr/local/sdl2</code>，则输出路径为<code>/usr/local/sdl2/Release</code>)，而我们希望输出的路径则是<code>/usr/local/sdl2/lib</code>。</p><p>为了满足要求，<strong>我们需要在指定输出目录下创建 **lib</strong> 目录，并将SDL2.lib 和 SDL2.dll文件拷贝到 lib 目录下。同时在 lib 目录下创建 pkgconfig 目录，将sdl2.pc 文件拷贝到该目录中**。</p><p>此外，我们还要修改 <strong>sdl2.pc</strong> 中的内容，将其中的库路径修改为指定的输出路径，最终完整的目录结构如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/sdl2</span><br><span class="line"> |------------ lib</span><br><span class="line"> |              |-- sdl2.lib</span><br><span class="line"> |              |-- sdl2.dll</span><br><span class="line"> |              |-- pkgconfig</span><br><span class="line"> |                     |----- sdl2.pc</span><br><span class="line"> |------------ include</span><br></pre></td></tr></table></figure><h3 id="编译x264"><a href="#编译x264" class="headerlink" title="编译x264"></a>编译x264</h3><p>x264库的编译还是比较简单的，与SDL一样我们也要先获取其源码，可以通过下面的命令获取x264源码：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://code.videolan.org/videolan/x264.git</span><br></pre></td></tr></table></figure><p>源码获取到后，可以直接在MSYS2环境下编译出Windows下可用的动态库，具体步骤如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过VS X64 Native... 窗口打开MSYS2</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /d/x264 <span class="comment"># 在MSYS2中进入x264源码目录</span></span><br><span class="line"></span><br><span class="line">pacman -S automake autoconf libtool <span class="comment"># 安装生成Makefile的工具</span></span><br><span class="line"></span><br><span class="line">CC=cl ./configure --prefix=/usr/<span class="built_in">local</span>/x264 --<span class="built_in">enable</span>-shared</span><br><span class="line"></span><br><span class="line">make -j 4 &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>通过上面的命令就可以将x264编译出来了。x264编译好后，其输出的目录结构与SDL2是一样的，在<code>/usr/local/x264</code>中包括了<code>include</code>、<code>lib</code>、<code>bin</code>等目录。</p><p>要特别强调的一点是，我们需要将<code>lib</code>目录下的<code>libx264.dll.lib</code>文件名修改为<code>libx264.lib</code>，否则ffmpeg编译时会报 <strong>“无法找到该库”</strong> 的错误。</p><h3 id="编译fdk-aac"><a href="#编译fdk-aac" class="headerlink" title="编译fdk-aac"></a>编译fdk-aac</h3><p>fdk-aac的编译与SDL类似，它同样要使用CMake生成VS工程文件，之后再通过VS编译该库。</p><p>首先，通下面的的命令获取fdk-aac源码:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/mstorsjo/fdk-aac.git</span><br></pre></td></tr></table></figure><p>之后，通过CMake生成VS工程文件，具体执行步骤请参考 SDL 生成 VS 工程的步骤，这里就不再重复了。</p><p>接下来，使用VS2019或VS2022编译fdk-aac，编译好的库同要会被放到Release或Debug目录下，因此我们必须像处理SDL库一样，需要手工组织fdk-aac的输出目录树。</p><p>至此fdk-aac就算编译好了。</p><blockquote><p>在编译fdk-aac时有个特殊情况，就是使用CMake的方式无法产生include头文件（这也有可能是我哪块执行的不对）。为了解决这个问题，我又用 MSYS2+mingw 的方式重新编译了一遍fdk-aac，这种方式是可以生成 <strong>include</strong> 头文件的，然后将生成的头文件手动拷贝到了/usr/local/fdk-aac目录下即可。</p></blockquote><h3 id="FFmpeg如何使用上述编译好的库呢？"><a href="#FFmpeg如何使用上述编译好的库呢？" class="headerlink" title="FFmpeg如何使用上述编译好的库呢？"></a>FFmpeg如何使用上述编译好的库呢？</h3><p>首先，我们要设置环境变量<code>PKG_CONFIG_PATH</code>，通过它告诉FFmpeg上述几个库从哪儿可以找到，具体的设置方法如下：</p><ul><li>在MSYS2窗口中打开<code>.bashrc</code><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pacman -S vim</span><br><span class="line">vim ~/.bashrc</span><br></pre></td></tr></table></figure></li><li>在<code>~/.bashrc</code>中设置环境变量<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PKG_CONFIG_PATH=/usr/<span class="built_in">local</span>/sdl2/lib/pkgconfig:/usr/<span class="built_in">local</span>/x264/lib/pkgconfig:/usr/<span class="built_in">local</span>/fdk-aac/lib/pkgconfig:<span class="variable">$PKG_CONFIG_PATH</span></span><br><span class="line"></span><br><span class="line">:wq <span class="comment">#保存并退出vim</span></span><br></pre></td></tr></table></figure></li><li>让环境变是生效<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure></li></ul><p>接下来，重新生成FFmpeg的Makefile文件，并重新编译，命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>/ffmpeg --arch=x86_64 --<span class="built_in">enable</span>-shared --<span class="built_in">disable</span>-ffprobe --<span class="built_in">disable</span>-doc --<span class="built_in">enable</span>-x264 --<span class="built_in">enable</span>-gpl --<span class="built_in">enable</span>-fdk-aac --<span class="built_in">enable</span>-nonfree --toolchain=msvc</span><br><span class="line"></span><br><span class="line">make clean</span><br><span class="line"></span><br><span class="line">make -j 4 &amp;&amp; make install</span><br></pre></td></tr></table></figure><p><strong>最后，将sdl2的dll、x264的dll以及fdk-aac的dll拷贝到ffmpeg的bin目录下，这样就可以正确的执行 ffmpeg.exe 或 ffplay.exe 命令了</strong>。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>上面就是在Windows下编译和使用FFmpeg的方法。如果你在Linux或Mac下可以熟练的编译FFmpeg，你会发现，在Window下编译FFmpeg的步骤与在Linux和Mac下编译的步骤是一样的，关键点是在Windows下该如何搭建好编译环境。</p><p>此外需要强调的是，在Windows下编译FFmpeg时，由于它不能识别 <strong>CC_IDENT</strong> 关键字，所以编译时会报错，我们只需将使用该关键字的语句注释掉即可解决该问题。</p><p>另外，在程序中通过<code>#include</code>引用FFmpeg头文件时，一定要记得加 <code>extern &quot;C&quot;</code>关键字，告诉C++编译器，这个头文件是一个C类型的头文件，这样它才能正确编译。</p><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><ul><li><a href="https://github.com/ShiftMediaProject/FFmpeg" target="_blank" rel="noopener">ShiftMediaProject</a>，有同学给我推荐了这个项目，我简单了解了一下，这个项目真不错，可以直接使用VS对FFmpeg进行调试，有兴趣的同学可以偿试一下。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img data-src=&quot;https://cdn.avdancedu.com/image/article/windows_ffmpeg/FFmpeg_logo.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;在我的FFmpeg课程中，我总是推荐大家使用 &lt;strong&gt;Linux(Ubuntu)系统&lt;/strong&gt; 或 &lt;strong&gt;Mac系统&lt;/strong&gt; 来学习FFmpeg。其原因，是在Windows下编译FFmpeg太麻烦了，这大大增加了我们学习FFmpeg的成本。&lt;/p&gt;
&lt;p&gt;不光如此，在Windows下编译FFmpeg所需要的依赖库也很麻烦，比如我们经常使用的fdk-aac、x264等在Windows下都要单独编译才可以使用。&lt;/p&gt;
&lt;p&gt;不过，总还是有一些同学需要在Windows下使用FFmpeg，而FFmpeg官网上介绍的Windows下编译FFmpeg的&lt;a href=&quot;https://visualstudio.microsoft.com/zh-hans/thank-you-downloading-visual-studio/?sku=Community&amp;channel=Release&amp;version=VS2022&amp;source=VSLandingPage&amp;cid=2030&amp;passive=false&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;文章&lt;/a&gt;实在是太老了，基本不可用。为了解决这部分同学的难题，这里我总结了一份Windows下编译和使用FFmpeg的方法，希望能帮助到大家！&lt;/p&gt;
    
    </summary>
    
    
      <category term="FFmpeg" scheme="https://blog.avdancedu.com/categories/FFmpeg/"/>
    
    
      <category term="FFmpeg" scheme="https://blog.avdancedu.com/tags/FFmpeg/"/>
    
  </entry>
  
  <entry>
    <title>VS中引入并使用WebRTC库</title>
    <link href="https://blog.avdancedu.com/fcd68433/"/>
    <id>https://blog.avdancedu.com/fcd68433/</id>
    <published>2022-11-24T13:35:00.000Z</published>
    <updated>2022-12-07T06:08:07.550Z</updated>
    
    <content type="html"><![CDATA[<p><img data-src="https://avdancevod.oss-cn-beijing.aliyuncs.com/image/article/import_webrtc/webrtc_banner_2.jpeg" alt="banner"></p><p>前段时间经常有同学问我，如何在Windows下利用编译出的WebRTC库开发自己的应用程序，当时特别忙就让同学到网上找答案了，没想到过了几天同学们又来问，说网上找不到……</p><p>相对于移动端，在Windows下使用WebRTC库确实困难些。在移动端（iOS、Andorid），你可以直接从Google提供的Pod库中拉取编译好的WebRTC库，而在Windows端则需要我们自己编译WebRTC库，并导出WebRTC头文件。</p><p>这几天手头的工作终于忙的差不多了，今天就花点时间整理一下这方面的知识，给同学们搭个<strong>台阶</strong>，让同学们快尽入手WebRTC:)。</p><a id="more"></a><h2 id="安装开发环境"><a href="#安装开发环境" class="headerlink" title="安装开发环境"></a>安装开发环境</h2><p>在Windows下开发应用程序最常用的开发工具还是Visual Studio，你可以使用VS2019，也可以使用VS2022，目前我还是建议大家先用 VS2019，再等个半年、一年的换VS2022比较合适。VS2019的下载地址<a href="https://visualstudio.microsoft.com/zh-hans/thank-you-downloading-visual-studio/?sku=community&rel=16&utm_medium=microsoft&utm_campaign=download+from+relnotes&utm_content=vs2019ga+button" target="_blank">在这里</a>，将 VS Installer下载好后，在CMD窗口中执行下面的命令即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ PATH_TO_INSTALLER.EXE ^</span><br><span class="line">--add Microsoft.VisualStudio.Workload.NativeDesktop ^</span><br><span class="line">--add Microsoft.VisualStudio.Component.VC.ATLMFC ^</span><br><span class="line">--includeRecommended</span><br></pre></td></tr></table></figure><p>当然，正常情况下你在配置WebRTC编译环境时就应该已经将VS安装好了。</p><h2 id="编译WebRTC"><a href="#编译WebRTC" class="headerlink" title="编译WebRTC"></a>编译WebRTC</h2><p>开发环境安装好后，下面我们就该编译WebRTC源码了。WebRTC源码的下载与编译请看<a href="https://avdancedu.com/2bafd6cf/" target="_blank" rel="noopener">这篇文章</a>。</p><p>需要注意的是，我们在新项目中引入的WebRTC库，不能直接用下面的命令进行编译：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gn gen out&#x2F;Default</span><br><span class="line">ninja -C out&#x2F;Default</span><br></pre></td></tr></table></figure><p>而必须明确指明编译出的WebRTC是<strong>Debug</strong>版本，还是<strong>Release</strong>版本；是<strong>x86</strong>版本还是<strong>x64</strong>版本……</p><p>因此，应该使用下面的命令编译WebRTC:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gn gen --target&#x3D;x64 --ide&#x3D;vs2019 --args&#x3D;&quot;is_debug&#x3D;true rtc_enable_protobuf&#x3D;false is_clang&#x3D;false target_cpu&#x3D;\&quot;x64\&quot;  enable_iterator_debugging&#x3D;true  use_custom_libcxx&#x3D;false symbol_level&#x3D;0 rtc_include_tests&#x3D;false&quot; out&#x2F;debug_x64</span><br><span class="line">ninja - C out&#x2F;debug_x64</span><br></pre></td></tr></table></figure><p>上述 <strong>gn</strong> 中的几个参数含义如下：</p><ul><li>–target，顾名思义，生成x64版本的WebRTC库</li><li>–ide，生成VS工程文件</li><li>–args，编译时的一些配置参数<ul><li>is_debug，为true编译出Debug版本；为false编译出Release版本</li><li>rtc_enable_protobuf，是否使用protobuf，使用可将其设置为true</li><li>use_custom_libcxx，WebRTC默认使用的是libc++库，而我们在Windows上使用的是libstdc++库，所以需要将其设置为false</li><li>symbol_level，编译出的WebRTC库是否带符号表，这个数据量很大，会影响运行速度，所以一般设置为0，表示编译出的WebRTC不带符号表</li><li>rtc_include_tests，编译WebRTC时是否编译测试用例，如果为false则不编译，这样可以大大加快WebRTC的编译速度</li></ul></li></ul><p>执行上面的命令时，会花一些时间，因此我们需要让<strong>子弹飞一会儿</strong>……</p><h2 id="构建自己的应用程序"><a href="#构建自己的应用程序" class="headerlink" title="构建自己的应用程序"></a>构建自己的应用程序</h2><p>如果顺利的话，你现在应该已经将WebRTC库编译好了。接下来我们来创建自己的应用程序。</p><p>为了方便，你可以将WebRTC examples中的peerconnection_client代码拿出来构建一个新的工程，之后再将前面编译好的WebRTC库引入进来，<strong>如果它可以正常运行就达到了我们的目标</strong>。</p><p>为了达到这个目标，首先我们先使用VS创建一个空项目，步骤如下：</p><ul><li>第一步，打开Visual Studio，<strong>创建新项目</strong><br><img data-src="https://cdn.avdancedu.com/image/article/import_webrtc/vs1.png" alt="图1"></li><li>第二步，使用Windows桌面向导创建Windows空项目<br><img data-src="https://cdn.avdancedu.com/image/article/import_webrtc/vs2.png" alt="图2"></li><li>第三步，填写项目名称，并将项目与解决方案放在同一目录下<br><img data-src="https://cdn.avdancedu.com/image/article/import_webrtc/vs3.png" alt="图3"></li><li>第四步，选择应用程序类型为<strong>桌面应用程序</strong><br><img data-src="https://cdn.avdancedu.com/image/article/import_webrtc/vs4.png" alt="图4"></li><li>第五步，同时勾选<strong>空项目</strong><br><img data-src="https://cdn.avdancedu.com/image/article/import_webrtc/vs5.png" alt="图5"></li></ul><p>至此，我们就构建出了一个VS<strong>空项目</strong>，它里边没有任何文件，如下图所示：</p><p><img data-src="https://cdn.avdancedu.com/image/article/import_webrtc/vs6_new.png" alt="图6"></p><p>空项目创建好后，紧接着我们来移植peerconnection_client代码到新项目中，步骤如下：</p><ul><li><p>第一步，从WebRTC源码中拷贝peerconnection_client中的代码到新项目的目录中，在我这里是<br>将<code>C:\webrtc\webrtc-checkout\src\exmaples\peerconnection\client</code>目录中的代码拷贝到<code>C:\Users\lichao\sourceMyWebRTCDemo</code>目录下。如下图所示：</p><p><img data-src="https://cdn.avdancedu.com/image/article/import_webrtc/code1.png" alt="code1"></p><p><img data-src="https://cdn.avdancedu.com/image/article/import_webrtc/code2.png" alt="code2"></p></li><li><p>第二步，将新项目中的代码<strong>拖</strong>到VS项目中<br><img data-src="https://cdn.avdancedu.com/image/article/import_webrtc/code3_new.png" alt="code3"></p></li></ul><p>通过以上步骤我们就将peerconnection_client中的代码移植好了。接下来咱们来看<strong>重头戏</strong>，如何在项目中引入WebRTC库。</p><h2 id="引入WebRTC库"><a href="#引入WebRTC库" class="headerlink" title="引入WebRTC库"></a>引入WebRTC库</h2><p>通常我们引入一个外部库只需要两步，<strong>引入库文件和其头文件</strong>。不过，对于WebRTC，更准确的说对于peerconnection_client而言，它需要的不仅仅是WebRTC库，还需要将WebRTC依赖的第三方库加进来，这是大家觉得在Windows下使用WebRTC库比较麻烦的原因。</p><p>下面咱们就来看一下如何引入WebRTC库吧！</p><h3 id="添加依赖的头文件"><a href="#添加依赖的头文件" class="headerlink" title="添加依赖的头文件"></a>添加依赖的头文件</h3><p>我们若想将WebRTC头文件引入到项目中，可以通过下面两种方法引入：</p><ul><li><p>方法一，在VS中将WebRTC源码路径添加到<strong>附加包含目录</strong>中。比如我这里将WebRTC源码下载到了<code>C:\webrtc\webrtc-checkout\src</code>目录下，我只需将该路径添加到:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">项目 -&gt; 属性 -&gt; C&#x2F;C++ -&gt; 常规 -&gt; 附加包含目录</span><br></pre></td></tr></table></figure><p>中即可，如下图所示：<br><img data-src="https://cdn.avdancedu.com/image/article/import_webrtc/setting1.png" alt="setting1"></p><p><strong>这种方法的好处是简单方便，坏处是不便于我们将库文件发布给别人使用。</strong></p></li><li><p>方法二，我们可以通过<a href="https://avdancevod.oss-cn-beijing.aliyuncs.com/image/article/import_webrtc/extrac_webrtc_headers.bat" target="_blank" rel="noopener">这个脚本</a>将WebRTC中的头文件提取出来。之后与<strong>方法一</strong>一样，将头文件路径添加到<strong>附加包含目录</strong>中即可。</p><p>需要注意的是，这个脚本下载后，要将其放到WebRTC源码目录<strong>src</strong>的同级目录中，如下图所示：<br><img data-src="https://cdn.avdancedu.com/image/article/import_webrtc/script.png" alt="script1"></p><p>之后打开Windows控制台，并进入到<strong>src</strong>的同级目录中，在CMD窗口中执行<code>extract_webrtc_headers.bat</code>脚本，这样就可以将WebRTC头文件提取出来了，如下图所示：<br><img data-src="https://cdn.avdancedu.com/image/article/import_webrtc/script2.png" alt="script2"></p><p><strong>这种方法的优点是方便其他人使用，缺点是抽取头文件需要花一些时间。</strong></p></li></ul><p>除了添加上面的头文件路径外，我们还需要将下面几个路径添加到<strong>附加包含项目</strong>中：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">C:\webrtc\webrtc-checkout\src\third_party\jsoncpp\generated</span><br><span class="line">C:\webrtc\webrtc-checkout\src\third_party\jsoncpp\source\include</span><br><span class="line">C:\webrtc\webrtc-checkout\src\third_party\libyuv\include</span><br><span class="line">C:\webrtc\webrtc-checkout\src\third_party\abseil-cpp</span><br></pre></td></tr></table></figure><h3 id="添加依赖的库"><a href="#添加依赖的库" class="headerlink" title="添加依赖的库"></a>添加依赖的库</h3><p>头文件添加好后，接下来咱们来添加WebRTC库文件。WebRTC编译好后，你可以在WebRTC源码目录<strong>src</strong>的<strong>out/debug_x64/obj</strong>目录下找到<strong>WebRTC.lib</strong>文件，这就是编译好的WebRTC库。</p><p>我们将它添加到VS中的<strong>附加库目录</strong>中，具体操作如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">右键项目 -&gt; 属性 -&gt; 链接器 -&gt; 常规 -&gt; 附加库目录</span><br></pre></td></tr></table></figure><p>WebRTC库文件路径添加好后，如下图所示：<br><img data-src="https://cdn.avdancedu.com/image/article/import_webrtc/linker1.png" alt="linker1"></p><p>接着咱们添加具体的的依赖库，添加依赖库的位置在:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">右键项目 -&gt; 属性 -&gt; 链接器 -&gt; 输入 -&gt; 附加依赖项</span><br></pre></td></tr></table></figure><p>如下图所示：<br><img data-src="https://cdn.avdancedu.com/image/article/import_webrtc/linker2.png" alt="linker2"></p><p>具体都依赖哪些依赖项呢？这里我以 <strong>M93(4577)</strong> 为例，对于这个版本的peerconnection_client来说，它需要下面的依赖库：</p><ul><li><p>WebRTC相关的库包括：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">third_party/abseil-cpp/absl/flags/marshalling/marshalling.obj</span><br><span class="line">third_party/abseil-cpp/absl/flags/program_name/program_name.obj</span><br><span class="line">third_party/abseil-cpp/absl/flags/flag/flag.obj</span><br><span class="line">third_party/abseil-cpp/absl/flags/flag_internal/flag.obj</span><br><span class="line">third_party/abseil-cpp/absl/flags/commandlineflag/commandlineflag.obj</span><br><span class="line">third_party/abseil-cpp/absl/flags/commandlineflag_internal/commandlineflag.obj</span><br><span class="line">third_party/abseil-cpp/absl/flags/private_handle_accessor/private_handle_accessor.obj</span><br><span class="line">third_party/abseil-cpp/absl/flags/reflection/reflection.obj</span><br><span class="line">third_party/abseil-cpp/absl/flags/parse/parse.obj</span><br><span class="line">third_party/abseil-cpp/absl/flags/usage/usage.obj</span><br><span class="line">third_party/abseil-cpp/absl/flags/usage_internal/usage.obj</span><br><span class="line">third_party/abseil-cpp/absl/flags/<span class="built_in">config</span>/usage_config.obj</span><br><span class="line">third_party/jsoncpp/jsoncpp/json_reader.obj</span><br><span class="line">third_party/jsoncpp/jsoncpp/json_value.obj</span><br><span class="line">third_party/jsoncpp/jsoncpp/json_writer.obj</span><br><span class="line">test/field_trial/field_trial.obj</span><br><span class="line">test/video_test_common/test_video_capturer.obj</span><br><span class="line">test/platform_video_capturer/vcm_capturer.obj</span><br><span class="line">rtc_base/rtc_json/json.obj</span><br></pre></td></tr></table></figure></li><li><p>系统相关的库包括：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">advapi32.lib</span><br><span class="line">comdlg32.lib</span><br><span class="line">dbghelp.lib</span><br><span class="line">dnsapi.lib</span><br><span class="line">gdi32.lib</span><br><span class="line">msimg32.lib</span><br><span class="line">odbc32.lib</span><br><span class="line">odbccp32.lib</span><br><span class="line">oleaut32.lib</span><br><span class="line">shell32.lib</span><br><span class="line">shlwapi.lib</span><br><span class="line">user32.lib</span><br><span class="line">usp10.lib</span><br><span class="line">uuid.lib</span><br><span class="line">version.lib</span><br><span class="line">wininet.lib</span><br><span class="line">winmm.lib</span><br><span class="line">winspool.lib</span><br><span class="line">ws2_32.lib</span><br><span class="line">delayimp.lib</span><br><span class="line">kernel32.lib</span><br><span class="line">ole32.lib</span><br><span class="line">crypt32.lib</span><br><span class="line">iphlpapi.lib</span><br><span class="line">secur32.lib</span><br><span class="line">dmoguids.lib</span><br><span class="line">wmcodecdspuuid.lib</span><br><span class="line">amstrmid.lib</span><br><span class="line">msdmo.lib</span><br><span class="line">strmiids.lib</span><br></pre></td></tr></table></figure></li></ul><h3 id="添加宏"><a href="#添加宏" class="headerlink" title="添加宏"></a>添加宏</h3><p>除了上面讲的需要引入头文件和WebRTC库之外，还需要添加下面这些宏。这些宏的具体含义我有不介绍了，有兴趣的同学可以自己在网上搜索一下。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">USE_AURA=<span class="number">1</span></span><br><span class="line">_HAS_NODISCARD</span><br><span class="line">_HAS_EXCEPTIONS=<span class="number">0</span></span><br><span class="line">__STD_C</span><br><span class="line">_CRT_RAND_S</span><br><span class="line">_CRT_SECURE_NO_DEPRECATE</span><br><span class="line">_SCL_SECURE_NO_DEPRECATE</span><br><span class="line">_ATL_NO_OPENGL</span><br><span class="line">_WINDOWS</span><br><span class="line">CERT_CHAIN_PARA_HAS_EXTRA_FIELDS</span><br><span class="line">PSAPI_VERSION=<span class="number">2</span></span><br><span class="line">WIN32</span><br><span class="line">_SECURE_ATL</span><br><span class="line">WINAPI_FAMILY=WINAPI_FAMILY_DESKTOP_APP</span><br><span class="line">WIN32_LEAN_AND_MEAN</span><br><span class="line">NOMINMAX</span><br><span class="line">_UNICODE</span><br><span class="line">UNICODE</span><br><span class="line">NTDDI_VERSION=NTDDI_WIN10_VB</span><br><span class="line">_WIN32_WINNT=<span class="number">0x0A00</span></span><br><span class="line">WINVER=<span class="number">0x0A00</span></span><br><span class="line">_DEBUG</span><br><span class="line">DYNAMIC_ANNOTATIONS_ENABLED=<span class="number">1</span></span><br><span class="line">WEBRTC_ENABLE_PROTOBUF=<span class="number">0</span></span><br><span class="line">WEBRTC_INCLUDE_INTERNAL_AUDIO_DEVICE</span><br><span class="line">RTC_ENABLE_VP9</span><br><span class="line">WEBRTC_HAVE_SCTP</span><br><span class="line">WEBRTC_ENABLE_AVX2</span><br><span class="line">RTC_ENABLE_WIN_WGC</span><br><span class="line">WEBRTC_NON_STATIC_TRACE_EVENT_HANDLERS=<span class="number">0</span></span><br><span class="line">WEBRTC_WIN</span><br><span class="line">ABSL_ALLOCATOR_NOTHROW=<span class="number">1</span></span><br><span class="line">_ENABLE_EXTENDED_ALIGNED_STORAGE</span><br><span class="line">ABSL_FLAGS_STRIP_NAMES=<span class="number">0</span></span><br><span class="line">HAVE_WEBRTC_VIDEO</span><br></pre></td></tr></table></figure><p>添加方法如下:</p><ul><li><p>首先在 VS 中执行下面的操作，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">右键项目 -&gt; 属性 -&gt; C&#x2F;C++ -&gt; 预处理器</span><br></pre></td></tr></table></figure></li><li><p>之后将上面的宏添加到<strong>预处理器</strong>中即可。</p></li></ul><h2 id="编译运行"><a href="#编译运行" class="headerlink" title="编译运行"></a>编译运行</h2><p>到此为止，我们就将peerconnection_client的代码移植好了，直接点<img data-src="https://cdn.avdancedu.com/image/article/import_webrtc/run.png" alt="">测试一下吧！</p><p>此时，编译器有可能报4996的错误，解决该问题办法很简单，只要在</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">右键项目项 -&gt; 属性 -&gt; C&#x2F;C++ -&gt; 高级 -&gt; 禁用特定警告</span><br></pre></td></tr></table></figure><p>中将 <strong>4996</strong> 添加进去即可。除此之外，还有可能遇到 <strong>/MDd</strong> 错误，解决它可以通过在</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">右键项目项 -&gt; 属性 -&gt; C&#x2F;C++ -&gt; 代码生成 -&gt; 运行库</span><br></pre></td></tr></table></figure><p>中将 <strong>/MDd</strong> 改为 <strong>/MTd</strong> 即可。</p><p>如果一切顺利，peerconnection_client的连接窗口就展示在你面前了，如下图所示。<br><img data-src="https://cdn.avdancedu.com/image/article/import_webrtc/conn.png" alt=""></p><p>此时，你需要先将peerconnection_server程序运行起来，让它侦听 <strong>8888</strong> 端口；之后在peerconnection_client的连接界面中输入 <strong>127.0.0.1</strong>，点击<strong>连接</strong>，如果能进入列表界面就表明OK了。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>上面我详细的向你介绍了如何将WebRTC中的peerconnection_client代码移植出来，并重点向你讲解了如何在项目中引入WebRTC库。</p><p>其重点包括三步：一是添加WebRTC库头文件路径；二是添加WebRTC库路径，及其WebRTC库；三是添加一堆宏。只要将上面三个步骤操作好了，其它的一些问题在网上都能找到答案。</p><p>祝大家好运！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img data-src=&quot;https://avdancevod.oss-cn-beijing.aliyuncs.com/image/article/import_webrtc/webrtc_banner_2.jpeg&quot; alt=&quot;banner&quot;&gt;&lt;/p&gt;
&lt;p&gt;前段时间经常有同学问我，如何在Windows下利用编译出的WebRTC库开发自己的应用程序，当时特别忙就让同学到网上找答案了，没想到过了几天同学们又来问，说网上找不到……&lt;/p&gt;
&lt;p&gt;相对于移动端，在Windows下使用WebRTC库确实困难些。在移动端（iOS、Andorid），你可以直接从Google提供的Pod库中拉取编译好的WebRTC库，而在Windows端则需要我们自己编译WebRTC库，并导出WebRTC头文件。&lt;/p&gt;
&lt;p&gt;这几天手头的工作终于忙的差不多了，今天就花点时间整理一下这方面的知识，给同学们搭个&lt;strong&gt;台阶&lt;/strong&gt;，让同学们快尽入手WebRTC:)。&lt;/p&gt;
    
    </summary>
    
    
      <category term="WebRTC" scheme="https://blog.avdancedu.com/categories/WebRTC/"/>
    
    
      <category term="WebRTC" scheme="https://blog.avdancedu.com/tags/WebRTC/"/>
    
      <category term="VS" scheme="https://blog.avdancedu.com/tags/VS/"/>
    
  </entry>
  
  <entry>
    <title>WebRTC源码深入剖析总结</title>
    <link href="https://blog.avdancedu.com/59ecb92/"/>
    <id>https://blog.avdancedu.com/59ecb92/</id>
    <published>2022-11-19T06:52:00.000Z</published>
    <updated>2022-11-20T04:48:00.500Z</updated>
    
    <content type="html"><![CDATA[<p><img data-src="https://cdn.avdancedu.com/image/article/webrtc_parse/fengmian.jpeg" alt=""></p><p>我精心打造的新课 <strong><a href="https://coding.imooc.com/class/532.html" target="_blank" rel="noopener">《WebRTC源码深入剖析》</a></strong> 终于更新完了！！！</p><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>2021年年初，在完成了我的处女作<a href="https://item.jd.com/10033954503352.html" target="_blank" rel="noopener">《WebRTC音视频实时互动技术——原理、实战与源码分析》</a>一书之后，我终于下定决心，出一部WebRTC源码分析的课程了。</p><a id="more"></a><p>我心里十分清楚，要完成这样一个“<strong>大部头</strong>” ，一定会遇到很多困难。比如，如何将这些苦涩难懂的代码讲的通俗易懂？多长时间能讲完？费那么大心血是否值得（有相应的回报） ……</p><p>但我内心又有几分笃定，一方面自2011年起，自己就开始关注WebRTC，最近几年也一直使用WebRTC做定制化开发。而且，在写<a href="https://item.jd.com/10033954503352.html" target="_blank" rel="noopener">《WebRTC音视频实时互动技术——原理、实战与源码分析》</a>一书时，我又对WebRTC源码翻了个底朝天；另一方面，自己已经推出多门视频课，对如何讲课，如何讲好课，也有了一些自己的心得。所以，对是否能讲好这门课，心里还是比较有把握的！<strong>更何况</strong>，这是我完成<strong>WebRTC三部曲</strong>的最后一步，无论付出多大代价都要完成的。唯一要做的选择是什么时候开始！</p><p>就是在这样一个背景下，2021年5月，<strong>我开始行动了！</strong></p><h2 id="WebRTC三部曲"><a href="#WebRTC三部曲" class="headerlink" title="WebRTC三部曲"></a>WebRTC三部曲</h2><p><strong>完成WebRTC三部曲！</strong> 是我这几年的一个<strong>梦想</strong>（显然这个梦想不够高远，因为已经实现了^V^）。音视频实时通信领域的技术有多难，只有自己亲自做过的人才知道，为了保障实时通信时的音视频质量，你不仅要解决音视频编码问题，还必须要解决网络质量，丢包、乱序、延时、重传等等，这些都属于网络质量问题。那为什么会引起网络质量问题呢？比如，发包量超过带宽大小，会导致丢包；线路本身质量带来的问题，各运营商之间的自我保护…..总之，用户看到的都是视频卡了，花屏了，但背后的原因可能各不相同。</p><p>要解决在不同的终端（设备）上进行音视频采集/播放，不同编解码格式的数据可以互通，在各种复杂网络环境中能够保障最佳的实时通话质量，难度之大，真如李白诗中描述的“难于上青天！”。而这样一个天大的难题，却被WebRTC“轻松”化解了。神奇不神奇？意外不意外？因此，自WebRTC被开源，便被业内人奉为圭臬，受到人们的追捧。可以说，所有做实时通信的技术人，无不以熟悉WebRTC而自傲！</p><p>WebRTC到底是怎么做的呢？我们遇到的各种问题为什么WebRTC却处理的很好呢？这些问题一直萦绕在每个技术人的心里。既然WebRTC开源了，那就好办了，读它的代码！！！</p><p>如电视剧的发展情节一样，事情总不会那么一帆风顺，想读懂WebRTC源码？那可不是一件容易的事儿！</p><ul><li><strong>第一关</strong>，代码下不下来。中美之间的关系大家都清楚，没有点<strong>小手段</strong>想从Goole的源码库中将WebRTC代码拉下来，那是不可能的！</li><li><strong>第二关</strong>，代码拉下来又能怎样呢？10多个G的代码，怎么看？从哪个模块看起？那行代码是头儿？</li><li><strong>第三关</strong>，有决心，硬着头皮看？WebRTC的多线程就可以把你搞死！</li><li>……</li></ul><p>好吧！对于绝大多数同学来说，读WebRTC源码的结果就是一轮游，或是<strong>从入门到放弃</strong>（超不过三天）！</p><p>2015年，一个偶然的机会，我加入了当时的明星创业团队–<strong>跟谁学</strong>，在那儿一年多的时间里，让我真正了解了什么是创业。<strong>几十个人，没日没夜，为了一个共同的目标，为了心中的梦想（愿景）一起奋斗！拼一把，为社会，为家庭，更是为自己</strong>。</p><p>这段经历为我埋下了创业的种子。我在想，要不要自己也做点事儿呢？30多岁，创业不年轻，但也绝不老！有体力，有心力，多少还有一点财力。当时的<strong>在线教育</strong>是一股热潮，WebRTC这么好的东西，这么一个宝藏，又是未来技术的方向，为什么不把它讲出来，让更多的人知道呢？</p><p><strong>WebRTC三部曲</strong>，这个计划渐渐的在我的脑海中浮现出来，于是2017年我出来创业了。</p><p>WebRTC三部曲的第一部是<a href="https://coding.imooc.com/class/329.html" target="_blank" rel="noopener">《WebRTC入门与实战》</a>，这门课从WebRTC的应用角度来讲，主要讲WebRTC都能做什么，该怎么使用它，包括各个终端的互联互通。这门课已于2019年上线；第二部<a href="https://coding.imooc.com/class/387.html" target="_blank" rel="noopener">《WebRTC流媒体服器》</a>讲的是如何设计、实现一个可以高负载、大并发，并且能与WebRTC（浏览器）互通的流媒体服务器，这门课同样于2019年上线；第三部就是刚刚更新完的<a href="https://coding.imooc.com/class/532.html" target="_blank" rel="noopener">《WebRTC源码深入剖析》</a>。</p><p>这门课对WebRTC进行了抽丝剥茧的分析。从WebRTC的Demo开始讲起，之后讲解WebRTC是如何控制音视频设备采集数据的；采集的数据是如何一步步转给编码器进行编码的；在编码的同时还要进行本地预览，预览的视频数据是在编码前还是编码后？这类大家比较关心的问题在课程中都做了详尽说明。此外，编码后的数据是如何通过网络传输给对端的；当有多个网络可以选择时，WebRTC是如何做选出最优链路的；WebRTC是如何保障网络质量的……所有的这些问题都在课程中一一做了剖析。</p><p><strong>至此，WebRTC三部曲计划完成！！！</strong></p><h2 id="呕心沥血，精心打造"><a href="#呕心沥血，精心打造" class="headerlink" title="呕心沥血，精心打造"></a>呕心沥血，精心打造</h2><p>如我在<strong>背景</strong>一节所述，我对录制这门课的难度是有预估的。但当真正开始录制之后，才发现难度远超想象。最大的困哪莫过于如何将各个类之间的错综复杂的关系讲明白。如果只讲类关系图，可以很好的梳理出它们的关系和脉络，但同学们看不到代码，看不到细节，这样的课能叫源码剖析吗？如果带着大家一行行看代码，似乎又只见树木不见森林，同样无法达到好的预期。光是为了解决这个问题就花了我好长时间。</p><p>本来计划这门课用6个月的时间录制完成，结果一拖再拖，最后花了整整一年的时间才完成。一年内，没有节假日，没有参加任何活动，全身心投入其中，不夸张的说，为了这门课，真的是<strong>呕心沥血了！</strong></p><p>在这一年中，我写了近 <strong>1400</strong> 页的PPT，画了 <strong>200</strong> 多张精美的图片， 录制了 <strong>200</strong> 多节课，剪辑出了近 <strong>40</strong> 个小时的视频。</p><p>讲解的知识之多，内容跨度之大也超出想象，包括：WebRTC线程模型、Windows CoreAudio、DirectShow、媒体协商过程、音频引擎、视频引擎、网络传输、Qos（Nack/RTX、jitterbuffer、FEC、NetEq)、Simulcast、SVC等等。</p><p>不夸张的说，这门至少在最近几年内，是同类课程的<strong>天花板</strong>了。而且课程还会不断更新，将一些当时想讲，但时间不够没有讲的内容陆续更新到课程中。相信这样一门精心打造的课程，一定会让你觉得<strong>物超所值</strong>！</p><h2 id="价格贵不贵？"><a href="#价格贵不贵？" class="headerlink" title="价格贵不贵？"></a>价格贵不贵？</h2><p>有同学说，这门课<strong>499</strong>的价格是不是有点小贵? 我们来简单的算一算你就清楚这个定价贵不贵了。 按课节算，200节课程，499/200，每节课才2块多钱；按小时算，近 40 个小时，每小时才10块多一点点。要知道我在外面线下培训每小时是几千块。</p><p><strong>你觉得这样的价格贵吗?</strong></p><h2 id="好评如潮"><a href="#好评如潮" class="headerlink" title="好评如潮"></a>好评如潮</h2><p><img data-src="https://cdn.avdancedu.com/image/article/webrtc_parse/haoping1.png" alt=""><br><img data-src="https://cdn.avdancedu.com/image/article/webrtc_parse/haoping2.png" alt=""><br><img data-src="https://cdn.avdancedu.com/image/article/webrtc_parse/haoping3.png" alt=""><br><img data-src="https://cdn.avdancedu.com/image/article/webrtc_parse/haoping4.png" alt=""></p><h2 id="课程目录"><a href="#课程目录" class="headerlink" title="课程目录"></a>课程目录</h2><p><img data-src="https://cdn.avdancedu.com/image/article/webrtc_parse/dir-1.png" alt=""><br><img data-src="https://cdn.avdancedu.com/image/article/webrtc_parse/dir-2.png" alt=""><br><img data-src="https://cdn.avdancedu.com/image/article/webrtc_parse/dir-3.png" alt=""><br><img data-src="https://cdn.avdancedu.com/image/article/webrtc_parse/dir-4.png" alt=""></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>在更新完课程的最后一天做个总结，一方面记录一下<strong>WebRTC三部曲</strong>的完成（这件事儿对我意义重大），另一方面也为下一阶段开启一个新的篇章，同时为这门课做个小小的宣传！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img data-src=&quot;https://cdn.avdancedu.com/image/article/webrtc_parse/fengmian.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;我精心打造的新课 &lt;strong&gt;&lt;a href=&quot;https://coding.imooc.com/class/532.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;《WebRTC源码深入剖析》&lt;/a&gt;&lt;/strong&gt; 终于更新完了！！！&lt;/p&gt;
&lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;2021年年初，在完成了我的处女作&lt;a href=&quot;https://item.jd.com/10033954503352.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;《WebRTC音视频实时互动技术——原理、实战与源码分析》&lt;/a&gt;一书之后，我终于下定决心，出一部WebRTC源码分析的课程了。&lt;/p&gt;
    
    </summary>
    
    
      <category term="WebRTC" scheme="https://blog.avdancedu.com/categories/WebRTC/"/>
    
      <category term="视频课" scheme="https://blog.avdancedu.com/categories/WebRTC/%E8%A7%86%E9%A2%91%E8%AF%BE/"/>
    
    
      <category term="WebRTC" scheme="https://blog.avdancedu.com/tags/WebRTC/"/>
    
      <category term="视频课" scheme="https://blog.avdancedu.com/tags/%E8%A7%86%E9%A2%91%E8%AF%BE/"/>
    
  </entry>
  
  <entry>
    <title>新书出版</title>
    <link href="https://blog.avdancedu.com/bc71cb9a/"/>
    <id>https://blog.avdancedu.com/bc71cb9a/</id>
    <published>2022-11-19T06:52:00.000Z</published>
    <updated>2022-11-20T04:58:51.247Z</updated>
    
    <content type="html"><![CDATA[<p><img data-src="https://cdn.avdancedu.com/image/article/webrtc_qos/webrtc_book.png" alt=""></p><p>近年来，在音视频领域WebRTC越来越受到大家的追棒，它就像音视频技术的一顶“王冠”，上面嵌了大大小小、各种各样的“宝石”，如回音消除、降噪、自动增益、NetEQ、网络拥塞控制……不胜枚举！几乎所有的实时直播客户端都或多或少的使用了WebRTC的代码或借鉴了WebRTC的思想。</p><a id="more"></a><h2 id="WebRTC服务质量"><a href="#WebRTC服务质量" class="headerlink" title="WebRTC服务质量"></a>WebRTC服务质量</h2><p>为什么WebRTC会受到如此追棒呢？我想，究其原因是它有非常好的服务质量（网络服务质量、音视频服务质量）。</p><p>在众多的服务质量中，网络服务质量是最为关键的。你可以想像一下，如果网络是“畅通无阻”的：有无限的带宽，不丢包、不延时，那一切都变得美好了。但现实中，不可能每个用户都有如此好的网络，更多的是网络不佳，带宽受限。而让那些网络不佳、带宽受限的用户也能享受较好的服务，则是WebRTC一直孜孜不倦追求的目标。</p><p>为了达到这个目标，WebRTC发明了一种网控拥塞控制算法，称为GCC。该算法最厉害的地方是可以根据网络的丢包情况和延时趋势准确的判断出用户带宽的大小，并根据带宽的大小来控制发包的速度，从而避免网络拥塞的发生。</p><p>这项技术是十分关键的。大多数情况下，用户的带宽是动态变化的，如果我们不能实时的、有效的判断出带宽的大小，那么很有可能会因为发送音视频码流过大，导致网络拥塞，最终引起网络瘫痪。举个典型的例子，像长城宽带这种共享网络，假如你购买的是 100M 带宽，但实际使用时，分到的带宽并不是 100M，它的波动是非常大的。在早上人少的时候，带宽可以接近 100M；但晚上人多时，可能还 2M都达不到。如果没有拥塞控制算法，不能动态的判断出带宽的大小，我们发送大码流的时候，后果就可想而知了。</p><p>当然，能够准确的评估出带宽，只是“万里长征”的第一步，后面还有很多事情要做呢，如：如何进行发送码流的控制？只控制发送速度就可以了吗？如果不对“源”（产生音频与视频数据的地方）进行控制，就会导致内存爆长，从而引起系统崩溃。</p><p>此外，传输的实时性也是非常关键的。此时又涉及到传输协议的选择了，我们在传输音视频数据时，是应该选择TCP还是UDP？在极端网络情况下为什么要选择UDP？这些都是值得深入探讨的问题。</p><p>当传输协议选好后，端与端之间连接通路的选择对传输的实时性也起着至关重要的作用。如果通信的双方在同一个局域网内，那么它们应该首先选择局域网这条通路，而不是将包发向外网绕一圈再回来；如果不在同一个局域网内，则应该优先选择P2P直连；只有在直连不通的情况下，才应该考虑通过中继服务器进行数据中转，从而达到数据实时传输的目的。</p><p>总之，为了达到更好的服务质量，WebRTC想到了各种办法，可以说无所不用其极。这里我对其方法做了一下总结，分成五大类，如下图所示：</p><p><img data-src="https://cdn.avdancedu.com/image/article/webrtc_qos/webrtc_qos.png" alt=""></p><h2 id="我的新书"><a href="#我的新书" class="headerlink" title="我的新书"></a>我的新书</h2><p>实际上，上面这些内容，都在我的书《WebRTC音视频实时互动技术–原理、实战与源码分析》中做了详细介绍。</p><p>本书不仅对WebRTC的网络传输做了细致、大量的分析，而且还向你详细介绍了如何通过WebRTC实现Web端与Android和iOS端的互联互通；并且还在本书的最后三章对WebRTC的源码进行了剖析，以使你不但可以知道如何使用WebRTC实现音视频通信，还能让你了解其中的原理，并知道WebRTC具体是如何做的。</p><p>总体来说，本书是一本WebRTC入门到进阶的书籍，尤其适合对于WebRTC有一定了解，想进阶的同学来说，非常适合学习本书的内容。以下是本书的目录:</p><p><img data-src="https://cdn.avdancedu.com/image/article/webrtc_qos/webrtc_dir1.png" alt=""><br><img data-src="https://cdn.avdancedu.com/image/article/webrtc_qos/webrtc_dir2.png" alt=""><br><img data-src="https://cdn.avdancedu.com/image/article/webrtc_qos/webrtc_dir3.png" alt=""><br><img data-src="https://cdn.avdancedu.com/image/article/webrtc_qos/webrtc_dir4.png" alt=""></p><h2 id="购买地址"><a href="#购买地址" class="headerlink" title="购买地址"></a>购买地址</h2><p><a href="https://item.jd.com/10033954503352.html" target="_blank" rel="noopener">机械工业出版社(华章)</a></p><h2 id="沟通群"><a href="#沟通群" class="headerlink" title="沟通群"></a>沟通群</h2><p>对于图中的任何疑问可以到微信群中提问。</p><p><img data-src="https://cdn.avdancedu.com/image/article/webrtc_qos/webrtc_group.jpeg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img data-src=&quot;https://cdn.avdancedu.com/image/article/webrtc_qos/webrtc_book.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;近年来，在音视频领域WebRTC越来越受到大家的追棒，它就像音视频技术的一顶“王冠”，上面嵌了大大小小、各种各样的“宝石”，如回音消除、降噪、自动增益、NetEQ、网络拥塞控制……不胜枚举！几乎所有的实时直播客户端都或多或少的使用了WebRTC的代码或借鉴了WebRTC的思想。&lt;/p&gt;
    
    </summary>
    
    
      <category term="WebRTC" scheme="https://blog.avdancedu.com/categories/WebRTC/"/>
    
      <category term="书" scheme="https://blog.avdancedu.com/categories/WebRTC/%E4%B9%A6/"/>
    
    
      <category term="WebRTC" scheme="https://blog.avdancedu.com/tags/WebRTC/"/>
    
      <category term="书" scheme="https://blog.avdancedu.com/tags/%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>《WebRTC音视频实时互动技术--原理、实战与源码分析》勘误表</title>
    <link href="https://blog.avdancedu.com/f2403a12/"/>
    <id>https://blog.avdancedu.com/f2403a12/</id>
    <published>2022-11-19T06:52:00.000Z</published>
    <updated>2022-11-20T05:52:20.056Z</updated>
    
    <content type="html"><![CDATA[<h2 id="勘误一"><a href="#勘误一" class="headerlink" title="勘误一"></a>勘误一</h2><p>a. P3, 1.2节，第三段中的 AVI 应为 AV1.<br>b. P11,  2.1.3节，第一段中的 AVI 应为 AV1<br>c. P22，3.2.2 节，第三段中的所有 AVI 应为 AV1<br>d. P261， 13.5节，第二段中的 AVI 应为 AV1</p><h2 id="勘误二"><a href="#勘误二" class="headerlink" title="勘误二"></a>勘误二</h2><p>P10, P11, P12 中的三张图，修改如下：</p><p><img data-src="https://cdn.avdancedu.com/image/article/webrtc_book_kw/AV_Archive2.png" alt=""></p><a id="more"></a><p><img data-src="https://cdn.avdancedu.com/image/article/webrtc_book_kw/AV_Archive3.png" alt=""><br><img data-src="https://cdn.avdancedu.com/image/article/webrtc_book_kw/AV_plugin.png" alt=""></p><h2 id="勘误三"><a href="#勘误三" class="headerlink" title="勘误三"></a>勘误三</h2><p>P15，第三段应为：</p><p>“从上面的描述中你可以看到，在 WebRTC 架构的四层中，最复杂、最核心的是第三层，即 引擎层，因此，这里我再对引擎层内部的关系做下简要介绍。引擎层包括三部分内容，分别是: 音频引擎、视频引擎以及网络传输。其中<strong>音频引擎</strong>和视频引擎是相对比较独立的。不过，它们 都需要与网络传输层(transport)打交道。也就是说，它们都需要将自己产生的数据通过网络 传输层发送出去;同时，也需要通过网络传输层接收其它端发过来的数据。此外，音频引擎与 视频引擎由于要进行音视频同步的原因，所以它们之间也存在着关联关系。”</p><h2 id="勘误四"><a href="#勘误四" class="headerlink" title="勘误四"></a>勘误四</h2><p>P34，代码4.4 修改如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">socket.to(room).emit(&#39;cmd&#39;);</span><br></pre></td></tr></table></figure><h2 id="勘误五"><a href="#勘误五" class="headerlink" title="勘误五"></a>勘误五</h2><p>P39，代码98行，修改如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">socket.to(room).emit(&#39;other_join&#39;, room, socket.id);</span><br></pre></td></tr></table></figure><h2 id="勘误六"><a href="#勘误六" class="headerlink" title="勘误六"></a>勘误六</h2><p>P40, 代码120行，修改如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">socket.emit(&#39;left&#39;, room, socket.id);</span><br></pre></td></tr></table></figure><h2 id="勘误七"><a href="#勘误七" class="headerlink" title="勘误七"></a>勘误七</h2><p>P43，第四段第一个单词<strong>groudId</strong>应为<strong>groupId</strong>。</p><h2 id="勘误八"><a href="#勘误八" class="headerlink" title="勘误八"></a>勘误八</h2><p>P50, 代码20行，修改如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">socket.on(&#39;other_join&#39;, (roomid) &#x3D;&gt; &#123;</span><br></pre></td></tr></table></figure><h2 id="勘误九"><a href="#勘误九" class="headerlink" title="勘误九"></a>勘误九</h2><p>P70, 代码170行，修改如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">socket.on(&#39;other_join&#39;, (roomid) &#x3D;&gt; &#123;</span><br></pre></td></tr></table></figure><h2 id="勘误十"><a href="#勘误十" class="headerlink" title="勘误十"></a>勘误十</h2><p>P71, 代码210行，修改如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">socket.on(&#39;left&#39;, (roomid, id) &#x3D;&gt; &#123;</span><br></pre></td></tr></table></figure><h2 id="勘误十一"><a href="#勘误十一" class="headerlink" title="勘误十一"></a>勘误十一</h2><p>P98，表6.2各NAT之间可穿越表应为：<br><img data-src="https://cdn.avdancedu.com/image/article/webrtc_book_kw/NAT_table.png" alt=""></p><h2 id="勘误十二"><a href="#勘误十二" class="headerlink" title="勘误十二"></a>勘误十二</h2><p>P103，6.4.2小节倒数第二应为：<br><img data-src="https://cdn.avdancedu.com/image/article/webrtc_book_kw/turn_protocal.png" alt=""></p><p>“因为主机 A 拿到了主机 B 的 Relay 类型的 Candidate，即 RelayB，所以主机 A 可以直接将音视频数据发向 RelayB。TurnServer 从 RelayB 接收到数据后，会将数据 打包成 TURN 消息，经 3478 端口发往主机<strong>B</strong>。主机<strong>B</strong>收数据后，再利用 TurnClient 模块将数据从 TURN 消息中取出，交给其它模块做进一步处理; 同理，主机 B 与主机 A 的操作流程是一样的。TurnServer 从 RelayA 收到数据后，将其打包成 TURN 消息， 也要经过 3478 端口转发给主机<strong>A</strong>。”</p><h2 id="勘误十三"><a href="#勘误十三" class="headerlink" title="勘误十三"></a>勘误十三</h2><p>P114，第一段应为：</p><p>“程， 默认情况下 WebRTC 会将 VP8/H264 等编码器编码后的数据再交由 red 模块编码，生成带一些冗余信息的数据包，这样当传输中某个包丢了，就可以通过其他包将其恢复回来，而不用重传丢失的包。了解了上面这些内容后，第 <strong>16～18</strong> 行代码的含义应该就清楚了，即 PT 值为 124 表示需要使用 red 对之前编码好的数据再进行 red 处理，119 是 PT=124 重传数据 包的 PayloadType。如果用 Wireshark 等抓包工具抓取 WebRTC 媒体数据包时会发现它们都 是 red 包，而在 red 包里装的是 VP8/H264 编码的数据。”</p><h2 id="勘误十四"><a href="#勘误十四" class="headerlink" title="勘误十四"></a>勘误十四</h2><p>P124，代码行号69，内容应为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">69 使用Opus时，每个音频帧的最小间隔为10毫秒，使用带内FEC</span><br><span class="line">70 a&#x3D;fmtp:111 minptime&#x3D;10;useinbandfec&#x3D;1</span><br></pre></td></tr></table></figure><h2 id="勘误十五"><a href="#勘误十五" class="headerlink" title="勘误十五"></a>勘误十五</h2><p>P168，图9.10有误，正确的图如下所示：<br><img data-src="https://cdn.avdancedu.com/image/article/webrtc_book_kw/onebyeheader2.png" alt=""></p><h2 id="勘误十六"><a href="#勘误十六" class="headerlink" title="勘误十六"></a>勘误十六</h2><p>P175，10.1 节的第一段应为：</p><p>“在 WebRTC 中包含多种拥塞控制算法，有 GCC、BBR和 PCC。GCC 根据其实现又可细分为基于发送端的拥塞控制算法 Transport-CC4和基于<strong>接收端</strong>的拥塞控制算法 Goog-REMB。”</p><h2 id="勘误十七"><a href="#勘误十七" class="headerlink" title="勘误十七"></a>勘误十七</h2><p>P176，第一段中的<strong>QUICK</strong>应该为<strong>QUIC</strong>。此外，注脚中的<strong>QUICK</strong>，也应为<strong>QUIC</strong>。</p><h2 id="勘误十八"><a href="#勘误十八" class="headerlink" title="勘误十八"></a>勘误十八</h2><p>P183, 公式10.19 下面一段的第一句应为：</p><p>“在上述公式中，d(i) 表示当前包组到达时长与包组发送时长之差，<strong>参见公式10.4。</strong>正常情况下该值有正有负, ……”</p><h2 id="勘误十九"><a href="#勘误十九" class="headerlink" title="勘误十九"></a>勘误十九</h2><p>P271, 第一段应为：</p><p>“在上述代码中，如果对其再进行简化的话，可以发现 StartNextDecode() 方法中只调用了frame_buffer_对象的 NextFrame() 这个方法。由于该方法传入参数过于复杂，所以不太好理解，其实关键点是掌握其核心代码的第9～15行。”</p><h2 id="勘误二十"><a href="#勘误二十" class="headerlink" title="勘误二十"></a>勘误二十</h2><ul><li>P126，代码126行，应修改为：“PT=96, 代表视频编码器VP8 / 采样率为90000”</li><li>P127，代码179行，应修改为：“PT=98，代表视频编码器VP9 / 采样率为90000”</li><li>P127，代码199行，应修改为：“PT=100，代表视频编码器VP9 / 采样率为90000”</li><li>P128，代码200行，应修改为：“PT=102，代表视频编码器H264 / 采样率为90000”</li><li>P128，代码237行，应修改为：“PT=127，代表视频编码器H264 / 采样率为90000”</li><li>P129，代码254行，应修改为：“PT=125，代表视频编码器H264 / 采样率为90000”</li><li>P129，代码271行，应修改为：“PT=108，代表视频编码器H264 / 采样率为90000”</li></ul><h2 id="勘误二十一"><a href="#勘误二十一" class="headerlink" title="勘误二十一"></a>勘误二十一</h2><p>P198, “博利叶算法”应改为”傅立叶算法”</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;勘误一&quot;&gt;&lt;a href=&quot;#勘误一&quot; class=&quot;headerlink&quot; title=&quot;勘误一&quot;&gt;&lt;/a&gt;勘误一&lt;/h2&gt;&lt;p&gt;a. P3, 1.2节，第三段中的 AVI 应为 AV1.&lt;br&gt;b. P11,  2.1.3节，第一段中的 AVI 应为 AV1&lt;br&gt;c. P22，3.2.2 节，第三段中的所有 AVI 应为 AV1&lt;br&gt;d. P261， 13.5节，第二段中的 AVI 应为 AV1&lt;/p&gt;
&lt;h2 id=&quot;勘误二&quot;&gt;&lt;a href=&quot;#勘误二&quot; class=&quot;headerlink&quot; title=&quot;勘误二&quot;&gt;&lt;/a&gt;勘误二&lt;/h2&gt;&lt;p&gt;P10, P11, P12 中的三张图，修改如下：&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;https://cdn.avdancedu.com/image/article/webrtc_book_kw/AV_Archive2.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="WebRTC" scheme="https://blog.avdancedu.com/categories/WebRTC/"/>
    
      <category term="书" scheme="https://blog.avdancedu.com/categories/WebRTC/%E4%B9%A6/"/>
    
    
      <category term="书" scheme="https://blog.avdancedu.com/tags/%E4%B9%A6/"/>
    
  </entry>
  
  <entry>
    <title>Windows下编译OpenCV库</title>
    <link href="https://blog.avdancedu.com/d6343897/"/>
    <id>https://blog.avdancedu.com/d6343897/</id>
    <published>2022-11-19T06:52:00.000Z</published>
    <updated>2022-11-20T04:50:46.846Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近发现有很多同学在学习OpenCV时，不知道该如何在Windows下编译OpenCV源码，这里我整理了一份Windows编译OpenCV的具体步聚，希望可以帮助到大家。</p><p>Windows下编译OpenCV分为四步，即：</p><ul><li>一、下载安装必要的工具</li><li>二、下载OpenCV源码</li><li>三、生成编译脚本</li><li>四、使用VS工程编译OpenCV</li></ul><a id="more"></a><h2 id="下载必要的工具"><a href="#下载必要的工具" class="headerlink" title="下载必要的工具"></a>下载必要的工具</h2><ol><li>安装python3和numpy库，<a href="https://www.python.org/ftp/python/3.9.2/python-3.9.2-amd64.exe" target="_blank" rel="noopener">下载地址：https://www.python.org/ftp/python/3.9.2/python-3.9.2-amd64.exe</a></li><li>安装 VS, 下载社区版即可，<a href="https://visualstudio.microsoft.com/zh-hans/downloads/" target="_blank" rel="noopener">下载地址： https://visualstudio.microsoft.com/zh-hans/downloads/</a></li><li>安装 cmake，<a href="https://github.com/Kitware/CMake/releases/download/v3.20.0-rc1/cmake-3.20.0-rc1-windows-x86_64.msi" target="_blank" rel="noopener">下载地址：https://github.com/Kitware/CMake/releases/download/v3.20.0-rc1/cmake-3.20.0-rc1-windows-x86_64.msi</a></li><li>下载IPPICV，<a href="https://github.com/opencv/opencv_3rdparty.git" target="_blank" rel="noopener">下载地址：https://github.com/opencv/opencv_3rdparty.git</a><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;opencv&#x2F;opencv_3rdparty.git</span><br></pre></td></tr></table></figure></li></ol><h2 id="下载opencv源码"><a href="#下载opencv源码" class="headerlink" title="下载opencv源码"></a>下载opencv源码</h2><ol><li><p>下载opencv源码, 方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;opencv&#x2F;opencv.git</span><br></pre></td></tr></table></figure></li><li><p>下载opencv-contrib源码, 方法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;opencv&#x2F;opencv_contrib.git</span><br></pre></td></tr></table></figure></li></ol><h2 id="生成编译脚本"><a href="#生成编译脚本" class="headerlink" title="生成编译脚本"></a>生成编译脚本</h2><ol><li>在存放opencv源码目录中创建build目录</li><li>运行cmake</li><li>选择opencv源码目录</li><li>选择编译目录</li><li>选择CPU架构</li><li>增加opencv-contrib选项, OPENCV_EXTRA_MODULES_PATH=../opencv_contrib/modules</li><li>检查编译选项，并<ol><li>勾选 opencv_world</li><li>勾选 ffmpeg</li><li>勾选 IPPICV，这步容易出错，如果你访问不了外网的话一般会出错。可以偿试手工下载IPPICV，进行设置。</li></ol></li><li>生成编译脚本</li></ol><h2 id="使用VS编译OpenCV"><a href="#使用VS编译OpenCV" class="headerlink" title="使用VS编译OpenCV"></a>使用VS编译OpenCV</h2><ol><li>选择输出版本类型</li><li>进行编译</li></ol><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>在上述步骤中，第三步<strong>生成编译脚本</strong>是最容易出错的，其中第7步是导致出错的最大原因，所以在生成编译脚本时一定要仔细检查这几项是否都是OK的。</p><h2 id="我的课程"><a href="#我的课程" class="headerlink" title="我的课程"></a>我的课程</h2><p>-<a href="https://coding.imooc.com/class/496.html" target="_blank" rel="noopener">OpenCV入门与实战</a></p><p>-<a href="https://coding.imooc.com/class/415.html" target="_blank" rel="noopener">音视频系统入门</a></p><p>-<a href="https://coding.imooc.com/class/279.html" target="_blank" rel="noopener">ffmpeg精讲</a></p><p>-<a href="https://coding.imooc.com/class/329.html" target="_blank" rel="noopener">WebRTC入门与实战</a></p><p>-<a href="https://coding.imooc.com/class/387.html" target="_blank" rel="noopener">WebRTC高并发流媒体服务器</a></p><p>-<a href="https://time.geekbang.org/column/article/111337" target="_blank" rel="noopener">从0开始构造直播系统</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;最近发现有很多同学在学习OpenCV时，不知道该如何在Windows下编译OpenCV源码，这里我整理了一份Windows编译OpenCV的具体步聚，希望可以帮助到大家。&lt;/p&gt;
&lt;p&gt;Windows下编译OpenCV分为四步，即：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一、下载安装必要的工具&lt;/li&gt;
&lt;li&gt;二、下载OpenCV源码&lt;/li&gt;
&lt;li&gt;三、生成编译脚本&lt;/li&gt;
&lt;li&gt;四、使用VS工程编译OpenCV&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="人工智能" scheme="https://blog.avdancedu.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
      <category term="图像处理" scheme="https://blog.avdancedu.com/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    
    
      <category term="OpenCV" scheme="https://blog.avdancedu.com/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>3A问题经验分享</title>
    <link href="https://blog.avdancedu.com/5756c48d/"/>
    <id>https://blog.avdancedu.com/5756c48d/</id>
    <published>2022-11-19T06:52:00.000Z</published>
    <updated>2022-11-20T04:52:01.269Z</updated>
    
    <content type="html"><![CDATA[<p>一直以来音频的3A（回音消除、降噪、自动增益）问题都是音视频实时通信中特别关键，也特别难以解决的问题。尤其是回音消除问题，更是难上加难，它就好比你向水中倒了一些墨汁，现在又想将它从水中提取出来一样困难。</p><p>对于做音视频 PaaS (提供API接口服务）的公司而言，只有将3A问题处理好，才能在音视频实时通信市场上占有一席之地，否则就没法与声网、腾讯等这些老牌或巨头公司进行竞争。正是由于3A 问题是做音视频公司必须要解决好的问题，所以它们对能够解决这类问题的人才都求贤若渴，对于想进入音视频行业的同学来说，如果你能具有3A问题的解决能力，那你一定会成为各音视频大厂挣抢的“香饽饽”。</p><p>为了让大家学到更多的干货，这次我特意邀请到拍乐云合伙人&amp;音频专家 Ark，请他为大家详细介绍在商业应用中都会遇到哪些3A问题，遇到这类问题时该如何解决，对于初入门的同学又该如何学习音频技术。相信通过这次分享，一定会让大家会收获满满。</p><p>感兴趣的小伙伴请加入讨论群, 分享时间为2021年6月30 19:45。</p><p><img data-src="https://cdn.avdancedu.com/image/article/3A/dakashuo.png" alt="音频3A经验分享群"></p><a id="more"></a><h2 id="本次分享的大体题纲如下："><a href="#本次分享的大体题纲如下：" class="headerlink" title="本次分享的大体题纲如下："></a>本次分享的大体题纲如下：</h2><h3 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h3><ul><li>音频的一些基本知识，音量（响度），分贝，频率、振幅与音量的关系，为什么音量是负值？</li><li>增益是指什么？它与音量大小的区别是什么？如何进行自动增益？<h3 id="降噪相关"><a href="#降噪相关" class="headerlink" title="降噪相关"></a>降噪相关</h3></li><li>什么是噪音，算法是如何判断出噪音的？</li><li>噪音是有颜色的，这是什么意思？</li><li>降噪的难点是什么？什么样的噪音不好降？</li><li>我们是否应该优先使用硬件降噪？移动端与PC端有什么区别吗？</li><li>什么是舒适噪音？为什么要增加舒适噪音？<h3 id="回音相关"><a href="#回音相关" class="headerlink" title="回音相关"></a>回音相关</h3></li><li>回音消除的难点是什么？</li><li>是否可以简要的介绍一下回音产生的一个大体原理？</li><li>机端的回音消除是否比PC端的回音更好消除一些？其中的原理是否可以比大家介绍一下？</li><li>WebRTC在回音消除方法做了哪些工作，最新的AEC3 与以前的回音消除算法有什么显著的差别？<h3 id="学习相关"><a href="#学习相关" class="headerlink" title="学习相关"></a>学习相关</h3></li><li>在解决实际3A问题时，一定要用到数学吗？</li><li>未来的技术方向</li><li>学习音频的基本路径是什么？</li><li>能否给推荐几本好书？</li></ul><h2 id="分享嘉宾"><a href="#分享嘉宾" class="headerlink" title="分享嘉宾"></a>分享嘉宾</h2><p>Ark，拍乐云合伙人&amp;音频专家。中科大硕士毕业，多年音频开发经验，5年WebEx音频专家工作经验，精通音频3A算法，深入理解实时通信音频框架，主导设计了多套音频处理框架，对于音频算法、移动端设备适配、大屏远场算法优化、智能手表音频优化等都非常了解。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;一直以来音频的3A（回音消除、降噪、自动增益）问题都是音视频实时通信中特别关键，也特别难以解决的问题。尤其是回音消除问题，更是难上加难，它就好比你向水中倒了一些墨汁，现在又想将它从水中提取出来一样困难。&lt;/p&gt;
&lt;p&gt;对于做音视频 PaaS (提供API接口服务）的公司而言，只有将3A问题处理好，才能在音视频实时通信市场上占有一席之地，否则就没法与声网、腾讯等这些老牌或巨头公司进行竞争。正是由于3A 问题是做音视频公司必须要解决好的问题，所以它们对能够解决这类问题的人才都求贤若渴，对于想进入音视频行业的同学来说，如果你能具有3A问题的解决能力，那你一定会成为各音视频大厂挣抢的“香饽饽”。&lt;/p&gt;
&lt;p&gt;为了让大家学到更多的干货，这次我特意邀请到拍乐云合伙人&amp;amp;音频专家 Ark，请他为大家详细介绍在商业应用中都会遇到哪些3A问题，遇到这类问题时该如何解决，对于初入门的同学又该如何学习音频技术。相信通过这次分享，一定会让大家会收获满满。&lt;/p&gt;
&lt;p&gt;感兴趣的小伙伴请加入讨论群, 分享时间为2021年6月30 19:45。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;https://cdn.avdancedu.com/image/article/3A/dakashuo.png&quot; alt=&quot;音频3A经验分享群&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="音频知识" scheme="https://blog.avdancedu.com/categories/%E9%9F%B3%E9%A2%91%E7%9F%A5%E8%AF%86/"/>
    
    
      <category term="3A" scheme="https://blog.avdancedu.com/tags/3A/"/>
    
  </entry>
  
  <entry>
    <title>Windows下编译WebRTC</title>
    <link href="https://blog.avdancedu.com/2bafd6cf/"/>
    <id>https://blog.avdancedu.com/2bafd6cf/</id>
    <published>2022-11-19T06:52:00.000Z</published>
    <updated>2022-12-07T06:06:18.548Z</updated>
    
    <content type="html"><![CDATA[<p><img data-src="https://cdn.avdancedu.com/image/article/webrtc_build/webrtc%E6%9E%B6%E6%9E%84.png" alt=""></p><p>随着音视频技术的不断普及，Google推出的 WebRTC 越来越受到大家的喜欢。现在很多直播产品都是基于WebRTC 进行二次开发做出来的。</p><p>WebRTC是提供了一整套处理实时音视频的开源库。它包括了音视频处理（采集，编解码，前处理，后处理，渲染），数据传输（实时传输，流控）和业务逻辑控制。可以说 WebRTC 的出现大大减少了做音视频开发的难度，所以熟练掌握好这个库对于做音视频相关的同学就显的特别重要了。</p><p>要想掌握 WebRTC 要过的头一关就是如何编译它。WebRTC库非常庞大，光源码就有几个G，所以它对开发主机的性能，网络带宽的要求都非常高。另外，在Windows平台下，它对Windows的系统版本，Visual Studio 版本也都有明确的要求，所以只要其中某一项出问题了，都可能导致失败。这就是为什么很多人在编译WebRTC经常失败的原因。</p><p>下面我们言归正传，介绍一下在如何在 Windows下成功编译WebRTC.</p><a id="more"></a><blockquote><p>注意：本文所有的操作的前提条件是，你可以访问外网</p></blockquote><h2 id="主机及系统配置"><a href="#主机及系统配置" class="headerlink" title="主机及系统配置"></a>主机及系统配置</h2><p>第一、WebRTC要求是 64位机器 8G 内存，最好超过16G内存。</p><blockquote><p>我实际的配置是 64位机器，4G内存，4核CPU也是没问题的。</p></blockquote><p>第二、至少 100G 磁盘空间，NTFS格式。</p><blockquote><p>FAT32格式是不能工作的，因为WebRTC中有的文件大于 4G。</p></blockquote><p>第三、Visual Studio 2019社区版即可。</p><blockquote><p>VS 不需要是英文版本</p></blockquote><p>第四、操作系统需要 Win10 系统。</p><h2 id="安装虚拟机（可选）"><a href="#安装虚拟机（可选）" class="headerlink" title="安装虚拟机（可选）"></a>安装虚拟机（可选）</h2><p>由于环境的问题经常会导致编译失败，所以为了方便设置环境，我使用了VirtualBox虚拟机（该虚拟机是免费的）。相较于VMware它虽然性能稍差，但完全够我们编译开发WebRTC使用。所以我们也不必在虚拟机这个环节上纠结。</p><p>安装虚拟机需要注意以下几点：</p><ol><li>为了更好的利用硬件，需要确认你机子的BOIS中是否打开了虚拟化选项，这对虚拟机的性能会产生很大影响。</li><li>在虚拟机上安装完系统后，一定要安装虚拟的<a href="https://jingyan.baidu.com/article/6525d4b13b7d0fac7d2e94ef.html" target="_blank" rel="noopener">增强驱动</a>，这样虚拟机要才能全屏显示。不会的可去问度娘。</li></ol><h2 id="安装-Visual-Stuido"><a href="#安装-Visual-Stuido" class="headerlink" title="安装 Visual Stuido"></a>安装 Visual Stuido</h2><p>官网上已经明确说可以使用<strong>Visual Studio 2022</strong>来编译WebRTC了，亲测确实可行!</p><p><strong>但需要注意的是，最新的WebRTC代码中的peerconnection_client程序无法与peerconnection_server连接，该问题已经存在一段时间了，目前还没有修复。所以，如果你想运行peerconnection_client程序，那么你需要将WebRTC切换到M93(4577)之前的版本。而WebRTC M93(4577)之前的版本必须使用VS2019，这一点你一定要清楚。</strong></p><p>在安装Visual Studio 时，可以使用免费的 Community Edition 版本。</p><h3 id="下载Visual-Studio-2022"><a href="#下载Visual-Studio-2022" class="headerlink" title="下载Visual Studio 2022"></a>下载Visual Studio 2022</h3><ul><li>VS2022可以从<a href="https://visualstudio.microsoft.com/zh-hans/thank-you-downloading-visual-studio/?sku=Community&channel=Release&version=VS2022&source=VSLandingPage&cid=2030&passive=false" target="_blank" rel="noopener">这里下载</a></li><li>其对应的Win 10 SDK版本为<strong>10.0.20348.0</strong>，你可以从<a href="https://go.microsoft.com/fwlink/?linkid=2164145" target="_blank" rel="noopener">这里下载</a></li></ul><h3 id="安装Visual-Studio-2019"><a href="#安装Visual-Studio-2019" class="headerlink" title="安装Visual Studio 2019"></a>安装Visual Studio 2019</h3><ul><li>VS2019对应的Win 10 SDK可以从<a href="https://developer.microsoft.com/zh-cn/windows/downloads/sdk-archive/" target="_blank" rel="noopener">这里下载</a>，选择<strong>10.0.18362.1</strong>这个版本。</li><li><a href="https://visualstudio.microsoft.com/zh-hans/thank-you-downloading-visual-studio/?sku=community&rel=16&utm_medium=microsoft&utm_campaign=download+from+relnotes&utm_content=vs2019ga+button" target="_blank">VS2019的下载地址</a></li></ul><h3 id="安装需要注意的事项"><a href="#安装需要注意的事项" class="headerlink" title="安装需要注意的事项"></a>安装需要注意的事项</h3><ul><li>安装Win 10 SDK 时，一定要选择 <strong>“Debugging Tools For Windows”</strong> 这项，它会将调试工具 windbg 和cdb安装上，这些工具会在后面测试和调试时使用。</li><li>另外，安装SDK和VS时要将它们安装到C盘</li><li>第三，当VS Installer下载好后，在命令行中执行下面的命令来安装VS：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ PATH_TO_INSTALLER.EXE ^</span><br><span class="line">--add Microsoft.VisualStudio.Workload.NativeDesktop ^</span><br><span class="line">--add Microsoft.VisualStudio.Component.VC.ATLMFC ^</span><br><span class="line">--includeRecommended</span><br></pre></td></tr></table></figure><blockquote><p>注意，如果 Windows SDK 是通过 Visual Studio 安装的, 则 调试 Tools 需要按下面步骤安装: </p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Control Panel → Programs → Programs and Features → Select the “Windows Software Development Kit” v14393 → Change → Change → Check “Debugging Tools For Windows” → Change.</span><br></pre></td></tr></table></figure><h2 id="安装-depot-tools"><a href="#安装-depot-tools" class="headerlink" title="安装 depot_tools"></a>安装 depot_tools</h2><p>depot_tools就是一堆下载代码，编译等相关的工具，Google统一打包在 <a href="https://storage.googleapis.com/chrome-infra/depot_tools.zip" target="_blank" rel="noopener">depot_tools</a>中，你需将它下载到本地。</p><p><strong>首先</strong>，将 depot_tools.zip 文件解压。</p><p><strong>其次</strong>，将 depot_tools 目录地址添加到你机器的 <strong>系统环境变量 PATH</strong>  里，而不是用户级的环境变量里。具体操作如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Control Panel → System and Security → System → Advanced system settings</span><br></pre></td></tr></table></figure><blockquote><p>注意，必须将它放在PATH环境变量的开头。</p></blockquote><p><strong>然后</strong>，用同样的方法将 <strong>DEPOT_TOOLS_WIN_TOOLCHAIN</strong> 设置到你的系统环境变量里，并设置它的值为 0 ，该变量会告诉 depot_tools 使用你本地安装的 Visual Studio 版本。</p><blockquote><p>默认，depot_tools 使用 Google 内部版本。</p></blockquote><p><strong>最后</strong>，打开 cmd.exe, 运行 gclient 命令(不用带作何参数)。第一次运行时，gclient 将安装 Windows 下需要的工具, 包括 msysgit 和 python。gclient 执行完后，在命令行提示符下输入 python 将会显示 python.bat ，这就说明 depot_tools 安装好了。</p><h2 id="获取-WebRTC-代码"><a href="#获取-WebRTC-代码" class="headerlink" title="获取 WebRTC 代码"></a>获取 WebRTC 代码</h2><p>执行下面的命令就可以获取 WebRTC 的代码了，也只有用这种方式，后面才能编译通过。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1. mkdir webrtc-checkout</span><br><span class="line">2. cd webrtc-checkout</span><br><span class="line">3. fetch --nohooks webrtc</span><br><span class="line">4. gclient sync</span><br></pre></td></tr></table></figure><blockquote><p>注意，由于 WebRTC 的代码量非常大，所以我一般都是在晚上让他去下载，第二天就可以用了。</p></blockquote><h2 id="编译及生成工程文件"><a href="#编译及生成工程文件" class="headerlink" title="编译及生成工程文件"></a>编译及生成工程文件</h2><p>执行下面的命令就可以编译WebRTC了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ cd src</span><br><span class="line">$ gn gen out&#x2F;Default</span><br><span class="line">$ ninja -C out&#x2F;Default</span><br></pre></td></tr></table></figure><p>编译成功后，执行下面的命令生成VS工程文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ gn gen --ide&#x3D;vs out\Default</span><br></pre></td></tr></table></figure><p>这时，我们就可以在 src\out\Default\ 目录下找到 all.sln 这个工程文件，到这里我们就大功告成了。</p><h2 id="切换Branch"><a href="#切换Branch" class="headerlink" title="切换Branch"></a>切换Branch</h2><p>有时候我们需要切到WebRTC的某个分支，可以按下面的步聚操作：</p><ul><li>查看WebRTC远端有哪些分支</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git branch -r</span><br></pre></td></tr></table></figure><ul><li>切换到某个具体的分支</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b my_branch refs&#x2F;remotes&#x2F;branch-heads&#x2F;xxxx</span><br><span class="line">gclient sync</span><br></pre></td></tr></table></figure><h2 id="指定VS-版本"><a href="#指定VS-版本" class="headerlink" title="指定VS 版本"></a>指定VS 版本</h2><p>有时间我们需要使用VS的老版本编译旧的WebRTC源码，此时除了需要在Windows上安装老版本VS外，还需要设置如下环境变量，这样WebRTC才会使用老的VS版本。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set GYP_MSVS_VERSION &#x3D; 2019</span><br><span class="line">set GYP_MSVS_OVERRIDE_PATH &#x3D; C:\Program Files (x86)\Microsoft Visual Studio\2019\Community</span><br></pre></td></tr></table></figure><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>我们上面详细介绍了编译WebRTC的步骤，由于WebRTC本身的原因，大家在操作时一定要仔细阅读每一步，否则都有可能导致编译失败。</p><p>谢谢！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img data-src=&quot;https://cdn.avdancedu.com/image/article/webrtc_build/webrtc%E6%9E%B6%E6%9E%84.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;随着音视频技术的不断普及，Google推出的 WebRTC 越来越受到大家的喜欢。现在很多直播产品都是基于WebRTC 进行二次开发做出来的。&lt;/p&gt;
&lt;p&gt;WebRTC是提供了一整套处理实时音视频的开源库。它包括了音视频处理（采集，编解码，前处理，后处理，渲染），数据传输（实时传输，流控）和业务逻辑控制。可以说 WebRTC 的出现大大减少了做音视频开发的难度，所以熟练掌握好这个库对于做音视频相关的同学就显的特别重要了。&lt;/p&gt;
&lt;p&gt;要想掌握 WebRTC 要过的头一关就是如何编译它。WebRTC库非常庞大，光源码就有几个G，所以它对开发主机的性能，网络带宽的要求都非常高。另外，在Windows平台下，它对Windows的系统版本，Visual Studio 版本也都有明确的要求，所以只要其中某一项出问题了，都可能导致失败。这就是为什么很多人在编译WebRTC经常失败的原因。&lt;/p&gt;
&lt;p&gt;下面我们言归正传，介绍一下在如何在 Windows下成功编译WebRTC.&lt;/p&gt;
    
    </summary>
    
    
      <category term="WebRTC" scheme="https://blog.avdancedu.com/categories/WebRTC/"/>
    
    
      <category term="WebRTC" scheme="https://blog.avdancedu.com/tags/WebRTC/"/>
    
  </entry>
  
  <entry>
    <title>WebRTC传输与服务质量</title>
    <link href="https://blog.avdancedu.com/2763ac60/"/>
    <id>https://blog.avdancedu.com/2763ac60/</id>
    <published>2022-11-19T06:52:00.000Z</published>
    <updated>2022-11-20T04:35:58.757Z</updated>
    
    <content type="html"><![CDATA[<p>作者 | 李超<br>整理 | LiveVideoStack</p><p>非常高兴和大家一同探讨WebRTC传输是如何保证音视频服务质量的。</p><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_1.webp" alt=""></p><p>本次分享我将从四个方面向大家介绍一下WebRTC传输是如何保证音视频服务质量的。第一，实时通信的目标。我们首先需要确定实时通信的目标，才能够知道要将实时通信做成怎样的系统、保证怎样的实时性；第二，WebRTC如何保障数据传输的实时性；第三，进行实时传输时，想要满足实时性，网络与服务质量之间可能存在的矛盾；最后，就是WebRTC如何解决网络与服务质量之间的矛盾。</p><a id="more"></a><h2 id="实时通信的目标"><a href="#实时通信的目标" class="headerlink" title="实时通信的目标"></a>实时通信的目标</h2><h3 id="实时通信的目标是什么？"><a href="#实时通信的目标是什么？" class="headerlink" title="实时通信的目标是什么？"></a>实时通信的目标是什么？</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_2.webp" alt=""></p><p>首先提出两个问题：第一，开会时你是喜欢在办公室里，还是更喜欢在线上开？第二，如果有一场演唱会，你愿意去现场呢？还是愿意在线上听？</p><h3 id="线上与现在不同的原因"><a href="#线上与现在不同的原因" class="headerlink" title="线上与现在不同的原因"></a>线上与现在不同的原因</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_3.webp" alt=""></p><p>相信大家更多都会选择线下，理由是线上线下感觉不一样。其不同点在于：首先是摄像头与人眼看到的效果不一样，例如摄像头采集的角度过小、无法拍到某些角度的画面；其次是采集设备的质量参差不齐，一场会议中大家所使用的设备有的高清、有的模糊；最后，也是最关键的一点就是现场的气氛无法被摄像头采集到，每个人都有自己的气场，当大家聚集在一起时，现场氛围感非常热烈，但隔着屏幕无法感受到。</p><h3 id="实时通信的目标-1"><a href="#实时通信的目标-1" class="headerlink" title="实时通信的目标"></a>实时通信的目标</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_4.webp" alt=""></p><p>根据以上几点，我们可以总结出实时通信最终的目标是：尽可能逼近或达到面对面交流的效果。从目前的情况来看，超越面对面交流的效果是几乎不可能的。</p><h2 id="几个重要指标"><a href="#几个重要指标" class="headerlink" title="几个重要指标"></a>几个重要指标</h2><h3 id="几个重要指标-1"><a href="#几个重要指标-1" class="headerlink" title="几个重要指标"></a>几个重要指标</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_6.webp" alt=""></p><p>那么如何才能达到面对面交流的效果呢，这里涉及到几个重要指标。</p><p>最为关键的是实时通信的延迟指标，只有将延迟指标搞清楚，才能知道做实时通信时，达到怎样的延迟才算符合要求的，即接近面对面交流的效果。然后是音视频服务质量指标，延迟指标达到后，再根据这项指标判断音视频服务质量的好坏。</p><h3 id="实时通信延时指标"><a href="#实时通信延时指标" class="headerlink" title="实时通信延时指标"></a>实时通信延时指标</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_7.webp" alt=""></p><p>下面具体看一下延迟指标的分级标准。通过图中表格可以看到，如果端到端延迟在200ms以内，说明整个通话是优质的，通话效果就像大家在同一个房间里聊天一样；300ms以内，大多数人很满意，400ms以内，有小部分人可以感觉到延迟，但互动基本不受影响；500ms以上时，延迟会明显影响互动，大部分人都不满意。</p><p>所以最关键的一级是500ms，只有延迟低于500ms，才可以说是合格的实时互动系统。</p><h3 id="音频服务质量指标"><a href="#音频服务质量指标" class="headerlink" title="音频服务质量指标"></a>音频服务质量指标</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_8.webp" alt=""></p><p>接下来是音频服务质量指标，它根据MOS值来打分。4.0-5.0为“优”，评值标准是听得非常清楚，延时小，交流顺畅；3.5-4.0为“良”，音质稍差，听得清，延时小，有点杂音；3.0-3.5为“中”，音质较可，能听清，有一定时延，可以交流；1.5-3.0为“差”，勉强能够听清，交流时需要重复多次才能够表述清楚；0-1.5为“劣”，完全听不清，延时大，交流不畅。</p><h3 id="视频服务质量指标"><a href="#视频服务质量指标" class="headerlink" title="视频服务质量指标"></a>视频服务质量指标</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_9.png" alt=""></p><p>视频服务质量的评价标准有几个，它们也都是通过MOS值打分来判断质量好坏的，图中参考是以码流大小为标准评估指标。以640*480为例，如果想达到MOS值为4.5的优质效果，可以看到产生的码流的大小大概在3Mbps左右。这样的码流对于实时传输来说太大了，如果是640*480的视频占用3Mbps的带宽，那是一件非常奢侈的事儿。一般情况下，我们会选择MOS值为3.5（绿色线）的码流，其码流范围在600kbps左右。</p><p>从以上可以看到，在保证传输的实时性时，由于带宽是一定的，可能会牺牲一定的服务质量。</p><h2 id="主要矛盾"><a href="#主要矛盾" class="headerlink" title="主要矛盾"></a>主要矛盾</h2><h3 id="实时通信与服务质量的矛盾"><a href="#实时通信与服务质量的矛盾" class="headerlink" title="实时通信与服务质量的矛盾"></a>实时通信与服务质量的矛盾</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_10.webp" alt=""></p><p>通过了解上述三个指标，我们可以得到实时通信与服务质量的主要矛盾。</p><p>第一，码流与带宽之间的矛盾。要想达到好的质量，码流一般会比较大（当然，不能超过最大码流)，而带宽是有限的，于是码流和带宽之间就会产生矛盾；第二，实时性和服务质量之间的矛盾。通常为了保证好的实时性我们会选择UDP，而UDP不保证网络传输的可靠性，丢包、乱序是经常发生的。一旦出现丢包、乱序，网络传输质量就无法得到保证，最终会影响到音视频的质量。</p><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_11.webp" alt=""></p><p>这里我们就可以总结出实时通信的主要矛盾，即：音视频的质量与带宽大小、实时性和网络质量之间存在矛盾，其它包括3A问题都属于次要矛盾。</p><h2 id="解决矛盾方法"><a href="#解决矛盾方法" class="headerlink" title="解决矛盾方法"></a>解决矛盾方法</h2><h3 id="解决矛盾的方法"><a href="#解决矛盾的方法" class="headerlink" title="解决矛盾的方法"></a>解决矛盾的方法</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_12.webp" alt=""></p><p>下面来看下解决矛盾的方法。对于WebRTC来说，主要从以下几个方面解决主要矛盾：如何保障数据传输的实时性、如何提高网络质量、如何更准确的评估带宽、如何平衡码流与带宽。</p><h2 id="保障数据的实时性"><a href="#保障数据的实时性" class="headerlink" title="保障数据的实时性"></a>保障数据的实时性</h2><p>对于WebRTC来说，为了保障数据的实时性，提供了两种方法：一种是传输路径的选择，它首先会选择最佳的传输路径，使得端到端传输时采取最好、最短的传输路径从而保障数据传输的实时性；另一种是传输协议的选择，可以选择TCP或者UDP。下面咱们先看一下WebRTC是如何选择最佳传输路径的。</p><h3 id="选择一条最好的路径"><a href="#选择一条最好的路径" class="headerlink" title="选择一条最好的路径"></a>选择一条最好的路径</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_13.png" alt=""></p><p>图为WebRTC路径选择的架构图。图中包括三个端，A端、B端和C端，其中A和B在同一个局域网内，对于WebRTC来说，如果发现同一局域网内的两端需要通信时，会选择局域网内直连，从而保障网络路径最短最优；如果是A和C通信，它们不在同一局域网内，那么WebRTC会选择P2P直连，做NAT穿越，如果穿越成功，便可进行直连，这样路径相对服务器中转来说也比较短。只有在P2P不成功时，才会选择服务端中转。从图中可以看到，当一端通过TURN服务器将数据传输给另一端时，其传输路径明显长于P2P直连，所以对于WebRTC来说，它一定会选择最短、最优的路径，从而保障端到端的实时传输。</p><h3 id="使用TCP还是UDP？"><a href="#使用TCP还是UDP？" class="headerlink" title="使用TCP还是UDP？"></a>使用TCP还是UDP？</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_14.webp" alt=""></p><p>接下来看一下WebRTC对TCP/UDP协议的选择。在网络比较优质时，TCP/UDP都可以用于实时传输，但大多数情况下，我们首选UDP（后面会介绍UDP的优势）；弱网环境下不能使用TCP；而在进行网络穿越时，使用TCP又有较大的好处，在企业内可以使用TCP访问外网的80端口进行穿透。</p><h3 id="为什么极端网络环境下不能用TCP？"><a href="#为什么极端网络环境下不能用TCP？" class="headerlink" title="为什么极端网络环境下不能用TCP？"></a>为什么极端网络环境下不能用TCP？</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_15.webp" alt=""></p><p>为什么在弱网环境下不能用TCP？这是由于TCP的机制所造成的。TCP的机制是发送、确认、丢包、重传。正常情况下，数据从一端传输到另一端是没有任何问题的，但当出现丢包时就会有较大的麻烦。</p><p>图中显示了多次丢包时的延迟情况：从客户端向服务端发送数据包，服务端需要返回ACK消息进行确认; 客户端收到确认消息后, 才能继续发送后面的数据（有滑窗时也是类似的）。每次客户端发完数据后，都会启动一个定时器，定时器的最短超时时间是200ms。如果因某种原因，在200毫秒客户端没有收到返回的ACK包，客户端会重发上一个包。由于TCP有退避机制，以防止频繁发送丢失包，因此会将重发包的超时时间延长到400ms。如果重发包依然没有收到确认消息，则下一次重发的超时时间会延长到800ms。我们可以看到，连续几次丢包后，就会产生非常大的延迟，这就是TCP在弱网环境下不能使用的根本原因。</p><h3 id="选择UDP带来的问题"><a href="#选择UDP带来的问题" class="headerlink" title="选择UDP带来的问题"></a>选择UDP带来的问题</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_17.webp" alt=""></p><p>由于TCP的机制问题，因此通常我们会选择UDP来保障音视频传输的实时性。UDP在实时性方面有优势，但缺点同样明显。由于UDP是不可靠传输，它只能尽力送达，所以出现丢包、乱序是常见的事儿，但对于网络质量来说，丢包是非常严重的事情，这就需要我们自己处理这个问题。下面咱们就来看看WebRTC是如何解决这个问题的吧！</p><h2 id="如何提高网络质量"><a href="#如何提高网络质量" class="headerlink" title="如何提高网络质量"></a>如何提高网络质量</h2><h3 id="网络质量包含哪些指标"><a href="#网络质量包含哪些指标" class="headerlink" title="网络质量包含哪些指标"></a>网络质量包含哪些指标</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_18.webp" alt=""></p><p>那么，WebRTC是如何处理UDP的网络质量的呢？</p><p>要想解决网络质量，首先要知道影响网络质量的几个因素：它包括了丢包率、延迟时间、抖动、乱序。如果网络丢包率低、延迟时间小、不抖动、不乱序，这就是非常优质的网络啦。但如果丢包率很高，那么网络质量一定会很差。</p><h3 id="造成丢包的原因"><a href="#造成丢包的原因" class="headerlink" title="造成丢包的原因"></a>造成丢包的原因</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_19.webp" alt=""></p><p>图中是网络基本的拓扑，造成丢包的原因有很多，如链路质量差，当手机与基站连接时，由于信号不好会造成丢包，这就属于链路差，这种情况在移动端是经常发生的；第二是带宽满，比如一台机子上行发送码率比较大，而下行接收链路比较小，这时在上游的路由器会把数据缓存起来慢慢发送，但缓存是有限制的，一旦缓存被塞满，后面就会造成大量丢包；第三是主动丢包，比如路由是跨运营商的，在不同运营商之间传输数据时，可能由于运营商未知的原因造成丢包；第四是光线被挖断等偶然原因造成丢包。</p><h3 id="减少丢包的方法"><a href="#减少丢包的方法" class="headerlink" title="减少丢包的方法"></a>减少丢包的方法</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_20.webp" alt=""></p><p>WebRTC主要通过两种方式解决丢包：NACK和FEC。</p><h3 id="NACK"><a href="#NACK" class="headerlink" title="NACK"></a>NACK</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_21.webp" alt=""></p><p>NACK的作用是丢包重传。从图中你可以看到，WebRTC的发送端不停地向接收端发送RTP包，接收端每隔一小段时间，就对这段时间内的丢包情况进行统计。如果发现丢包，它会给发送端回一个NACK消息，NACK消息中记录了这一段时间内哪些包丢失了。发送端收到NACK后，会在之前的发送历史记录中找到丢失的包并重新发送。</p><h3 id="NACK适合使用的场景"><a href="#NACK适合使用的场景" class="headerlink" title="NACK适合使用的场景"></a>NACK适合使用的场景</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_22.webp" alt=""></p><p>当然，通过NACK重传，会产生一定的延时，该延时包括：等待发送NACK的时间（10或20ms），NACK经过网络的时延以及RTP的网络时延和重传RTP包的网络时延，即1.5RTT+10或20ms。通过这个公式我们可以知道，如果RTT时延比较大，比如200ms，那么1.5RTT就是300ms。通过前面讲述的实时传输延时指标我们可以知道，端到端实时传输的时延需要控制在500ms之内，如果仅数据的网络传输就占了300ms，那数据再经过采集、编码、解码、渲染等流程，这些处理时间加在一起很有可能就超过500ms。</p><p>所以可以得出结论，丢包重传仅适用于网络传输时延比较小的情况，如果RTT比较大时，就不适合使用丢包重传来保障网络质量了。</p><h3 id="FEC"><a href="#FEC" class="headerlink" title="FEC"></a>FEC</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_23.webp" alt=""></p><p>FEC的作用是通过冗余数据解决丢包。实际上，它就是一个异或操作。如图所示，假设传输的数据是Data1和Data2，这两个数据如果在传输的过程中没有FEC进行保护，其中一个数据丢失了，那只能通过NACK重新找回。那么，能否在传输过程中加一些冗余数据，以保证接收时，当某一个数据丢失后，不经过重传就可以将丢失的包找回来呢？这就是FEC。</p><p>在图中我们可以看到，Data1和Data2同时发送到对端，在发送时对它们做一下异或操作，即Data1的最后一位0与Data2的最后一位0异或为0，Data1的倒数第二位1与 Data2的倒数第二位1异或为0，依次类推，最后就产生了冗余数据R，同时将三个包从一端传输到另一端。传输过程中，如果Data1丢失，通过Data2和冗余包R就可以将Data1找回来。找回包的算法也是异或操作，即在接收端将Data2的每一位与冗余包中的相同位进行异或操作就算出了Data1。这就保证了不用重新请求，就将丢失包找回的作用。</p><p>而且异或具有传递性，A、B、C三个包可以同时异或得到D，如果其中任意一个包丢失，可以通过D和其它包找回丢失的包。</p><h3 id="ULPFEC"><a href="#ULPFEC" class="headerlink" title="ULPFEC"></a>ULPFEC</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_24.webp" alt=""></p><p>对于WebRTC来说，它默认使用的是ULPFEC。其原理是，将要传输的数据包先进行分组，如将三个包分为一组，然后为这一组包产生一个冗余包，如果这一组中某个包丢失了，就可以通过冗余包和其它包的异或操作将其找回。从图中第一行可以看到1和2到了，3丢了，通过R1可以找回3，第三行同样可以找回9。其缺点是，如果连续的两个包都丢失了，这种算法就失效了，比如第二行4和5丢失后，通过6和R2无法找回它们。</p><h3 id="FlexFEC"><a href="#FlexFEC" class="headerlink" title="FlexFEC"></a>FlexFEC</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_25.webp" alt=""></p><p>于是就有了改进的FlexFEC，它做了双向冗余处理，不仅横向做了冗余，而且纵向也做了冗余。</p><p>此时，当4和5同时丢失时，通过1、7和C1可以找到4，2、8和C2可以找到5，这样就可以找回连续的两个丢包。当然它也有弊端，其弊端是无法处理批量的连续丢包，例如连续丢失了10个包，FlexFEC对这种情况也无能为力。</p><p>以上就是WebRTC对于丢包的解决方法，通过“NACK+FEC”防止丢包。</p><h3 id="如何解决抖动和乱序"><a href="#如何解决抖动和乱序" class="headerlink" title="如何解决抖动和乱序"></a>如何解决抖动和乱序</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_26.webp" alt=""></p><p>下面来说说抖动和乱序。抖动的意思是，一会儿来了很多包，一会儿又一个没有，包是一波一波的来，包到达的时间很不平均；而乱序指的是先发的包后到了，后发的包先到了。</p><p>WebRTC处理抖动和乱序使用的是JitterBuffer和NetEQ。JitterBuffer用于处理视频包，NetEQ用于处理音频包。它们的原理大致相同（NetEQ更为复杂一些），都是通过一个队列（缓存区）对接收到的数据做下缓冲，然后再从队列的另一端将数据包一个个均匀的取出， 这样取出的数据就是平滑的了。</p><p>对于乱序的处理也比较好解决，如图中所示，每个RTP包进来的时候有一个序号（Sequence Number），在数据进入队列时，它会根据序号插到对应的位置上，比如图中104、107包已经到达，并且在对应的位置上，而103、105和106没来，位置就空着，等它们来了再插入对应的位置，这样就可以防止乱序，所以通过JitterBuffer和NetEQ就可以同时解决乱序和抖动了。</p><p>总结一下，NACK和FEC解决丢包问题，NACK会增加时延，FEC会占用带宽。JitterBuffer解决视频的乱序与抖动，NetEQ解决音频的乱序与抖动。</p><h3 id="网络延时产生的原因"><a href="#网络延时产生的原因" class="headerlink" title="网络延时产生的原因"></a>网络延时产生的原因</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_27.webp" alt=""></p><p>说到延时，实际上就与带宽评估有密切的关系了。延时的产生有两个原因：第一是链路问题，正常的网络上，数据包的传输都是时快时慢的；第二是发生了网络拥塞，当发生拥塞后，数据包会进行缓冲，就会造成延时，而当缓冲溢出时，就出现了丢包。</p><p>所以对于延时来说，我们需要解决的是因拥塞而造成的延时，链路问题无法解决。下面咱们就来看看WebRTC是如何防止拥塞的。</p><h2 id="准确的带宽评估方法"><a href="#准确的带宽评估方法" class="headerlink" title="准确的带宽评估方法"></a>准确的带宽评估方法</h2><h3 id="如何解决抖动和乱序-1"><a href="#如何解决抖动和乱序-1" class="headerlink" title="如何解决抖动和乱序"></a>如何解决抖动和乱序</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_28.webp" alt=""></p><p>WebRTC防止拥塞的根基是有准确的带宽评估方法。它提供了两种带宽评估方法，一种是基于丢包的带宽评估，另一种是基于延时的带宽评估。而基于延时的评估方法又分为接收端（Goog-REMB）和发送端（Goog-TCC）的带宽评估方法，目前默认采用的是Goog-TCC方法，因为其相对来说更为精准。</p><h3 id="基于丢包的带宽评估"><a href="#基于丢包的带宽评估" class="headerlink" title="基于丢包的带宽评估"></a>基于丢包的带宽评估</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_29.webp" alt=""></p><p>基于丢包的带宽评估方法比较简单，根据丢包率进行计算。实际上，正常带宽也有一定的丢包，如果丢包率&lt;2%，属于网络质量不错的正常丢包，说明带宽还没有达到上限，应该增加评估的带宽值。举个例子，比如你家里的带宽是8M，WebRTC最开始是不知道你家里的真实带宽的，它必须一点点测量，所以一开始它先给你的带宽设置一个假设值，即500K，当发现丢包率很低时，它再增加带宽的评估值，如从500K升到1兆，如果丢包率还是很低，就会加到1.5兆、2兆……，带宽评估值增加的速度是每次增加8%；如果丢包率&gt;10%，说明发生拥塞了，此时应该立即降低带宽，公式如图（loss&gt;0.1时）所示。如果丢包率&lt;10%，说明现在的带宽评估的比较准确，此时应该保持这个带宽，不增加也不减少；</p><h3 id="基于延时的带宽评估"><a href="#基于延时的带宽评估" class="headerlink" title="基于延时的带宽评估"></a>基于延时的带宽评估</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_30.webp" alt=""></p><p>基于延时的带宽评估方法比基于丢包的评估更好一些，因为它可以提前预估是否发生了拥塞。基于丢包的评估丢包率一旦超过10%就说明可能已经发生拥塞了，而网络一旦拥塞，再想恢复回原来的状态，需要花费一段时间，而这段时间就会影响音视频的服务质量。</p><p>而基于延时的带宽评估就不会产生这种情况。它的基本原理是，如果接收到的数据包的网络传输时延在持续增长，就说明网络变差了，当达到一定程度时，就要将评估的带宽值降下来，以防止发生网络拥塞。它的计算公式是根据状态机来的（状态机比较复杂，我这里就不讲了），当状态非常好时，需要增加带宽，同丢包增加带宽一样，每次增加8%；如果延时一直累加，则需要降低带宽，带宽降为原来85%，其它情况就保持当前带宽，无增无减。</p><h2 id="媒体数据与带宽的平衡"><a href="#媒体数据与带宽的平衡" class="headerlink" title="媒体数据与带宽的平衡"></a>媒体数据与带宽的平衡</h2><h3 id="媒体数据与带宽的平衡-1"><a href="#媒体数据与带宽的平衡-1" class="headerlink" title="媒体数据与带宽的平衡"></a>媒体数据与带宽的平衡</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_31.webp" alt=""></p><p>当带宽评估准确之后再进行控制就非常容易了。接下来，我们看一下WebRTC如何平衡媒体数据与带宽。</p><p>带宽评估方法和网络质量的提升在前面我已经介绍了。在有限的带宽下，如何才能提供更好的音视频服务质量，是人们一直孜孜不倦追求的目标。因此在同等条件下，可以将数据压缩的更小，一直是解决服务质量的一种关键方法。目前最常用的视频编码器还是H.264，不过新的编码器已经有了很大突破VP9/H265、AV1/H266提供了更高的压缩率，这使得我们在网络条件有限的情况下，可以传输更多的数据从而保障更好的服务质量。</p><p>另一方面，在带宽相同且码流无法压缩的情况下，还可以采用动态码率。通常，在使用动态码率时，我们可以直接从产品上看出来，你会发现视频一会儿清晰，一会儿模糊。即在带宽小时，编码器压缩码流，此时视频变得模糊；带宽大时，编码器放大了码流，所以视频变得清晰。以上就是通过减少数据量的方法来保障实时通信质量的。</p><h3 id="Simulcast与SVC"><a href="#Simulcast与SVC" class="headerlink" title="Simulcast与SVC"></a>Simulcast与SVC</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_32.png" alt=""></p><p>除此之外，还可以通过Simulcast或SVC解决质量问题。Simulcast和SVC解决问题的思路是类似的，它们会在发送端增大码流的发送，将数据先传给服务端，然后由服务端根据接收端带宽的不同，选择合适的码流下发。对于网络较差的用户，传输清晰度低的码流，对于网络较好的用户，传输高清晰度的码流。所以这两种技术对于发送方的带宽和质量有非常高的要求。</p><p>SVC与Simulcast最大的区别：SVC上传的是一路码流，但这一路码流是由多层构成的。服务端会按照不同接收端的带宽大小，选择传输不同的层。如上图所示，手机端带宽小，就传输小的一层数据，PC端带宽大，就将所有层全部传输过去；而Simulcast上传的是多路流，一般分为小、中、大三路。对手机端传输小的一路，对PC端传输最大的一路。Simulcast的好处在于，每一路流都是独立的，所以可以对每一路流使用硬件编解码器，而 SVC的分层方式目前没有硬件支持，所以无法通过硬件加速。</p><h3 id="流控"><a href="#流控" class="headerlink" title="流控"></a>流控</h3><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_33.png" alt=""></p><p>当带宽评估准确后，如果发送的的码流还是大于带宽大小，此时就需要通过流控来进行控制了。流控的作用是当输出码流大于带宽时，降低发送码率，以防止发生拥塞。当然它会导致时延的增加。实际上，对于流控来说，它需要控制两个点：第一个点是Pacer，降低发送码率。当然仅降低发送码率还不够，因为如果编码器仍然输出大量码流给Pacer，那么Pacer 的缓冲区迟早会被撑爆。所以在控制Pacer让它减少发送码率的同时，一定要降低音视频的编码器的输出码率，从而保持平衡，进而使数据平缓下行。</p><p>正如我前面所说的，流控虽然防止了网络拥塞的发生，但会增加一些延时，增加的延时最终会反应到实时通信的总指标里，总的延时必须控制在500ms以内。比如以前端到端时延是200ms，由于带宽不足，时延增加到300ms、400ms都是可以的，但一定不要超过500ms。</p><p>此外，对于编码器的输出码流来说，如果流控通过直接降低码流仍然不能与带宽适配时，还可以通过降低分辨率的方式来降低码流。总之，在带宽不足时，要想尽办法减少数据量。实在不行，也可以关掉视频只保留音频来保障网络的畅通。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_34.png" alt=""></p><p>总结一下，对于服务质量保障，首先提高网络质量，NACK和FEC解决丢包问题，JitterBuffer解决视频的乱序与抖动，NetEQ解决音频的乱序与抖动；带宽评估通过Goog-REMB和Goog-TCC，还有丢包的带宽评估；为了保障实时性，需要选择更优质的线路，比如客户端与服务端通信的时候选择更好的路线节点，保证云端网络带宽等等；从业务上，减少数据量可以用AV1、SVC、Simulcast、动态码率，减少业务；在防拥塞上，通过Pacer进行流控，只要能控制在500ms之内，适当增加时延也是可以接收的。</p><p>以上就是本次分享的全部内容，谢谢！</p><h2 id="Q-amp-A-部分"><a href="#Q-amp-A-部分" class="headerlink" title="Q&amp;A (部分)"></a>Q&amp;A (部分)</h2><p><strong>1. 路径的选择是WebRTC内部自动选择的吗？</strong></p><p>是自动选择的。WebRTC会自动判断通信的双方是否在同一个局域网内，如果是就直接在局域网内建立连接；如果不是，会通过STUN协议获取各自的外网地址，然后进行NAT穿越；如果还不成功的话，才会选择TURN服务进行数据中转。</p><p><strong>2. WebRTC网络传输质量衡量指标有什么？</strong><br>衡量任何一个实时传输系统时，首要看它的时延是否达到500ms以内。其实500ms对于实时通信而言，也是比较苛刻的标准了，因为网络的变化是非常大的， 所以要实现这个指标其实难度也是蛮大的。其次是丢包率，这是非常关键的指标，刚才说到2%的丢包率代表网络比较好；小于10%，对于WebRTC来说，代表目前的带宽是准确的；超过10%则代表发生了拥塞。有些厂商说它的产品可以抗xx%的丢包，这样的前提是不认为丢包是一个指标，但在真网络中，当路由的缓冲被撑爆后，必然会出现大量丢包，如果不把丢包当作指标的话，就缺少了一种判断网络拥塞发生的条件，这显然是不合理的。</p><p><strong>3. 视频JitterBuffer怎么具体控制平滑的？</strong><br>其实JitterBuffer平滑处理的难度并不像我们想像的那样复杂，之所以大家认为它复杂，可能是因为一些额外的因素，如还要处理音视频同步等问题。对于平滑处理，我们完全可以自己通过一个Buffer来实现。Buffer可以是动态大小或固定大小。为了简化，我们假设它是固定大小，比如定义一个可以存放 100 个元素的数组，在数组的一头每隔 10 毫秒取一个包，这就是一个最简单的平滑处理。当然更好的方式是可以根据网络的变化让这个平滑数组的大小也动态变化，这样就更高级一些。当然，如果Buffer是动态变化的，那在计算平滑数组的动态大小时，会稍难一些。</p><p><strong>4. WebRTC要和SIP客户端通讯有什么好的方案？</strong><br>一般与SIP通信最好借助流媒体服务器比如Janus，它既支持SIP协议也能支持WebRTC客户端。这样SIP终端就可以将数据传输流媒体服务器，然后再转发给WebRTC终端了，同理WebRTC终端也可以通过流媒体服务器与SIP终端通信了。</p><p><strong>5. FEC和NACK默认是不是都要开启？</strong><br>是的。对于WebRTC来说，FEC和NACK都是开启的，也可以控制它们的开关。</p><p><strong>6. 能说下为什么TCC比REMB准确吗？</strong><br>TCC和REMB主要有两个区别。第一是计算的端不同，REMB是在接收端计算的，接收端计算后再将结果返回给发送端进行控制，而在回传结果时，可能网络又发生了新的变化，这就造成了REMB的及时性不够；TCC是将所有数据都交给发送端做计算和控制，因此及时性和准确度会更高。第二是滤波器不同，REMB是卡尔曼滤波器（Kalman），TCC是最小二乘法滤波器（Trend line）。最小二乘法滤波器在网络延时评估这方面比卡尔曼滤波器效果更好一些。</p><p><strong>7. 在内网环境下p2p想让延时尽可能小，可以做哪些工作？实验室环境最小延时可以达到100ms以下吗？</strong><br>如果在同一个局域网内，实际只有几十毫秒的延迟。有同学可能会疑惑，有的产品在同一局域网内延迟非常小，为什么用WebRTC反而延迟增大了？这就是因为WebRTC为保障网络质量，在内部通过多种机制，各种缓冲，来做到的。所以它必然会产生一定的延迟，也就是拿延迟换质量。而在局域网内，网络基本没有延时，不丢包、不抖动、不乱序。这时什么策略都不采用，网络的传输才是最快的，因此在内网通信时，WebRTC的实时性一定不如什么策略都不加的产品好。</p><p><strong>8. ULPFEC和FLEXFEC区别是？</strong><br>ULPFEC只能进行单向冗余处理，而FLEXFEC可以进行双向冗余处理，即可以横向分组还可以纵向分组做冗余，所以它的抗丢包性要比ULPFEC好，同时占的带宽也比ULPFEC多。</p><p><strong>9. 可靠性这块，UDP上的WebRTC做ack是自己封装了seq吗？然后，一样需要ack重传的话，跟TCP SACK有什么区别呢？</strong><br>WebRTC使用的是RTP协议传输数据。RTP协议中有seq字段。此外，WebRTC用的NACK与TCP的ACK机制不同。TCP每一块数据都需要通过ACK进行确认，如果没收到ACK就重发，直到成功收到ACK或断连；而NACK允许丢包，当重传多次不行时，就不传了。且而即使重传了数据包，在接收端发现它已经过期时，也会将其丢掉。</p><p><strong>10. WebRTC后面会用QUIC协议吗？</strong><br>这个问题争论较大。WebRTC也在一直在尝试使用QUIC协议，从我的角度来看，QUIC协议最主要的是解决Http3，Http3解决的是TCP的问题，就要保证数据的可靠性，那么实时性就会受到影响，什么时候QUIC如果可以解决好实时性问题就可以用，反之则不能。</p><p>从我的角度看，一种协议最好只解决一件事儿，很难通过一套协议解决所有问题。</p><p><strong>阅读推荐</strong></p><p><img data-src="https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_35.webp" alt=""></p><p>《WebRTC音视频实时互动技术 — 原理、实战与源码分析》— 李超</p><p>书籍深入浅出的对WebRTC进行了系统讲解，既有原理，又有实战，从WebRTC是如何实现实时音视频通信的，到如何应用WebRTC库实现音视频通信，再到WebRTC源码的剖析，逐步展开讲解。此外，本书对WebRTC的传输系统进行了重点分析，相信读者通过本书可以一窥WebRTC传输的奥秘。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;作者 | 李超&lt;br&gt;整理 | LiveVideoStack&lt;/p&gt;
&lt;p&gt;非常高兴和大家一同探讨WebRTC传输是如何保证音视频服务质量的。&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&quot;https://cdn.avdancedu.com/image/article/WebRTC_QoS/webrtc_1.webp&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;本次分享我将从四个方面向大家介绍一下WebRTC传输是如何保证音视频服务质量的。第一，实时通信的目标。我们首先需要确定实时通信的目标，才能够知道要将实时通信做成怎样的系统、保证怎样的实时性；第二，WebRTC如何保障数据传输的实时性；第三，进行实时传输时，想要满足实时性，网络与服务质量之间可能存在的矛盾；最后，就是WebRTC如何解决网络与服务质量之间的矛盾。&lt;/p&gt;
    
    </summary>
    
    
      <category term="WebRTC" scheme="https://blog.avdancedu.com/categories/WebRTC/"/>
    
    
      <category term="WebRTC" scheme="https://blog.avdancedu.com/tags/WebRTC/"/>
    
  </entry>
  
  <entry>
    <title>GDB与LLDB</title>
    <link href="https://blog.avdancedu.com/2ffb45c8/"/>
    <id>https://blog.avdancedu.com/2ffb45c8/</id>
    <published>2022-11-19T06:52:00.000Z</published>
    <updated>2022-11-20T05:10:05.569Z</updated>
    
    <content type="html"><![CDATA[<h2 id="GDB与LLDB命令对照表"><a href="#GDB与LLDB命令对照表" class="headerlink" title="GDB与LLDB命令对照表"></a>GDB与LLDB命令对照表</h2><hr><p><a href="https://lldb.llvm.org/lldb-gdb.html" target="_blank" rel="noopener">GDB 与 LLDB 命令对照表1</a><br><a href="https://developer.apple.com/library/content/documentation/IDEs/Conceptual/gdb_to_lldb_transition_guide/document/lldb-command-examples.html" target="_blank" rel="noopener">GDB 与 LLDB 命令对照表2</a></p><hr><a id="more"></a><h2 id="设置观察点"><a href="#设置观察点" class="headerlink" title="设置观察点"></a>设置观察点</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wa s v 变量名</span><br><span class="line">或 watchpoint set variable 变量名</span><br></pre></td></tr></table></figure><ul><li>观察点必须是独立的原始变量，而不能是类变量或结构体变量。</li></ul><h2 id="目前-LLDB-无法打印宏信息"><a href="#目前-LLDB-无法打印宏信息" class="headerlink" title="目前 LLDB 无法打印宏信息"></a>目前 LLDB 无法打印宏信息</h2><h2 id="查看内存内容"><a href="#查看内存内容" class="headerlink" title="查看内存内容"></a>查看内存内容</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x -s4 -fx -c4 0xbffff3c0</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;GDB与LLDB命令对照表&quot;&gt;&lt;a href=&quot;#GDB与LLDB命令对照表&quot; class=&quot;headerlink&quot; title=&quot;GDB与LLDB命令对照表&quot;&gt;&lt;/a&gt;GDB与LLDB命令对照表&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;&lt;a href=&quot;https://lldb.llvm.org/lldb-gdb.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GDB 与 LLDB 命令对照表1&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;https://developer.apple.com/library/content/documentation/IDEs/Conceptual/gdb_to_lldb_transition_guide/document/lldb-command-examples.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GDB 与 LLDB 命令对照表2&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
    
      <category term="常用工具" scheme="https://blog.avdancedu.com/categories/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="GDB" scheme="https://blog.avdancedu.com/tags/GDB/"/>
    
      <category term="LLDB" scheme="https://blog.avdancedu.com/tags/LLDB/"/>
    
  </entry>
  
  <entry>
    <title>SDL事件处理</title>
    <link href="https://blog.avdancedu.com/a0ec02a7/"/>
    <id>https://blog.avdancedu.com/a0ec02a7/</id>
    <published>2022-11-19T06:52:00.000Z</published>
    <updated>2022-11-20T04:07:08.621Z</updated>
    
    <content type="html"><![CDATA[<p>前面我为大家介绍了 SDL 的三个主题：</p><ul><li><a href="http://www.avdancedu.com/56ef4bcb" target="_blank" rel="noopener">SDL 入门</a></li><li><a href="http://www.avdancedu.com/287ad9ab" target="_blank" rel="noopener">SDL窗口渲染</a></li><li><a href="http://www.avdancedu.com/24ee78a8" target="_blank" rel="noopener">SDL基本图形绘制</a></li></ul><p>今天我为大家介绍一下SDL的事件处理。这里所指的事件处理就是我们通常所说的，键盘事件，鼠标事件，窗口事件等。</p><p>SDL对这些事件都做了封装，提供了统一的API，下面我们就来详细的看一下。</p><a id="more"></a><h2 id="SDL中的事件处理"><a href="#SDL中的事件处理" class="headerlink" title="SDL中的事件处理"></a>SDL中的事件处理</h2><p>要想了解 SDL 的事件处理，我们必须要知道的一个原理是，SDL将所有事件都存放在一个队列中。所有对事件的操作，其实就是对队列的操作。了解了这个原理后，我们再来说SDL提供的 API 就很容易理解了。</p><ul><li>SDL_PollEvent: 将队列头中的事件抛出来。</li><li>SDL_WaitEvent: 当队列中有事件时，抛出事件。否则处于阻塞状态，释放 CPU。</li><li>SDL_WaitEventTimeout: 与SDL_WaitEvent的区别时，当到达超时时间后，退出阻塞状态。</li><li>SDL_PeekEvent: 从队列中取出事件，但该事件不从队列中删除。</li><li>SDL_PushEvent: 向队列中插入事件。</li></ul><p>SDL只提供了这样几个简单的API，下面们来介绍几个常见的事件：</p><ul><li>SDL_WindowEvent : Window窗口相关的事件。</li><li>SDL_KeyboardEvent : 键盘相关的事件。</li><li>SDL_MouseMotionEvent : 鼠标移动相关的事件。</li><li>SDL_QuitEvent : 退出事件。</li><li>SDL_UserEvent : 用户自定义事件。</li></ul><p>关于事件更加详的信息可以到 <a href="https://wiki.libsdl.org/SDL_Event" target="_blank" rel="noopener">SDL Wiki</a> 上进行查询。现在我们来看一个使用的例子吧。</p><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>在我们之前文章的例子中，大家已经发现一个问题，那就是窗口只显示了 3 秒钟，之后就自动消失了。</p><p>有的同学可以会通过修改代码最后面的 SDL_Delay 函数，增加它的等待时间让窗口多活一段时间。</p><p>但这样的体验实在是太糟糕了。有没有一种好的办法可以解决这个问题呢？能不能窗口一直显示，直到检测到用户按了<code>ctrl+c</code> 或 使用鼠标点击关闭按钮后才关闭呢？</p><p>当然是可以的。我们只需要在之前的程序的末尾增加下面这段代码即可。它会一直检测用户是否按下了退出按钮。如果检测到了，则直接退出，否则保持显示状态。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">while(!quit)&#123;</span><br><span class="line">    SDL_Event event;</span><br><span class="line">    while(SDL_PollEvent(&amp;event))&#123;</span><br><span class="line">        switch(event.type)&#123;</span><br><span class="line">            case SDL_QUIT:</span><br><span class="line">               quit &#x3D; 1;</span><br><span class="line">               break;</span><br><span class="line">            default:</span><br><span class="line">               SDL_Log(&quot;.&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="SDL-PollEvent-与-SDL-WaitEvent"><a href="#SDL-PollEvent-与-SDL-WaitEvent" class="headerlink" title="SDL_PollEvent 与 SDL_WaitEvent"></a>SDL_PollEvent 与 SDL_WaitEvent</h2><p>增加了上面的代码，我们的实验程序似乎也显的很正规了。但有一个问题不知你发现没有<br>?当我们打开任务管理器时，发现我们的程序居然占了 100% 的 CPU。My GOD!这个的结果是决对不能接受的。</p><p>是什么原因造成的呢？我们来仔细看一下我们增加的代码吧。它由两层 while 循环组成，最里面的while循环的意思是，当队列中一直能取出事件，那就让他一直做下去，直到事件队列为空。外面的while循环的意思是，当队列为空的时候，重新执行内部的while循环。</p><p>也就是说，这段代码一直在工作，从不休息。所以导致cpu占到了100%。即然找到了问题的原因，我们就好处理了，只要在外层循环的最后 delay一下，让CPU休息一下就好了。</p><p>当然，SDL还为我们提供了 SDL_WaitEvent方法，使用这个API,你的CPU就不会跑到 100%了，因为当它发现队列为空时，它会阻塞在那里，并将CPU释放掉。</p><p>即然有 SDL_WaitEvent了，为什么还要有SDL_PollEvent呢？这主要是由于使用的场景不同。对于游戏来说，它要求事件的实时处理； 而对于一些其它实时性不高的case来说，则可以使用 SDL_WaitEvent了。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>到此，本文的内容就介绍完了。在本文中主要介绍了SDL是如何处理事件的，SDL为我们提供了非常简单的API，这大大减少了我们的开发成本。</p><p>另外，我在文章的最后，介绍了SDL_PollEvent 与 SDL_WaitEvent两个 API的区别。这也是使用 SDL 事件处理中最容易引起困惑的地方。</p><p>希望本文能对您有所帮助，谢谢！</p><h2 id="推荐阅读："><a href="#推荐阅读：" class="headerlink" title="推荐阅读："></a>推荐阅读：</h2><ul><li><a href="http://www.avdancedu.com/56ef4bcb" target="_blank" rel="noopener">SDL 入门</a></li><li><a href="http://www.avdancedu.com/287ad9ab" target="_blank" rel="noopener">SDL窗口渲染</a></li><li><a href="http://www.avdancedu.com/24ee78a8" target="_blank" rel="noopener">SDL基本图形绘制</a></li><li><a href="http://www.avdancedu.com/a0ec02a7" target="_blank" rel="noopener">SDL事件处事</a></li><li><a href="http://www.avdancedu.com/67189745" target="_blank" rel="noopener">彻底理解SDL纹理</a></li><li><a href="http://www.avdancedu.com/a6aca2fe" target="_blank" rel="noopener">SDL孙悟空与多线程</a></li><li><a href="http://www.avdancedu.com/f94132a0" target="_blank" rel="noopener">PCM音频播放器的实现</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前面我为大家介绍了 SDL 的三个主题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/56ef4bcb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL 入门&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/287ad9ab&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL窗口渲染&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/24ee78a8&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL基本图形绘制&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;今天我为大家介绍一下SDL的事件处理。这里所指的事件处理就是我们通常所说的，键盘事件，鼠标事件，窗口事件等。&lt;/p&gt;
&lt;p&gt;SDL对这些事件都做了封装，提供了统一的API，下面我们就来详细的看一下。&lt;/p&gt;
    
    </summary>
    
    
      <category term="视频渲染" scheme="https://blog.avdancedu.com/categories/%E8%A7%86%E9%A2%91%E6%B8%B2%E6%9F%93/"/>
    
    
      <category term="SDL" scheme="https://blog.avdancedu.com/tags/SDL/"/>
    
  </entry>
  
  <entry>
    <title>SDL多线程</title>
    <link href="https://blog.avdancedu.com/a6aca2fe/"/>
    <id>https://blog.avdancedu.com/a6aca2fe/</id>
    <published>2022-11-19T06:52:00.000Z</published>
    <updated>2022-11-20T05:06:29.173Z</updated>
    
    <content type="html"><![CDATA[<p>今天将向大家介绍一下SDL中的多线程的使用。通过下面对SDL 线程与锁相关的API介绍，你会发现，它与 Linux, Windows相关的API几乎是一模一样的。从这里可以推断出，其实SDL对于多线程的处理只是为大家提供了一套统一接口，并没有做其它太多的工作。</p><p>这是我们介绍 SDL 的第六篇文章。有兴趣的同学可以通过下面的链接查看其它几篇文章。</p><ul><li><a href="http://www.avdancedu.com/56ef4bcb" target="_blank" rel="noopener">SDL 入门</a></li><li><a href="http://www.avdancedu.com/287ad9ab" target="_blank" rel="noopener">SDL窗口渲染</a></li><li><a href="http://www.avdancedu.com/24ee78a8" target="_blank" rel="noopener">SDL基本图形绘制</a></li><li><a href="http://www.avdancedu.com/a0ec02a7" target="_blank" rel="noopener">SDL事件处事</a></li><li><a href="http://www.avdancedu.com/67189745" target="_blank" rel="noopener">彻底理解SDL纹理</a></li><li><a href="http://www.avdancedu.com/a6aca2fe" target="_blank" rel="noopener">SDL孙悟空与多线程</a></li><li><a href="http://www.avdancedu.com/f94132a0" target="_blank" rel="noopener">PCM音频播放器的实现</a></li><li><a href="https://coding.imooc.com/class/279.html" target="_blank" rel="noopener">ffmpeg精讲</a></li></ul><a id="more"></a><h2 id="为啥要用多线程？"><a href="#为啥要用多线程？" class="headerlink" title="为啥要用多线程？"></a>为啥要用多线程？</h2><p>我觉得这个小节的标题就是一个废话。不过为了文章的完整性，还是简单的说一说吧。多线程（多进程）是啥意思呢？做个不恰当的比喻，可以把CPU看成是孙悟空，它有一个能耐，从后脑揪几个猴毛就可以变出许多的小猴子。</p><p>多线程（多进程）就是这些小猴子。当干一件比较复杂的事儿时，可以孙悟空一个人干，这样自己比较累。它还有一种选择就是揪几根猴毛，让小猴子们一起帮着干。这样一件复杂的事件，分给许多猴子干，每只猴只干一部分，事情很快就被做完了，这样岂不是比一个人干要强的多？</p><p>当然，有好处也有坏外。猴子多了就需要管理，如果管理不好，就会闹翻天。比如，只有一块肉，该给哪个猴子吃呢？这真是一个另人头痛的问题。</p><p>实际上整个操作系统的演进，就是一部管理学的演进。如何才能让CPU，内存，磁盘I/O，各种设备之间高效的工作，一直是操作系统追求的目标。当然，这话有点扯远了。</p><p>今天我们要讲的就是多线程（多进程）之间该如何高效的工作。要想让多线程之间高效工作，就要给它们之间立点规矩，大家都要遵守的规矩。</p><h2 id="线程互斥与同步"><a href="#线程互斥与同步" class="headerlink" title="线程互斥与同步"></a>线程互斥与同步</h2><p>当僧多粥少时，就引入了互斥的概念。再举个我们生活中的例子吧，比如有一大家族住在同一个大屋子里，却只有一个厕所。早上起来大家都想去厕所，这时有谁先抢到了厕所，其它人就只能等他出来后再进入了，这就是<strong>互斥</strong>。</p><p>当仅有一份资源，大家都需要时，这就产生了管理问题。解决的办法就是通过互斥方法来解决。这种情况是在做多线程处理时要尽量避免的；如果资源足够呢？那当然是平均分配，人人有份了。这中情况是多线路程最希望的。</p><p>除了互斥之外，有些情况还需要更精细化的管理，比如说<strong>同步</strong>。例如车间里的流水线，每个人负责一块，每一块都是半成品，第一个人完成之后交给第二个人做下一步，而后面的人又必须依赖于前而人的结果，依次类推，最后一个人才能完成最终的产品。这就是线程间的精细化管理<strong>同步</strong>。</p><p>要想实现互斥和同步，就需要一种机制。在操作系统上提供了锁的概念来达到互斥与同步。</p><h2 id="锁的种类"><a href="#锁的种类" class="headerlink" title="锁的种类"></a>锁的种类</h2><p>在操作系统上有很种锁，有读写锁、自旋锁、可重入锁等。下面我简单的介绍一下它们之间的不同。</p><p>读写锁: 分为读锁与写锁。所谓读锁就是被访问的资源只要你不改变它的值，你就可以访问，但如果你想改变它，那么就需要等所有读它的线程都释放了它们的锁后，才可以进行修改；写锁是同一时刻只能有一个人访问，当资源被加锁后，其它人只能等待。</p><p>自旋锁: 偿试着给访问资源加锁，如果此时被访问资源已经上锁了，那就一直不停的偿试，直到加锁成功为止。由于它会非常消耗CPU资源，所以一般只锁今资源非常短的情况下才能使用它。</p><p>可重入锁: 同一个线程对被访问资源可以一直加锁。但如果被访问资源已经上锁了，那么其它线程则无法对其加锁。</p><p>锁是解决互斥的一种好办法，但同样有利必有弊。如果使用不善就会出现死锁。</p><h2 id="死锁问题"><a href="#死锁问题" class="headerlink" title="死锁问题"></a>死锁问题</h2><p>死锁顾名思意，就是打不开的锁。它是怎么产生的呢？举个例子，两个人需要一起完成一件事儿，A说他要等B做完了，他才能开始；而B说它要等A做完了，它才能开使。于时他们在相互等待中老去。</p><p>看类很简单的问题，但这类事情经常在我们的工作中出现。而在我们开发的多线程程序中更是频繁出现。别说人没遇到过哟！</p><p>如何解决？那就是考验你的管理能力了。共实很多情况是出现了死锁我们自己却不知道，否则的话，凭我们的聪名才智怎么能让他们一直锁在那儿呢。</p><h2 id="SDL多线程"><a href="#SDL多线程" class="headerlink" title="SDL多线程"></a>SDL多线程</h2><p>上面介绍了一大堆的理论，现在来看看 SDL 为我们都提供了那些API吧。</p><ul><li><p>创建线程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SDL_Thread* SDL_CreateThread(SDL_ThreadFunction fn,</span><br><span class="line">                           const char*        name,</span><br><span class="line">                           void*              data)</span><br></pre></td></tr></table></figure><ul><li>fn: 线程要运行的函数。</li><li>name: 线程名。</li><li>data: 函数参数。</li></ul></li><li><p>等待线程</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">void SDL_WaitThread(SDL_Thread* thread,</span><br><span class="line">                  int*        status)</span><br></pre></td></tr></table></figure><p>等待线程结束。</p></li><li><p>创建互斥量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SDL_mutex* SDL_CreateMutex(void)</span><br></pre></td></tr></table></figure><p>也就是创建一个稀有资源，这样大家就去抢这个资源。从而达到为真正资源加锁的目的。</p></li></ul><ul><li><p>销毁互斥量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void SDL_DestroyMutex(SDL_mutex* mutex)</span><br></pre></td></tr></table></figure></li><li><p>加锁</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int SDL_LockMutex(SDL_mutex* mutex)</span><br></pre></td></tr></table></figure></li><li><p>解锁</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int SDL_UnlockMutex(SDL_mutex* mutex)</span><br></pre></td></tr></table></figure></li></ul><p>常用的与线程和锁相关的 API 就以上几个，是不是非常简单？下面我们来看一个简单的例子吧。</p><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>下面这个例子是在主线程中创建了一个子线程。然后主线程就一直等待子线程结束。等子线程结束后，主线程也随之结束。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &quot;SDL.h&quot;</span><br><span class="line"></span><br><span class="line">&#x2F;* Very simple thread - counts 0 to 9 delaying 50ms between increments *&#x2F;</span><br><span class="line">static int TestThread(void *ptr)</span><br><span class="line">&#123;</span><br><span class="line">    int cnt;</span><br><span class="line"></span><br><span class="line">    for (cnt &#x3D; 0; cnt &lt; 10; ++cnt) &#123;</span><br><span class="line">        printf(&quot;\nThread counter: %d&quot;, cnt);</span><br><span class="line">        SDL_Delay(50);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return cnt;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main(int argc, char *argv[])</span><br><span class="line">&#123;</span><br><span class="line">    SDL_Thread *thread;</span><br><span class="line">    int         threadReturnValue;</span><br><span class="line"></span><br><span class="line">    printf(&quot;\nSimple SDL_CreateThread test:&quot;);</span><br><span class="line"></span><br><span class="line">    &#x2F;* Simply create a thread *&#x2F;</span><br><span class="line">    thread &#x3D; SDL_CreateThread(TestThread, &quot;TestThread&quot;, (void *)NULL);</span><br><span class="line"></span><br><span class="line">    if (NULL &#x3D;&#x3D; thread) &#123;</span><br><span class="line">        printf(&quot;\nSDL_CreateThread failed: %s\n&quot;, SDL_GetError());</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">        SDL_WaitThread(thread, &amp;threadReturnValue);</span><br><span class="line">        printf(&quot;\nThread returned value: %d&quot;, threadReturnValue);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文主要介绍了两方面的内容。一是对多线程理论做了一下简单的介绍；二是介绍了SDL中与线程和锁相关的API。</p><p>最后通过一个例子显示了如何使用 SDL 中的多线程。</p><p>希望本文能对你有所帮助，谢谢！</p><h2 id="隆重推荐"><a href="#隆重推荐" class="headerlink" title="隆重推荐"></a>隆重推荐</h2><ul><li><a href="http://www.avdancedu.com/56ef4bcb" target="_blank" rel="noopener">SDL 入门</a></li><li><a href="http://www.avdancedu.com/287ad9ab" target="_blank" rel="noopener">SDL窗口渲染</a></li><li><a href="http://www.avdancedu.com/24ee78a8" target="_blank" rel="noopener">SDL基本图形绘制</a></li><li><a href="http://www.avdancedu.com/a0ec02a7" target="_blank" rel="noopener">SDL事件处事</a></li><li><a href="http://www.avdancedu.com/67189745" target="_blank" rel="noopener">彻底理解SDL纹理</a></li><li><a href="http://www.avdancedu.com/a6aca2fe" target="_blank" rel="noopener">SDL孙悟空与多线程</a></li><li><a href="http://www.avdancedu.com/f94132a0" target="_blank" rel="noopener">PCM音频播放器的实现</a></li><li><a href="https://coding.imooc.com/class/279.html" target="_blank" rel="noopener">ffmpeg精讲</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天将向大家介绍一下SDL中的多线程的使用。通过下面对SDL 线程与锁相关的API介绍，你会发现，它与 Linux, Windows相关的API几乎是一模一样的。从这里可以推断出，其实SDL对于多线程的处理只是为大家提供了一套统一接口，并没有做其它太多的工作。&lt;/p&gt;
&lt;p&gt;这是我们介绍 SDL 的第六篇文章。有兴趣的同学可以通过下面的链接查看其它几篇文章。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/56ef4bcb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL 入门&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/287ad9ab&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL窗口渲染&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/24ee78a8&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL基本图形绘制&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/a0ec02a7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL事件处事&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/67189745&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;彻底理解SDL纹理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/a6aca2fe&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL孙悟空与多线程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/f94132a0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;PCM音频播放器的实现&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://coding.imooc.com/class/279.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ffmpeg精讲&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="视频渲染" scheme="https://blog.avdancedu.com/categories/%E8%A7%86%E9%A2%91%E6%B8%B2%E6%9F%93/"/>
    
    
      <category term="SDL" scheme="https://blog.avdancedu.com/tags/SDL/"/>
    
      <category term="多线程" scheme="https://blog.avdancedu.com/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>SDL入门</title>
    <link href="https://blog.avdancedu.com/56ef4bcb/"/>
    <id>https://blog.avdancedu.com/56ef4bcb/</id>
    <published>2022-11-19T06:52:00.000Z</published>
    <updated>2022-11-20T05:07:01.481Z</updated>
    
    <content type="html"><![CDATA[<p>推荐阅读：</p><ul><li><a href="http://www.avdancedu.com/56ef4bcb" target="_blank" rel="noopener">SDL 入门</a></li><li><a href="http://www.avdancedu.com/287ad9ab" target="_blank" rel="noopener">SDL窗口渲染</a></li><li><a href="http://www.avdancedu.com/24ee78a8" target="_blank" rel="noopener">SDL基本图形绘制</a></li><li><a href="http://www.avdancedu.com/a0ec02a7" target="_blank" rel="noopener">SDL事件处事</a></li><li><a href="http://www.avdancedu.com/67189745" target="_blank" rel="noopener">彻底理解SDL纹理</a></li><li><a href="http://www.avdancedu.com/a6aca2fe" target="_blank" rel="noopener">SDL孙悟空与多线程</a></li><li><a href="http://www.avdancedu.com/f94132a0" target="_blank" rel="noopener">PCM音频播放器的实现</a></li></ul><p>SDL是 “Simple DirectMedia Layer”的缩写，它是一个开源的项目。其主要用于游戏开发中的多媒体处理，如视频渲染，音频播放，鼠标/键盘控制等操作。</p><p>并且它是一个跨平台的多媒体库。也就是说它对外接供了一套统一的接口，但在内部，它会根据不同平台调用不同的底层 API库。如在 Linux 系统下，它会使用 opengl 做渲染，而在 Window 下它会调用 D3D API进行渲染。</p><p>我之所以要介绍它，主要是因为我要在开发的多媒体播放器中使用它。</p><a id="more"></a><h2 id="SDL的编译与安装"><a href="#SDL的编译与安装" class="headerlink" title="SDL的编译与安装"></a>SDL的编译与安装</h2><p>目前 SDL 分为 SDL1 和 SDL2 两个主要版本。这两上版本差异非常大，无法相兼容。不过SDL1已经基本过时，主流产品都在使用的 SDL2，所以我们这里也使用SDL2作为例子进行讲解。</p><ul><li><p><a href="https://www.libsdl.org/download-2.0.php" target="_blank" rel="noopener">下载SDL源码</a>（<strong>可能需要翻墙才行</strong>）</p></li><li><p>编译与安装</p><ul><li><p>生成SDL的Makefile</p><pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">configure --prefix&#x3D;&#x2F;usr&#x2F;local</span><br></pre></td></tr></table></figure></code></pre></li><li><p>编译并安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo make &amp;&amp; make install</span><br></pre></td></tr></table></figure></li></ul></li></ul><h2 id="使用-SDL2-的其本流程"><a href="#使用-SDL2-的其本流程" class="headerlink" title="使用 SDL2 的其本流程"></a>使用 SDL2 的其本流程</h2><p>当我们通过源码编译并安装好 SDL2后，在我们的程序中使用 SDL2 就非常简单了，只要按照下面的步骤就可以绘制出一个窗口来。</p><ul><li><p>添加SDL头文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;SDL.h&gt;</span><br></pre></td></tr></table></figure></li><li><p>初始化SDL</p></li><li><p>创建窗口</p></li><li><p>销毁窗口</p></li><li><p>退出SDL</p></li></ul><p>当然，上面的步骤只是一个最基本的使用 SDL 的步骤，如果想了解更多的 SDL 的内容，静请期待我后面的文章。</p><h2 id="API详细介绍"><a href="#API详细介绍" class="headerlink" title="API详细介绍"></a>API详细介绍</h2><p>下面我们详细介绍一下上面用到的几个SDL API。</p><ul><li><p>初始化 SDL</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int SDL_Init(Uint32 flags)</span><br></pre></td></tr></table></figure><table><thead><tr><th>flags</th><th>说明</th></tr></thead><tbody><tr><td>SDL_INIT_TIMER</td><td>timer subsystem</td></tr><tr><td>SDL_INIT_AUDIO</td><td>audio subsystem</td></tr><tr><td>SDL_INIT_VIDEO</td><td>video subsystem; automatically initializes the events subsystem</td></tr><tr><td>SDL_INIT_EVENTS</td><td>events subsystem</td></tr><tr><td>SDL_INIT_EVERYTHING</td><td>all of the above subsystems</td></tr></tbody></table><p>返回值：0, 成功。非0, 失败。</p></li><li><p>退出 SDL</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void SDL_Quit(void)</span><br></pre></td></tr></table></figure></li><li><p>打印日志</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void SDL_Log(const char* fmt, ...)</span><br></pre></td></tr></table></figure><p>它与 C 语言中的 printf 格式相同。</p></li><li><p>创建窗口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">SDL_Window* SDL_CreateWindow(const char* title,</span><br><span class="line">                           int         x,</span><br><span class="line">                           int         y,</span><br><span class="line">                           int         w,</span><br><span class="line">                           int         h,</span><br><span class="line">                           Uint32      flags)</span><br></pre></td></tr></table></figure><ul><li><p>title：窗口标题</p></li><li><p>x,y,w,h：窗口坐标</p></li><li><p>flag</p><table><thead><tr><th>flags</th><th>说明</th></tr></thead><tbody><tr><td>SDL_WINDOW_FULLSCREEN</td><td>fullscreen window</td></tr><tr><td>SDL_WINDOW_FULLSCREEN_DESKTOP</td><td>fullscreen window at the current desktop resolution</td></tr><tr><td>SDL_WINDOW_OPENGL</td><td>window usable with OpenGL context</td></tr><tr><td>SDL_WINDOW_HIDDEN</td><td>window is not visible</td></tr><tr><td>SDL_WINDOW_BORDERLESS</td><td>no window decoration</td></tr><tr><td>SDL_WINDOW_RESIZABLE</td><td>window can be resized</td></tr><tr><td>SDL_WINDOW_MINIMIZED</td><td>window is minimized</td></tr><tr><td>SDL_WINDOW_MAXIMIZED</td><td>window is maximized</td></tr><tr><td>SDL_WINDOW_SHOWN</td><td>show window</td></tr></tbody></table></li></ul></li><li><p>销毁窗口</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void SDL_DestroyWindow(SDL_Window* window)</span><br></pre></td></tr></table></figure></li></ul><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>下面是一个完整的使用SDL创建窗口的例子，你可以在 linux/mac环境下执行它。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">#include &quot;SDL.h&quot;</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">int main(int argc, char* argv[]) &#123;</span><br><span class="line"></span><br><span class="line">    int flag &#x3D; 1;</span><br><span class="line"></span><br><span class="line">    SDL_Window *window;                    &#x2F;&#x2F; Declare a pointer</span><br><span class="line"></span><br><span class="line">    SDL_Init(SDL_INIT_VIDEO);              &#x2F;&#x2F; Initialize SDL2</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Create an application window with the following settings:</span><br><span class="line">    window &#x3D; SDL_CreateWindow(</span><br><span class="line">        &quot;An SDL2 window&quot;,                  &#x2F;&#x2F; window title</span><br><span class="line">        SDL_WINDOWPOS_UNDEFINED,           &#x2F;&#x2F; initial x position</span><br><span class="line">        SDL_WINDOWPOS_UNDEFINED,           &#x2F;&#x2F; initial y position</span><br><span class="line">        640,                               &#x2F;&#x2F; width, in pixels</span><br><span class="line">        480,                               &#x2F;&#x2F; height, in pixels</span><br><span class="line">        SDL_WINDOW_SHOWN | SDL_WINDOW_BORDERLESS&#x2F;&#x2F; flags - see below</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Check that the window was successfully created</span><br><span class="line">    if (window &#x3D;&#x3D; NULL) &#123;</span><br><span class="line">        &#x2F;&#x2F; In the case that the window could not be made...</span><br><span class="line">        printf(&quot;Could not create window: %s\n&quot;, SDL_GetError());</span><br><span class="line">        return 1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; The window is open: could enter program loop here (see SDL_PollEvent())</span><br><span class="line"></span><br><span class="line">    SDL_Delay(3000);  &#x2F;&#x2F; Pause execution for 3000 milliseconds, for example</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Close and destroy the window</span><br><span class="line">    SDL_DestroyWindow(window);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Clean up</span><br><span class="line">    SDL_Quit();</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>你可以使用下面的命令在linux/mac上编译上面的程序。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc&#x2F;clang -g -o sdl2_base 文件名.c &#96;pkg-config --cflags --libs sdl2&#96;</span><br></pre></td></tr></table></figure><p>编译出的程序名为 sdl2_base，执行下面的命令就可能看到运行的结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;sdl2_base</span><br></pre></td></tr></table></figure><p><strong>需要注意的是，虽然上面的程序可以正常编译执行，但你会发现该程序创建的窗口并不能显示出来。我会在第二篇文章中介绍如何让窗口正常的显示出来</strong></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>通过本文的介绍大家是不是觉得使用 SDL 非常简单易用呢？当然也许有人不太喜欢 SDL，认为直接使用 opengl 更高效。</p><p>但你要知道，SDL不只是对图像渲染做了封装，它还对其它媒体API做了封装，如对音频处理的封装等。这些封装大大减少了我们的开发工作量。</p><p>从另一方面讲，SDL 是一款非常优秀有多媒体库，除了使用它，其实我们还可以通过对其源码的分析，从中学到很多使用底层API的技巧。尤其是想学习播放器开发的同学，更是应该学好 SDL，因为著名的 ffplay 就是用的 SDL 做视频和音频的最终渲染与播放的。</p><p>最后，希望本文能帮你进行到 SDL 的世界。</p><h2 id="推荐阅读："><a href="#推荐阅读：" class="headerlink" title="推荐阅读："></a>推荐阅读：</h2><ul><li><a href="http://www.avdancedu.com/56ef4bcb" target="_blank" rel="noopener">SDL 入门</a></li><li><a href="http://www.avdancedu.com/287ad9ab" target="_blank" rel="noopener">SDL窗口渲染</a></li><li><a href="http://www.avdancedu.com/24ee78a8" target="_blank" rel="noopener">SDL基本图形绘制</a></li><li><a href="http://www.avdancedu.com/a0ec02a7" target="_blank" rel="noopener">SDL事件处事</a></li><li><a href="http://www.avdancedu.com/67189745" target="_blank" rel="noopener">彻底理解SDL纹理</a></li><li><a href="http://www.avdancedu.com/a6aca2fe" target="_blank" rel="noopener">SDL孙悟空与多线程</a></li><li><a href="http://www.avdancedu.com/f94132a0" target="_blank" rel="noopener">PCM音频播放器的实现</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;推荐阅读：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/56ef4bcb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL 入门&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/287ad9ab&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL窗口渲染&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/24ee78a8&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL基本图形绘制&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/a0ec02a7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL事件处事&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/67189745&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;彻底理解SDL纹理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/a6aca2fe&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL孙悟空与多线程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/f94132a0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;PCM音频播放器的实现&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;SDL是 “Simple DirectMedia Layer”的缩写，它是一个开源的项目。其主要用于游戏开发中的多媒体处理，如视频渲染，音频播放，鼠标/键盘控制等操作。&lt;/p&gt;
&lt;p&gt;并且它是一个跨平台的多媒体库。也就是说它对外接供了一套统一的接口，但在内部，它会根据不同平台调用不同的底层 API库。如在 Linux 系统下，它会使用 opengl 做渲染，而在 Window 下它会调用 D3D API进行渲染。&lt;/p&gt;
&lt;p&gt;我之所以要介绍它，主要是因为我要在开发的多媒体播放器中使用它。&lt;/p&gt;
    
    </summary>
    
    
      <category term="视频渲染" scheme="https://blog.avdancedu.com/categories/%E8%A7%86%E9%A2%91%E6%B8%B2%E6%9F%93/"/>
    
    
      <category term="视频渲染" scheme="https://blog.avdancedu.com/tags/%E8%A7%86%E9%A2%91%E6%B8%B2%E6%9F%93/"/>
    
      <category term="SDL" scheme="https://blog.avdancedu.com/tags/SDL/"/>
    
  </entry>
  
  <entry>
    <title>SDL窗口渲染</title>
    <link href="https://blog.avdancedu.com/287ad9ab/"/>
    <id>https://blog.avdancedu.com/287ad9ab/</id>
    <published>2022-11-19T06:52:00.000Z</published>
    <updated>2022-11-20T04:30:42.785Z</updated>
    
    <content type="html"><![CDATA[<p>推荐阅读：</p><ul><li><a href="http://www.avdancedu.com/56ef4bcb" target="_blank" rel="noopener">SDL 入门</a></li><li><a href="http://www.avdancedu.com/287ad9ab" target="_blank" rel="noopener">SDL窗口渲染</a></li><li><a href="http://www.avdancedu.com/24ee78a8" target="_blank" rel="noopener">SDL基本图形绘制</a></li><li><a href="http://www.avdancedu.com/a0ec02a7" target="_blank" rel="noopener">SDL事件处事</a></li><li><a href="http://www.avdancedu.com/67189745" target="_blank" rel="noopener">彻底理解SDL纹理</a></li><li><a href="http://www.avdancedu.com/a6aca2fe" target="_blank" rel="noopener">SDL孙悟空与多线程</a></li><li><a href="http://www.avdancedu.com/f94132a0" target="_blank" rel="noopener">PCM音频播放器的实现</a></li></ul><p>上一篇文章中我们对SDL作了简单的介绍，重点介绍了如何编译SDL以及如何使用它。在文章的最后我们留下了一个疑问，即虽然我们创建了窗口，但窗口却并没有真正显示出来。</p><p>今天我们就来看一看，如何才能让创建的窗口真正的显示出来。</p><a id="more"></a><h2 id="渲染的基本流程"><a href="#渲染的基本流程" class="headerlink" title="渲染的基本流程"></a>渲染的基本流程</h2><p>为什么我们上一课中创建了窗口，但它却并没有显示出来呢？其原因是，我们创建的窗口只是逻辑上的窗口，要想让窗口显示出来，我们需要对窗口进行效果渲染，也就是要通过绘制像素的方法，将窗口中的像素全部点亮。</p><p>那么如何对窗口进行渲染呢？SDL为我们提供了方便是的API。不过在使用SDL对窗口进行渲染之前，我们要先了解渲染的基本原理。</p><p>其基本原理是，首先创建一个window窗口，它是我们要渲染的目标。然后，要有一个渲染上下文，该上下文中一方面存放着要渲染的目标，也就是windows窗口；另一方面是存放着一个缓冲区，该缓冲区用于存放渲染的内容。</p><p>渲染的内容可以是点、线、各种图形以及图片，视频的各种组合。这些组合后的内容首先被存放到缓冲区中，最终SDL将缓冲区中的内容渲染到窗口中。</p><p>所以渲染的基本流程如下：</p><ul><li>创建窗口</li><li>创建渲染器</li><li>清空缓冲区</li><li>绘制要显示的内容</li><li>最终将缓冲区内容渲染到window窗口上。</li></ul><h2 id="常用API"><a href="#常用API" class="headerlink" title="常用API"></a>常用API</h2><ul><li><p>创建渲染上下文</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SDL_Renderer* SDL_CreateRenderer(SDL_Window* window,</span><br><span class="line">                               int         index,</span><br><span class="line">                               Uint32      flags)</span><br></pre></td></tr></table></figure><p>window: 指明在哪个窗口里进行渲染<br>index: 指定渲染驱动的索引号。一般指定为 -1.<br>flags:</p><table><thead><tr><th>flags</th><th>说明</th></tr></thead><tbody><tr><td>SDL_RENDERER_SOFTWARE</td><td>the renderer is a software fallback</td></tr><tr><td>SDL_RENDERER_ACCELERATED</td><td>the renderer uses hardware acceleration</td></tr><tr><td>SDL_RENDERER_PRESENTVSYNC</td><td>present is synchronized with the refresh rate</td></tr><tr><td>SDL_RENDERER_TARGETTEXTURE</td><td>the renderer supports rendering to texture</td></tr></tbody></table></li><li><p>消毁渲染上下文</p><p>释放渲染上下文相关的资源。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void SDL_DestroyRenderer(SDL_Renderer* renderer)</span><br></pre></td></tr></table></figure></li><li><p>清空渲染目标</p><p>该函数的作用是用指定的颜色清空缓冲区。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int SDL_RenderClear(SDL_Renderer* renderer)</span><br></pre></td></tr></table></figure><p>renderer: 上面创建的渲染器上下文。</p></li><li><p>展示要渲染的内容</p><p>将缓冲区中的内容输出到目标上，也就是 windows 窗口上。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void SDL_RenderPresent(SDL_Renderer* renderer)</span><br></pre></td></tr></table></figure><p>renderer: 上面创建的渲染器上下文</p></li></ul><h2 id="完整例子"><a href="#完整例子" class="headerlink" title="完整例子"></a>完整例子</h2><p>我在第一课的代码上，添加了上面几个函数之后，大家可以看到一个全红色的窗口可以显示在我们的面前了。</p><p>当然我们还可以在上面画一些图形，比如使用 SDL_RenderDrawLines() 函数在窗口中画一条直线。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">#include &quot;SDL.h&quot;</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">int main(int argc, char* argv[]) &#123;</span><br><span class="line"></span><br><span class="line">    int flag &#x3D; 1;</span><br><span class="line"></span><br><span class="line">    SDL_Window *window;                    &#x2F;&#x2F; Declare a pointer</span><br><span class="line">    SDL_Renderer *renderer;</span><br><span class="line"></span><br><span class="line">    SDL_Init(SDL_INIT_VIDEO);              &#x2F;&#x2F; Initialize SDL2</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Create an application window with the following settings:</span><br><span class="line">    window &#x3D; SDL_CreateWindow(</span><br><span class="line">        &quot;An SDL2 window&quot;,                  &#x2F;&#x2F; window title</span><br><span class="line">        SDL_WINDOWPOS_UNDEFINED,           &#x2F;&#x2F; initial x position</span><br><span class="line">        SDL_WINDOWPOS_UNDEFINED,           &#x2F;&#x2F; initial y position</span><br><span class="line">        640,                               &#x2F;&#x2F; width, in pixels</span><br><span class="line">        480,                               &#x2F;&#x2F; height, in pixels</span><br><span class="line">        SDL_WINDOW_SHOWN | SDL_WINDOW_BORDERLESS&#x2F;&#x2F; flags - see below</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Check that the window was successfully created</span><br><span class="line">    if (window &#x3D;&#x3D; NULL) &#123;</span><br><span class="line">        &#x2F;&#x2F; In the case that the window could not be made...</span><br><span class="line">        printf(&quot;Could not create window: %s\n&quot;, SDL_GetError());</span><br><span class="line">        return 1;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;* We must call SDL_CreateRenderer in order for draw calls to affect this window. *&#x2F;</span><br><span class="line">    renderer &#x3D; SDL_CreateRenderer(window, -1, 0);</span><br><span class="line"></span><br><span class="line">    &#x2F;* Select the color for drawing. It is set to red here. *&#x2F;</span><br><span class="line">    SDL_SetRenderDrawColor(renderer, 255, 0, 0, 255);</span><br><span class="line"></span><br><span class="line">    &#x2F;* Clear the entire screen to our selected color. *&#x2F;</span><br><span class="line">    SDL_RenderClear(renderer);</span><br><span class="line"></span><br><span class="line">    &#x2F;* Up until now everything was drawn behind the scenes.</span><br><span class="line">       This will show the new, red contents of the window. *&#x2F;</span><br><span class="line">    SDL_RenderPresent(renderer);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; The window is open: could enter program loop here (see SDL_PollEvent())</span><br><span class="line"></span><br><span class="line">    SDL_Delay(3000);  &#x2F;&#x2F; Pause execution for 3000 milliseconds, for example</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;destory renderer</span><br><span class="line">    if (renderer) &#123;</span><br><span class="line">        SDL_DestroyRenderer(renderer);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    &#x2F;&#x2F; Close and destroy the window</span><br><span class="line">    SDL_DestroyWindow(window);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Clean up</span><br><span class="line">    SDL_Quit();</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文我向大家介绍了如何将创建的窗口展示出来，并重点介绍了窗口渲染的基本原理以及使用的 SDL API。</p><p>后面的文章我将向大家重点介绍如何在窗口绘制一些常用图形。</p><p>谢谢！</p><h2 id="推荐阅读："><a href="#推荐阅读：" class="headerlink" title="推荐阅读："></a>推荐阅读：</h2><ul><li><a href="http://www.avdancedu.com/56ef4bcb" target="_blank" rel="noopener">SDL 入门</a></li><li><a href="http://www.avdancedu.com/287ad9ab" target="_blank" rel="noopener">SDL窗口渲染</a></li><li><a href="http://www.avdancedu.com/24ee78a8" target="_blank" rel="noopener">SDL基本图形绘制</a></li><li><a href="http://www.avdancedu.com/a0ec02a7" target="_blank" rel="noopener">SDL事件处事</a></li><li><a href="http://www.avdancedu.com/67189745" target="_blank" rel="noopener">彻底理解SDL纹理</a></li><li><a href="http://www.avdancedu.com/a6aca2fe" target="_blank" rel="noopener">SDL孙悟空与多线程</a></li><li><a href="http://www.avdancedu.com/f94132a0" target="_blank" rel="noopener">PCM音频播放器的实现</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;推荐阅读：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/56ef4bcb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL 入门&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/287ad9ab&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL窗口渲染&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/24ee78a8&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL基本图形绘制&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/a0ec02a7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL事件处事&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/67189745&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;彻底理解SDL纹理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/a6aca2fe&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL孙悟空与多线程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/f94132a0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;PCM音频播放器的实现&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上一篇文章中我们对SDL作了简单的介绍，重点介绍了如何编译SDL以及如何使用它。在文章的最后我们留下了一个疑问，即虽然我们创建了窗口，但窗口却并没有真正显示出来。&lt;/p&gt;
&lt;p&gt;今天我们就来看一看，如何才能让创建的窗口真正的显示出来。&lt;/p&gt;
    
    </summary>
    
    
      <category term="视频渲染" scheme="https://blog.avdancedu.com/categories/%E8%A7%86%E9%A2%91%E6%B8%B2%E6%9F%93/"/>
    
    
      <category term="SDL" scheme="https://blog.avdancedu.com/tags/SDL/"/>
    
  </entry>
  
  <entry>
    <title>SDL彻底理解纹理</title>
    <link href="https://blog.avdancedu.com/67189745/"/>
    <id>https://blog.avdancedu.com/67189745/</id>
    <published>2022-11-19T06:52:00.000Z</published>
    <updated>2022-11-20T04:31:10.024Z</updated>
    
    <content type="html"><![CDATA[<p>这是SDL系列文章的第五篇，本文将彻底让你理解什么是纹理。并带你深入探讨SDL的几个重要概念SDL_Window、SDL_Render、SDL_Surface 与 SDL_Texture。在文章的最后向你展示SDL如何通过SDL_Texture进行渲染。</p><p>对于前面系列文章感兴趣的同学可以通过下面的链接查看：</p><ul><li><a href="http://www.avdancedu.com/56ef4bcb" target="_blank" rel="noopener">SDL 入门</a></li><li><a href="http://www.avdancedu.com/287ad9ab" target="_blank" rel="noopener">SDL窗口渲染</a></li><li><a href="http://www.avdancedu.com/24ee78a8" target="_blank" rel="noopener">SDL基本图形绘制</a></li><li><a href="http://www.avdancedu.com/a0ec02a7" target="_blank" rel="noopener">SDL事件处事</a></li><li><a href="http://www.avdancedu.com/67189745" target="_blank" rel="noopener">彻底理解SDL纹理</a></li><li><a href="http://www.avdancedu.com/a6aca2fe" target="_blank" rel="noopener">SDL孙悟空与多线程</a></li><li><a href="http://www.avdancedu.com/f94132a0" target="_blank" rel="noopener">PCM音频播放器的实现</a></li></ul><a id="more"></a><h2 id="SDL-Surface-vs-SDL-Texture"><a href="#SDL-Surface-vs-SDL-Texture" class="headerlink" title="SDL_Surface vs SDL_Texture"></a>SDL_Surface vs SDL_Texture</h2><p>在SDL系列文章的第二篇里，我详细的介绍了SDL 渲染的工作原理。即在SDL_Render对象中有一个视频缓冲区，该缓冲区我们称之为SDL_Surface，它是按照像素存放图像的。我们一般把真彩色的像素称为RGB24数据。也就是说，每一个像素由24位组成，每8位代表一种颜色，像素的最终颜色是由RGB三种颜色混合而成的。</p><p>SDL_Texture 与SDL_Surface相似，也是一种缓冲区。只不过它存放的不是真正的像素数据，而是存放的图像的描述信息。当渲染纹理时，SDL以这些描述信息为数据，底层通过OpenGL、D3D 或 Metal操作GPU，最终绘制出与SDL_Surface一样的图形，且效率更高（因为它是GPU硬件计算的）。</p><p>看了以上的介绍，是不是对纹理有了一个清楚的认识了？</p><p>介绍完 SDL_Surface 和 SDL_Texture后，我们再看下SDL_Window 与 SDL_Render。</p><h2 id="SDL-Window-与-SDL-Render"><a href="#SDL-Window-与-SDL-Render" class="headerlink" title="SDL_Window 与 SDL_Render"></a>SDL_Window 与 SDL_Render</h2><p>SDL_Window代表的是窗口的逻辑概念，它是存放在主内存中的一个对象。所以当我们调用SDL API 创建窗口后，它并不会被显示出来。</p><p>SDL_Render 是渲染器，它也是主存中的一个对象。对Render操作时实际上分为两个阶段：</p><p>一、渲染阶段。在该阶段，用户可以画各种图形渲染到SDL_Surface或SDL_Texture 中;</p><p>二、显示阶段。参SDL_Texture为数据，通过OpenGL操作GPU，最终将 SDL_Surfce 或SDL_Texture中的数据输出到显示器上。</p><p>通过上面的介绍，我们就将 SDL_Window、SDL_Render、SDL_Surface与 SDL_Texture之间的关系梳理清楚了，下面我们来看一下如何使用 SDL_Texture。</p><h2 id="使用SDL-Texture"><a href="#使用SDL-Texture" class="headerlink" title="使用SDL_Texture"></a>使用SDL_Texture</h2><p>SDL提供了非常好用的操作SDL_Texture的方法，下面我们来重点介绍一下使用SDL_Texute的基本步骤。</p><ul><li><p>创建一个 SDL_Texture。</p></li><li><p>渲染 Texture</p></li><li><p>Destory Texture</p></li></ul><h2 id="API详细介绍"><a href="#API详细介绍" class="headerlink" title="API详细介绍"></a>API详细介绍</h2><ul><li><p>创建 SDL_Texture</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SDL_Texture* SDL_CreateTexture(SDL_Renderer* renderer,</span><br><span class="line">                             Uint32        format,</span><br><span class="line">                             int           access,</span><br><span class="line">                             int           w,</span><br><span class="line">                             int           h)</span><br></pre></td></tr></table></figure><ul><li>format: 指明像素格式，可以是YUV，也可以是RGB</li><li>access: 指明Texture的类型。可以是 Stream(视频)，也可以是Target一般的类型。</li></ul></li><li><p>渲染</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int SDL_RenderCopy(SDL_Renderer*   renderer,</span><br><span class="line">                 SDL_Texture*    texture,</span><br><span class="line">                 const SDL_Rect* srcrect,</span><br><span class="line">                 const SDL_Rect* dstrect)</span><br></pre></td></tr></table></figure><ul><li>srcrect: 指定 Texture 中要渲染的一部分。如果将 Texture全部输出，可以设置它为 NULL。</li><li>dstrect: 指定输出的空间大小。</li></ul></li><li><p>销毁Texture</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void SDL_DestroyTexture(SDL_Texture* texture)</span><br></pre></td></tr></table></figure></li></ul><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>下面这个例子非常简单，我这里就不做特别的说明了。对这个程序看不懂的同学可以看我之前的几篇 SDL 的相关文章。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">#include &quot;SDL.h&quot;</span><br><span class="line"></span><br><span class="line">&#x2F;* Moving Rectangle *&#x2F;</span><br><span class="line">int main(int argc, char *argv[])</span><br><span class="line">&#123;</span><br><span class="line">        SDL_Window *window;</span><br><span class="line">        SDL_Renderer *renderer;</span><br><span class="line">        SDL_Texture *texture;</span><br><span class="line">        SDL_Event event;</span><br><span class="line">        SDL_Rect r;</span><br><span class="line"></span><br><span class="line">        if (SDL_Init(SDL_INIT_VIDEO) &lt; 0) &#123;</span><br><span class="line">                SDL_LogError(SDL_LOG_CATEGORY_APPLICATION, &quot;Couldn&#39;t initialize SDL: %s&quot;, SDL_GetError());</span><br><span class="line">                return 3;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        window &#x3D; SDL_CreateWindow(&quot;SDL_CreateTexture&quot;,</span><br><span class="line">                        SDL_WINDOWPOS_UNDEFINED,</span><br><span class="line">                        SDL_WINDOWPOS_UNDEFINED,</span><br><span class="line">                        1024, 768,</span><br><span class="line">                        SDL_WINDOW_RESIZABLE);</span><br><span class="line"></span><br><span class="line">        r.w &#x3D; 100;</span><br><span class="line">        r.h &#x3D; 50;</span><br><span class="line"></span><br><span class="line">        renderer &#x3D; SDL_CreateRenderer(window, -1, 0);</span><br><span class="line"></span><br><span class="line">        texture &#x3D; SDL_CreateTexture(renderer, SDL_PIXELFORMAT_RGBA8888, SDL_TEXTUREACCESS_TARGET, 1024, 768);</span><br><span class="line"></span><br><span class="line">        while (1) &#123;</span><br><span class="line">                SDL_PollEvent(&amp;event);</span><br><span class="line">                if(event.type &#x3D;&#x3D; SDL_QUIT)</span><br><span class="line">                        break;</span><br><span class="line">                r.x&#x3D;rand()%500;</span><br><span class="line">                r.y&#x3D;rand()%500;</span><br><span class="line"></span><br><span class="line">                SDL_SetRenderTarget(renderer, texture);</span><br><span class="line">                SDL_SetRenderDrawColor(renderer, 0x00, 0x00, 0x00, 0x00);</span><br><span class="line">                SDL_RenderClear(renderer);</span><br><span class="line">                SDL_RenderDrawRect(renderer,&amp;r);</span><br><span class="line">                SDL_SetRenderDrawColor(renderer, 0xFF, 0x00, 0x00, 0x00);</span><br><span class="line">                SDL_RenderFillRect(renderer, &amp;r);</span><br><span class="line">                SDL_SetRenderTarget(renderer, NULL);</span><br><span class="line">                SDL_RenderCopy(renderer, texture, NULL, NULL);</span><br><span class="line">                SDL_RenderPresent(renderer);</span><br><span class="line">        &#125;</span><br><span class="line">        SDL_DestroyRenderer(renderer);</span><br><span class="line">        SDL_Quit();</span><br><span class="line">        return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文重点介绍了 SDL_Window、SDL_Render、SDL_Surface以及SDL_Texture之间的关系。搞清楚它们之前的关系对于理解 SDL 渲染起着至关重要的作用。</p><p>大家一定要仔细的理解文章中所讲的内容，在我后序的文章中，尤其是后面介绍 播放器 相关内容时，都要用到现在所讲的这些内容。</p><p>希望本文能对你有所帮助，谢谢！</p><h2 id="隆重推荐"><a href="#隆重推荐" class="headerlink" title="隆重推荐"></a>隆重推荐</h2><ul><li><a href="http://www.avdancedu.com/56ef4bcb" target="_blank" rel="noopener">SDL 入门</a></li><li><a href="http://www.avdancedu.com/287ad9ab" target="_blank" rel="noopener">SDL窗口渲染</a></li><li><a href="http://www.avdancedu.com/24ee78a8" target="_blank" rel="noopener">SDL基本图形绘制</a></li><li><a href="http://www.avdancedu.com/a0ec02a7" target="_blank" rel="noopener">SDL事件处事</a></li><li><a href="http://www.avdancedu.com/67189745" target="_blank" rel="noopener">彻底理解SDL纹理</a></li><li><a href="http://www.avdancedu.com/a6aca2fe" target="_blank" rel="noopener">SDL孙悟空与多线程</a></li><li><a href="http://www.avdancedu.com/f94132a0" target="_blank" rel="noopener">PCM音频播放器的实现</a></li><li><a href="https://coding.imooc.com/class/279.html" target="_blank" rel="noopener">ffmpeg精讲</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是SDL系列文章的第五篇，本文将彻底让你理解什么是纹理。并带你深入探讨SDL的几个重要概念SDL_Window、SDL_Render、SDL_Surface 与 SDL_Texture。在文章的最后向你展示SDL如何通过SDL_Texture进行渲染。&lt;/p&gt;
&lt;p&gt;对于前面系列文章感兴趣的同学可以通过下面的链接查看：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/56ef4bcb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL 入门&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/287ad9ab&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL窗口渲染&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/24ee78a8&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL基本图形绘制&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/a0ec02a7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL事件处事&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/67189745&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;彻底理解SDL纹理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/a6aca2fe&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL孙悟空与多线程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/f94132a0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;PCM音频播放器的实现&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="视频渲染" scheme="https://blog.avdancedu.com/categories/%E8%A7%86%E9%A2%91%E6%B8%B2%E6%9F%93/"/>
    
    
      <category term="SDL" scheme="https://blog.avdancedu.com/tags/SDL/"/>
    
  </entry>
  
  <entry>
    <title>SDL绘制基本图型</title>
    <link href="https://blog.avdancedu.com/24ee78a8/"/>
    <id>https://blog.avdancedu.com/24ee78a8/</id>
    <published>2022-11-19T06:52:00.000Z</published>
    <updated>2022-11-20T04:31:32.523Z</updated>
    
    <content type="html"><![CDATA[<p>之前的SDL的两篇文章我向大家介绍了如何编译使用 SDL，以及如何才能让窗口显示出来。想了解相关内容的同学可以点击下面的链接查看相关内容。</p><ul><li><a href="http://www.avdancedu.com/56ef4bcb" target="_blank" rel="noopener">SDL 入门</a></li><li><a href="http://www.avdancedu.com/287ad9ab" target="_blank" rel="noopener">SDL窗口渲染</a></li><li><a href="http://www.avdancedu.com/24ee78a8" target="_blank" rel="noopener">SDL基本图形绘制</a></li><li><a href="http://www.avdancedu.com/a0ec02a7" target="_blank" rel="noopener">SDL事件处事</a></li><li><a href="http://www.avdancedu.com/67189745" target="_blank" rel="noopener">彻底理解SDL纹理</a></li><li><a href="http://www.avdancedu.com/a6aca2fe" target="_blank" rel="noopener">SDL孙悟空与多线程</a></li><li><a href="http://www.avdancedu.com/f94132a0" target="_blank" rel="noopener">PCM音频播放器的实现</a></li></ul><p>本文将向大家介绍一下，如何通过 SDL 绘制一些基本图形，如 点、线、矩形。了解了这些基本图形后，你就可以按照搭积木的方式，构造出其它更复杂的图形了。</p><a id="more"></a><h2 id="有哪些基本图形可以绘制"><a href="#有哪些基本图形可以绘制" class="headerlink" title="有哪些基本图形可以绘制"></a>有哪些基本图形可以绘制</h2><p>SDL中绘制基本图形的 API并不多，主要是 点、线、矩形。其它图形都可以通过 点、线、矩形组合出来。</p><ul><li>设置颜色：在绘制图形前，要设置一下画笔的色彩。这里需要注意的是，如果画笔与背景色相同了，那在窗口中是显示不出来图形的。</li><li>画点。</li><li>画线。</li><li>画矩形。</li><li>填充矩形。</li></ul><p>下面来详细介绍一下这几个API。</p><h2 id="API详细介绍"><a href="#API详细介绍" class="headerlink" title="API详细介绍"></a>API详细介绍</h2><ul><li><p>设置颜色</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">int SDL_SetRenderDrawColor(SDL_Renderer* renderer,</span><br><span class="line">                         Uint8         r,</span><br><span class="line">                         Uint8         g,</span><br><span class="line">                         Uint8         b,</span><br><span class="line">                         Uint8         a)</span><br></pre></td></tr></table></figure><p>该函数中的参数 a 指明了颜色的透明度。</p><p><strong>但该值我设置了一下没有起作用，应该需要和BlendMode一起才能起作用。这块有谁清楚可以指定一下</strong></p></li><li><p>画点</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int SDL_RenderDrawPoint(SDL_Renderer* renderer,</span><br><span class="line">                      int           x, </span><br><span class="line">                      int           y)</span><br></pre></td></tr></table></figure></li><li><p>画多个点</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int SDL_RenderDrawPoints(SDL_Renderer*    renderer,</span><br><span class="line">                       const SDL_Point* points,</span><br><span class="line">                       int              count)</span><br></pre></td></tr></table></figure><ul><li>points: 点数组。</li><li>count: 点的个数。</li></ul></li><li><p>画线</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">int SDL_RenderDrawLine(SDL_Renderer* renderer,</span><br><span class="line">                     int           x1,</span><br><span class="line">                     int           y1,</span><br><span class="line">                     int           x2,</span><br><span class="line">                     int           y2)</span><br></pre></td></tr></table></figure></li><li><p>画多条线</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int SDL_RenderDrawLines(SDL_Renderer*    renderer,</span><br><span class="line">                      const SDL_Point* points,</span><br><span class="line">                      int              count)</span><br></pre></td></tr></table></figure><p>该函数会将使用两个相邻的点之间进行连线。最终画出你想画的图形。如画三角形，多边形或圆形。</p></li><li><p>绘制矩形</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int SDL_RenderDrawRect(SDL_Renderer*   renderer,</span><br><span class="line">                     const SDL_Rect* rect)</span><br></pre></td></tr></table></figure><p>rect: 是要绘制的一块区域。它包括，x,y,w,h这个元素。</p></li><li><p>填充矩形</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int SDL_RenderFillRect(SDL_Renderer*   renderer,</span><br><span class="line">                     const SDL_Rect* rect)</span><br></pre></td></tr></table></figure><p>使用指定的色彩填充一块矩形。</p></li><li><p>填充多块矩形</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int SDL_RenderDrawRects(SDL_Renderer*   renderer,</span><br><span class="line">                      const SDL_Rect* rects,</span><br><span class="line">                      int             count)</span><br></pre></td></tr></table></figure><ul><li>rects: 指定的矩形数组。</li><li>count: 指定矩形个数。</li></ul></li></ul><h2 id="我们来看看代码"><a href="#我们来看看代码" class="headerlink" title="我们来看看代码"></a>我们来看看代码</h2><p>下面的代码非常之简单，我们在上一篇文章代码的基础上增加了几个画线、画矩形的API就可以了。</p><p>这里唯一值得注意的地方是下面这个函数。 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SDL_SetRenderDrawColor(renderer, 0, 0, 255, 255);</span><br></pre></td></tr></table></figure><p>该函数是设置画笔颜色，也就是说我们想画出什么颜色的图形，只要用这个函数设置一下，再使用画点、画线的API就可以画出对应颜色的图形了。</p><p>原码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">#include &quot;SDL.h&quot;</span><br><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">#define POINTS_COUNT 4</span><br><span class="line"></span><br><span class="line">static SDL_Point points[POINTS_COUNT] &#x3D; &#123;</span><br><span class="line">    &#123;320, 200&#125;,</span><br><span class="line">    &#123;300, 240&#125;,</span><br><span class="line">    &#123;340, 240&#125;,</span><br><span class="line">    &#123;320, 200&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">static SDL_Rect bigrect &#x3D; &#123;0,0,540, 380&#125;;</span><br><span class="line"></span><br><span class="line">int main(int argc, char* argv[]) &#123;</span><br><span class="line"></span><br><span class="line">    int flag &#x3D; 1;</span><br><span class="line"></span><br><span class="line">    SDL_Window *window;                    &#x2F;&#x2F; Declare a pointer</span><br><span class="line">    SDL_Renderer *renderer;</span><br><span class="line"></span><br><span class="line">    SDL_Init(SDL_INIT_VIDEO);              &#x2F;&#x2F; Initialize SDL2</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Create an application window with the following settings:</span><br><span class="line">    window &#x3D; SDL_CreateWindow(</span><br><span class="line">        &quot;An SDL2 window&quot;,                  &#x2F;&#x2F; window title</span><br><span class="line">        SDL_WINDOWPOS_UNDEFINED,           &#x2F;&#x2F; initial x position</span><br><span class="line">        SDL_WINDOWPOS_UNDEFINED,           &#x2F;&#x2F; initial y position</span><br><span class="line">        640,                               &#x2F;&#x2F; width, in pixels</span><br><span class="line">        480,                               &#x2F;&#x2F; height, in pixels</span><br><span class="line">        SDL_WINDOW_SHOWN | SDL_WINDOW_BORDERLESS&#x2F;&#x2F; flags - see below</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Check that the window was successfully created</span><br><span class="line">    if (window &#x3D;&#x3D; NULL) &#123;</span><br><span class="line">        &#x2F;&#x2F; In the case that the window could not be made...</span><br><span class="line">        printf(&quot;Could not create window: %s\n&quot;, SDL_GetError());</span><br><span class="line">        return 1;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    &#x2F;* We must call SDL_CreateRenderer in order for draw calls to affect this window. *&#x2F;</span><br><span class="line">    renderer &#x3D; SDL_CreateRenderer(window, -1, 0);</span><br><span class="line"></span><br><span class="line">    &#x2F;* Select the color for drawing. It is set to red here. *&#x2F;</span><br><span class="line">    SDL_SetRenderDrawColor(renderer, 255, 0, 0, 255);</span><br><span class="line"></span><br><span class="line">    &#x2F;* Clear the entire screen to our selected color. *&#x2F;</span><br><span class="line">    SDL_RenderClear(renderer);</span><br><span class="line"></span><br><span class="line">    SDL_SetRenderDrawColor(renderer, 255, 255, 255, SDL_ALPHA_OPAQUE);</span><br><span class="line">    &#x2F;&#x2F;SDL_RenderDrawLine(renderer, 100, 20, 500, 400);</span><br><span class="line">    SDL_RenderDrawLines(renderer, points, POINTS_COUNT);</span><br><span class="line"></span><br><span class="line">    SDL_Rect rect &#x3D; &#123;200, 300, 100, 100&#125;;</span><br><span class="line">    SDL_RenderDrawRect(renderer, &amp;rect);</span><br><span class="line"></span><br><span class="line">    SDL_SetRenderDrawColor(renderer, 0, 255, 255, 255);</span><br><span class="line">    SDL_RenderFillRect(renderer, &amp;rect);</span><br><span class="line"></span><br><span class="line">    SDL_SetRenderDrawColor(renderer, 0, 0, 255, 255);</span><br><span class="line">    SDL_RenderFillRect(renderer, &amp;bigrect);</span><br><span class="line"></span><br><span class="line">    &#x2F;* Up until now everything was drawn behind the scenes.</span><br><span class="line">       This will show the new, red contents of the window. *&#x2F;</span><br><span class="line">    SDL_RenderPresent(renderer);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; The window is open: could enter program loop here (see SDL_PollEvent())</span><br><span class="line"></span><br><span class="line">    SDL_Delay(3000);  &#x2F;&#x2F; Pause execution for 3000 milliseconds, for example</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;destory renderer</span><br><span class="line">    if (renderer) &#123;</span><br><span class="line">        SDL_DestroyRenderer(renderer);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Close and destroy the window</span><br><span class="line">    SDL_DestroyWindow(window);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Clean up</span><br><span class="line">    SDL_Quit();</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文重点介绍了 SDL 绘制经常使用的几个基本图形API，通过这些API你可以构造出更加复杂的图形。</p><p>希望本文能对你所有帮助，谢谢！</p><h2 id="推荐阅读："><a href="#推荐阅读：" class="headerlink" title="推荐阅读："></a>推荐阅读：</h2><ul><li><a href="http://www.avdancedu.com/56ef4bcb" target="_blank" rel="noopener">SDL 入门</a></li><li><a href="http://www.avdancedu.com/287ad9ab" target="_blank" rel="noopener">SDL窗口渲染</a></li><li><a href="http://www.avdancedu.com/24ee78a8" target="_blank" rel="noopener">SDL基本图形绘制</a></li><li><a href="http://www.avdancedu.com/a0ec02a7" target="_blank" rel="noopener">SDL事件处事</a></li><li><a href="http://www.avdancedu.com/67189745" target="_blank" rel="noopener">彻底理解SDL纹理</a></li><li><a href="http://www.avdancedu.com/a6aca2fe" target="_blank" rel="noopener">SDL孙悟空与多线程</a></li><li><a href="http://www.avdancedu.com/f94132a0" target="_blank" rel="noopener">PCM音频播放器的实现</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前的SDL的两篇文章我向大家介绍了如何编译使用 SDL，以及如何才能让窗口显示出来。想了解相关内容的同学可以点击下面的链接查看相关内容。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/56ef4bcb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL 入门&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/287ad9ab&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL窗口渲染&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/24ee78a8&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL基本图形绘制&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/a0ec02a7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL事件处事&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/67189745&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;彻底理解SDL纹理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/a6aca2fe&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL孙悟空与多线程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/f94132a0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;PCM音频播放器的实现&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本文将向大家介绍一下，如何通过 SDL 绘制一些基本图形，如 点、线、矩形。了解了这些基本图形后，你就可以按照搭积木的方式，构造出其它更复杂的图形了。&lt;/p&gt;
    
    </summary>
    
    
      <category term="视频渲染" scheme="https://blog.avdancedu.com/categories/%E8%A7%86%E9%A2%91%E6%B8%B2%E6%9F%93/"/>
    
    
      <category term="SDL" scheme="https://blog.avdancedu.com/tags/SDL/"/>
    
  </entry>
  
  <entry>
    <title>SDL音频播放器的实现</title>
    <link href="https://blog.avdancedu.com/f94132a0/"/>
    <id>https://blog.avdancedu.com/f94132a0/</id>
    <published>2022-11-19T06:52:00.000Z</published>
    <updated>2022-11-20T04:31:53.207Z</updated>
    
    <content type="html"><![CDATA[<p>今天向大家介绍一下如何通过 SDL 实现一个PCM音频播放器。这是一个最简单的播放器，它不涉及到音频的解复用，解码等工作。我们只需要将音频原始数据喂给 SDL 音频接口就可以听到悦耳的声音了。在下面的列子中我将向你演示，使用 SDL 做这样一个播放器是何等的简单。</p><p>当然这个看似简单的播放器其实是由许多的理论基础在底层支持着的。如果在这方面没有什么基础的同学可以通过下面的链接去自行学习。</p><ul><li><a href="http://www.avdancedu.com/56ef4bcb" target="_blank" rel="noopener">SDL 入门</a></li><li><a href="http://www.avdancedu.com/287ad9ab" target="_blank" rel="noopener">SDL窗口渲染</a></li><li><a href="http://www.avdancedu.com/24ee78a8" target="_blank" rel="noopener">SDL基本图形绘制</a></li><li><a href="http://www.avdancedu.com/a0ec02a7" target="_blank" rel="noopener">SDL事件处事</a></li><li><a href="http://www.avdancedu.com/67189745" target="_blank" rel="noopener">彻底理解SDL纹理</a></li><li><a href="http://www.avdancedu.com/a6aca2fe" target="_blank" rel="noopener">SDL孙悟空与多线程</a></li><li><a href="http://www.avdancedu.com/f94132a0" target="_blank" rel="noopener">PCM音频播放器的实现</a></li></ul><a id="more"></a><h2 id="播放音频的基本原则"><a href="#播放音频的基本原则" class="headerlink" title="播放音频的基本原则"></a>播放音频的基本原则</h2><p>如果我们要播放一段声音，想当然的认为直接将播放的声音发送给声卡，这样扬声器就会将声音播放出来。只要我们不断的送数据，声音就会不停的输出。</p><p>事实上真的是这样吗？<strong>当 然 不 是!!!</strong></p><p>实际上，所有的音频播放都遵守着一个原则，就是当声卡将要播放的声音输出到扬声器时，它首先会通过回调函数，向你要它一部分声频数据，然后拿着这部分音频数据去播放。等播放完了，它会再向你要下一部分。</p><p>至于要的数据的多少，什么时候向你要，这些都是由声卡决定的。对于我们上层应用来说，这些都是由底层 API 决定的。</p><p>为什么会出现这种情况呢？为什么播放音频与我们一般的逻辑相反呢？这是因为声卡会严格按照音频的播放时间进行播放，不会多一秒，也不会少一秒。正因为它能准确的计算出时间来，而应用层是不知道这个时间的，所以我们必须按照声卡的要求给它喂数据，而不能依据自己的性子来。</p><p>那么有人会问，为什么声卡可以精准的计算出播放时间来呢？这是因为在播放之前我们给它设置了采样率、通道数、采样大小等参数，通过这些参数它就可以计算出时间来。</p><p>我们来做个计算，假设采样率是 48000, 双通道，采样大小是 16bit，那么一秒种的数据是多少呢？ 48000*2*16=1536000. 反过来，如果我们有一段 8M 的数据，那么声卡就知道它能播放 5秒多的声音。</p><p>上面的一大段文字描述，实际上只是想说明一个道理，就是要播放的声音数据，是声卡主动要的，不能由上层直接设置。这是通过回调函数来实现的。后面会有具体的例子。</p><h2 id="SDL如何处理音频"><a href="#SDL如何处理音频" class="headerlink" title="SDL如何处理音频"></a>SDL如何处理音频</h2><p>SDL是一个处理多媒体的开源库，我们来看看它是如何播放音频的，具体的操作步骤是啥？</p><ul><li>打开音频设备</li><li>设置音频参数</li><li>播放音频</li><li>向声卡喂数据</li><li>关闭音频设置</li></ul><h2 id="详细API介绍"><a href="#详细API介绍" class="headerlink" title="详细API介绍"></a>详细API介绍</h2><ul><li><p>打开音频设备</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int SDL_OpenAudio(SDL_AudioSpec* desired,</span><br><span class="line">                SDL_AudioSpec* obtained)</span><br></pre></td></tr></table></figure><ul><li><p>desired: 设置音频参数。</p><table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>freq</td><td>每秒采频率</td></tr><tr><td>SDL_AudioFormat</td><td>音频数据存储格式</td></tr><tr><td>channels</td><td>通道数</td></tr><tr><td>silence</td><td>静音值</td></tr><tr><td>samples</td><td>采样个数</td></tr><tr><td>size</td><td>音频缓冲区大小</td></tr><tr><td>SDL_AudioCallback</td><td>回调函数</td></tr><tr><td>userdata</td><td>回调函数参数指针</td></tr></tbody></table></li><li><p>obtained: 返回参数。</p></li></ul></li></ul><ul><li><p>关闭音频设备</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void SDL_CloseAudio(void)</span><br></pre></td></tr></table></figure></li><li><p>播放与暂停</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void SDL_PauseAudio(int pause_on)</span><br></pre></td></tr></table></figure><p>pause_on: 0, 暂停播放；1, 播放；</p></li><li><p>喂数据</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">void SDL_MixAudio(Uint8*    dst,</span><br><span class="line">               const Uint8* src,</span><br><span class="line">               Uint32       len,</span><br><span class="line">               int          volume)</span><br></pre></td></tr></table></figure><ul><li>dst: 目的缓冲区</li><li>src: 源缓冲区</li><li>len: 音频数据长度</li><li>volume: 音量大小，0-128 之间的数。SDL_MIX_MAXVOLUME代表最大音量。</li></ul></li></ul><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>这个例子主要为大家展示了一下如何使用 SDL 的音频 API 来播放声音。其基本流程是，从 pcm 文件一块一块的读数据。然后通过 read_audio_data 这个回调函数给声卡喂数据。如果一次没用完，SDL会再次调用回调函数读数据。</p><p>如果audio_buf中的数据用完了，则再次从文件中读一块数据，直到读到文件尾。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line">#include &lt;SDL.h&gt;</span><br><span class="line"></span><br><span class="line">#define BLOCK_SIZE 4096000</span><br><span class="line"></span><br><span class="line">static Uint8 *audio_buf &#x3D; NULL;</span><br><span class="line">static Uint8 *audio_pos &#x3D; NULL;</span><br><span class="line">static size_t buffer_len &#x3D; 0;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;callback function for audio devcie</span><br><span class="line">void read_audio_data(void *udata, Uint8 *stream, int len)&#123;</span><br><span class="line"></span><br><span class="line">    if(buffer_len &#x3D;&#x3D; 0)&#123;</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    SDL_memset(stream, 0, len);</span><br><span class="line"></span><br><span class="line">    len &#x3D; (len &lt; buffer_len) ? len : buffer_len;</span><br><span class="line">    SDL_MixAudio(stream, audio_pos, len, SDL_MIX_MAXVOLUME);</span><br><span class="line"></span><br><span class="line">    audio_pos +&#x3D; len;</span><br><span class="line">    buffer_len -&#x3D; len;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main(int argc, char *argv[])</span><br><span class="line">&#123;</span><br><span class="line">    int ret &#x3D; -1;</span><br><span class="line"></span><br><span class="line">    FILE *audio_fd &#x3D; NULL;</span><br><span class="line"></span><br><span class="line">    SDL_AudioSpec spec;</span><br><span class="line"></span><br><span class="line">    char *path &#x3D; &quot;.&#x2F;test.pcm&quot;;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;SDL initialize</span><br><span class="line">    if(SDL_Init(SDL_INIT_VIDEO | SDL_INIT_AUDIO | SDL_INIT_TIMER))&#123;</span><br><span class="line">        fprintf(stderr, &quot;Could not initialize SDL - %s\n&quot;, SDL_GetError());</span><br><span class="line">        return ret;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;open pcm file</span><br><span class="line">    audio_fd &#x3D; fopen(path, &quot;r&quot;);</span><br><span class="line">    if(!audio_fd)&#123;</span><br><span class="line">        fprintf(stderr, &quot;Failed to open pcm file!\n&quot;);</span><br><span class="line">        goto __FAIL;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;SDL_AudioSpec</span><br><span class="line">    spec.freq &#x3D; 44100;;</span><br><span class="line">    spec.format &#x3D; AUDIO_S16SYS;</span><br><span class="line">    spec.channels &#x3D; 2;</span><br><span class="line">    spec.silence &#x3D; 0;</span><br><span class="line">    spec.samples &#x3D; 1024;;</span><br><span class="line">    spec.callback &#x3D; read_audio_data;;</span><br><span class="line">    spec.userdata &#x3D; NULL;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;open audio devcie</span><br><span class="line">    if(SDL_OpenAudio(&amp;spec, NULL))&#123;</span><br><span class="line">        fprintf(stderr, &quot;Failed to open audio device, %s\n&quot;, SDL_GetError());</span><br><span class="line">        goto __FAIL;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;play audio</span><br><span class="line">    SDL_PauseAudio(0);</span><br><span class="line"></span><br><span class="line">    do&#123;</span><br><span class="line">        &#x2F;&#x2F;read data from pcm file</span><br><span class="line">        buffer_len &#x3D; fread(audio_buf, 1, BLOCK_SIZE, audio_fd);</span><br><span class="line">        fprintf(stderr, &quot;block size is %zu\n&quot;, buffer_len);</span><br><span class="line"></span><br><span class="line">        audio_pos &#x3D; audio_buf;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;the main thread wait for a moment</span><br><span class="line">        while(audio_pos &lt; (audio_buf + buffer_len)) &#123;</span><br><span class="line">            SDL_Delay(1);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;while(buffer_len !&#x3D;0);</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F;close audio device</span><br><span class="line">    SDL_CloseAudio();</span><br><span class="line"></span><br><span class="line">    ret &#x3D; 0;</span><br><span class="line"></span><br><span class="line">__FAIL:</span><br><span class="line">    &#x2F;&#x2F;release some resources</span><br><span class="line">    if(audio_buf)&#123;</span><br><span class="line">        free(audio_buf);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if(audio_fd)&#123;</span><br><span class="line">        fclose(audio_fd);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    &#x2F;&#x2F;quit SDL</span><br><span class="line">    SDL_Quit();</span><br><span class="line"></span><br><span class="line">    return ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本文向大家讲解了一下如何通过SDL库的音频处理 API 实现一个最简单的 PCM 播放器。通过个例子大家可以了解到，SDL的使用是如此简单。</p><p>当然这个播放器还是有点 Low,不过不要紧，随着后面文章的推出，你会逐渐看到一个完整的播放器是如何被打造出来的。</p><p>希望本文能对你有所帮助，谢谢！</p><h2 id="隆重推荐"><a href="#隆重推荐" class="headerlink" title="隆重推荐"></a>隆重推荐</h2><ul><li><a href="http://www.avdancedu.com/56ef4bcb" target="_blank" rel="noopener">SDL 入门</a></li><li><a href="http://www.avdancedu.com/287ad9ab" target="_blank" rel="noopener">SDL窗口渲染</a></li><li><a href="http://www.avdancedu.com/24ee78a8" target="_blank" rel="noopener">SDL基本图形绘制</a></li><li><a href="http://www.avdancedu.com/a0ec02a7" target="_blank" rel="noopener">SDL事件处事</a></li><li><a href="http://www.avdancedu.com/67189745" target="_blank" rel="noopener">彻底理解SDL纹理</a></li><li><a href="http://www.avdancedu.com/a6aca2fe" target="_blank" rel="noopener">SDL孙悟空与多线程</a></li><li><a href="http://www.avdancedu.com/f94132a0" target="_blank" rel="noopener">PCM音频播放器的实现</a></li><li><a href="https://coding.imooc.com/class/279.html" target="_blank" rel="noopener">ffmpeg精讲</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天向大家介绍一下如何通过 SDL 实现一个PCM音频播放器。这是一个最简单的播放器，它不涉及到音频的解复用，解码等工作。我们只需要将音频原始数据喂给 SDL 音频接口就可以听到悦耳的声音了。在下面的列子中我将向你演示，使用 SDL 做这样一个播放器是何等的简单。&lt;/p&gt;
&lt;p&gt;当然这个看似简单的播放器其实是由许多的理论基础在底层支持着的。如果在这方面没有什么基础的同学可以通过下面的链接去自行学习。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/56ef4bcb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL 入门&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/287ad9ab&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL窗口渲染&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/24ee78a8&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL基本图形绘制&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/a0ec02a7&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL事件处事&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/67189745&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;彻底理解SDL纹理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/a6aca2fe&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;SDL孙悟空与多线程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.avdancedu.com/f94132a0&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;PCM音频播放器的实现&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="视频渲染" scheme="https://blog.avdancedu.com/categories/%E8%A7%86%E9%A2%91%E6%B8%B2%E6%9F%93/"/>
    
    
      <category term="SDL" scheme="https://blog.avdancedu.com/tags/SDL/"/>
    
  </entry>
  
  <entry>
    <title>VS调试技巧</title>
    <link href="https://blog.avdancedu.com/736c6e64/"/>
    <id>https://blog.avdancedu.com/736c6e64/</id>
    <published>2022-11-19T06:52:00.000Z</published>
    <updated>2022-11-20T04:34:12.327Z</updated>
    
    <content type="html"><![CDATA[<p>文中记录了一些我经常使用的VS快捷键以及调试工具，希望也能帮助到其它同学。</p><h2 id="常用调试快捷键"><a href="#常用调试快捷键" class="headerlink" title="常用调试快捷键"></a>常用调试快捷键</h2><ul><li>F5 : 运行程序</li><li>F10：单步调试</li><li>F11：进入函数</li><li>Shift+F11: 跳出函数</li><li>F9：设置或取消断点</li></ul><a id="more"></a><h2 id="阅读代码快捷键"><a href="#阅读代码快捷键" class="headerlink" title="阅读代码快捷键"></a>阅读代码快捷键</h2><ul><li>F12 :  函数间跳转</li><li>crtl + -: 跳回去，与F12方向向反。</li></ul><h2 id="查看变量内存值"><a href="#查看变量内存值" class="headerlink" title="查看变量内存值"></a>查看变量内存值</h2><ul><li>打开内存显示窗口</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DEBUG-&gt;windows-&gt;memory</span><br></pre></td></tr></table></figure><ul><li><p>在内存显示窗口里贴入要查看的变量地址</p></li><li><p>查看当前所有线程</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">点击 Debug -&gt; Windows -&gt; Threads</span><br></pre></td></tr></table></figure><ul><li>查看线程视图</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Debug -&gt; Windows -&gt; Parallel Stack</span><br></pre></td></tr></table></figure><blockquote><p>注意，在程序中打断点，然后启动调试（线程窗口需要启动调试才可以看得到）</p></blockquote><h2 id="VS常用设置"><a href="#VS常用设置" class="headerlink" title="VS常用设置"></a>VS常用设置</h2><ul><li><p>如何设置 $(Outdir)  路径</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">右键工程-〉属性-〉配置属性-〉常规-〉输出目录</span><br></pre></td></tr></table></figure></li><li><p>如何设置输出文件类型</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">右键工程-〉属性-〉配置属性-〉常规-〉项目默认值-&gt;配置类型</span><br></pre></td></tr></table></figure></li><li><p>如何设置目标文件名</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">右键工程-〉属性-〉配置属性-〉常规-〉目标文件名</span><br></pre></td></tr></table></figure></li><li><p>如何设置目标扩展名</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">右键工程-〉属性-〉配置属性-〉常规-〉目标扩展名</span><br></pre></td></tr></table></figure></li><li><p>如何修改C/C++中将警告视为错误</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">右键工程-〉属性-〉配置属性-〉C&#x2F;C++-&gt;将警告视为错误</span><br></pre></td></tr></table></figure></li><li><p>当一个工程里有多个项目时，要设置一个启动项目做为开始</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">右键工程-〉设置为启动项目</span><br></pre></td></tr></table></figure></li></ul><h2 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h2><p>持继更新中……</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;文中记录了一些我经常使用的VS快捷键以及调试工具，希望也能帮助到其它同学。&lt;/p&gt;
&lt;h2 id=&quot;常用调试快捷键&quot;&gt;&lt;a href=&quot;#常用调试快捷键&quot; class=&quot;headerlink&quot; title=&quot;常用调试快捷键&quot;&gt;&lt;/a&gt;常用调试快捷键&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;F5 : 运行程序&lt;/li&gt;
&lt;li&gt;F10：单步调试&lt;/li&gt;
&lt;li&gt;F11：进入函数&lt;/li&gt;
&lt;li&gt;Shift+F11: 跳出函数&lt;/li&gt;
&lt;li&gt;F9：设置或取消断点&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="文本编辑器" scheme="https://blog.avdancedu.com/categories/%E6%96%87%E6%9C%AC%E7%BC%96%E8%BE%91%E5%99%A8/"/>
    
    
      <category term="VisualStudio" scheme="https://blog.avdancedu.com/tags/VisualStudio/"/>
    
  </entry>
  
  <entry>
    <title>音视频通信为什么要选择WebRTC</title>
    <link href="https://blog.avdancedu.com/b363212d/"/>
    <id>https://blog.avdancedu.com/b363212d/</id>
    <published>2022-11-19T06:52:00.000Z</published>
    <updated>2022-11-20T05:28:42.462Z</updated>
    
    <content type="html"><![CDATA[<p><img data-src="https://cdn.avdancedu.com/image/article/select_webrtc/webrtc_win_event.jpg" alt=""><br>在网上经常看到有人说：“在线教育直播是用WebRTC做的”，“音视频会议是用WebRTC做的”……；“声网、腾讯、阿里……都使用的WebRTC”。但你有没有好奇，这些一线大厂为什么都要使用WebRTC呢？换句话说，WebRTC到底好在哪里呢？</p><p>这个问题，对于长期做音视频实时通信的老手来说是不言而喻的；但对于新手，则是急切想知道，而又很难得到答案的问题。那么本文我将采用对比法，向你详细阐述一下WebRTC到底好在哪里。</p><p>这次我们对比的指标包括：性能、易用性、可维护性、流行性、代码风格等多个方面。不过，要做这样的对比并非易事儿，首先要解决的难点是，目前市面上没有一款与WebRTC接近或有相似功能的开源库。这真成了无米之炊了！</p><p>好在这点困难并难不倒我们，既然没有与之可比较的开源库，那我们就自己“造”一个，用自研系统与WebRTC作比较。评估一下自研系统与基于WebRTC开发的音视频客户端，哪个成本更低、质量更好。通过这样的对比，相信能让你更加了解WebRTC，知道其到底有多优秀了。</p><a id="more"></a><h2 id="自研系统直播客户端架构"><a href="#自研系统直播客户端架构" class="headerlink" title="自研系统直播客户端架构"></a>自研系统直播客户端架构</h2><p>首先我们先来了解一下自研直播客户端的架构，其如（图1）所示。这是一个最简单的音视频直播客户端架构，通过这张架构图，你大体可以知道自研系统都要实现那些模块了。</p><p><img data-src="https://cdn.avdancedu.com/image/article/select_webrtc/simple_arch.jpg" alt="图1"></p><center><font color=gray>（图1）</font></center>由（图1）你可以知道，一个最简单的直播客户端至少应该包括：音视频采集模块、音视频编码模块、网络传输模块、音视频解码模块和音视频渲染模块五大部分。<p>音视频采集模块：该模块调用系统的API，从麦克风和摄像读取设备采集到的音视频数据。音频采集的是PCM数据，视频采集的是YUV数据。<br>音视频编码模块：它负责将音视频设备上采集的原始数据（PCM、YUV)进行压缩编码。网<br>络传输模块：该模块负责将编码后的数据生成RTP包，并通过网络传输给对端；同时，接收对端的RTP数据。<br>音视频解码模块：它将网络模块接收到的压缩数据进行解码，还原回原始数据（PCM、YUV）。<br>音视频渲染渲染：拿到解码后的数据后，该模块将音频输出到扬声器，将视频渲染到显示器。<br>通过前面的介绍，相信你一定觉得，自研一个直播客户端好像也不是特别难的事儿。但实际上，上面介绍的音视频直播客户端架构是极简化的，甚至都不能称之为直播客户端架构，而只能称它为示意图。因为要将它变为真实的、可商用的架构还需要做不少的细化工作。</p><h2 id="拆分音视频模块"><a href="#拆分音视频模块" class="headerlink" title="拆分音视频模块"></a>拆分音视频模块</h2><p>接下来，咱们就对上面的直播客户端架构图进行逐步细化，细化的第一步就是拆分音视频模块。因为在实际开发中，音频与视频的处理是完全独立的，它们有各自的处理方式。如音频有独立的采集设备（声卡），独立的播放设备（扬声器）、访问音频设备的系统API等，另外，音频还有多种音频编解码器，如Opus、AAC、iLBC等；同样，视频也有自己独立的采集设备（摄像头）、渲染设备（显示器）、各种视频编码器，如H264、VP8等。细化后的直播客户端架构如（图2）所示。<br><img data-src="https://cdn.avdancedu.com/image/article/select_webrtc/split_arch.jpg" alt="图2"></p><center><font color=gray>（图2）</font></center>从（图2）中你可以看到，细化后的架构中，音频的采集模块与视频的采集模块是分开的，而音频编解码模块与视频的编解码模块也都是分开的。也就是说，音频是一条处理流程，视频是另外一条处理流程，它们之间并不相交。在音视频处理中，我们一般称每一路音频或每一路视频为一条轨。<p>除此之外，你还可以知道，自研音视频直播客户端要实现的模块远不止5个，至少应该包括：音频采集模块、视频采集模块、音频编码/音频解码模块、视频编码/视频解码模块、网络传输模块、音频播放模块以及视频渲染７个模块。</p><h2 id="跨平台"><a href="#跨平台" class="headerlink" title="跨平台"></a>跨平台</h2><p>实现音视频直播客户端除了要实现上面介绍的7个模块外，还要考虑跨平台的问题，只有在各个平台上都能实现音视频的互联互通，才能称得上是一个合格的音视频直播客户端。所以它至少应该实现Windows端、Mac端、Android端以及iOS四个终端，当然如果还能够支持Linux端和浏览器则是再好不过的了。</p><p>你要知道的是，如果不借助WebRTC，想在浏览器上实现音视频实时互通，难度是非常大的，这是自研系统的一大缺陷。除了与浏览器互通外，其它几个终端实现互通倒是相对较容易的事儿。</p><p>增加跨平台后，音视频直播客户端的架构要较之前复杂得多了，其如（图3）所示。从这张图中你可以看到，要实现跨平台，难度最大、首当其冲的，是访问硬件设备的模块，如音频采集模块、音频播放模块、视频采集模块以及视频播放模块等，它们在架构中的变化是最大的。</p><p><img data-src="https://cdn.avdancedu.com/image/article/select_webrtc/multi_platform_arch.jpg" alt="图3"></p><center><font color=gray>（图3）</font></center>以音频采集为例，在不同的平台上，采集音频数据时使用的API是完全不一样的。PC端使用的是CoreAudio系列的API；巧合的是，Mac端用于采集音频的系统API也称为CoreAudio，不过具体的函数名肯定是不同的；在Android端，它为采集音视频提供的API称之为AudioRecord；iOS端，使用AudioUnit来采集音频数据；而Linux端，则使用PulseAudio采集音频数据。<p>总之，每个终端都有各自采集音视频数据的API。由于不同的系统，其API设计的架构也不同，所以在使用这些API时，调用的方式和使用的逻辑也千差万别。因此，在开发这部分模块时，其工作量是巨大的。</p><h2 id="插件化管理"><a href="#插件化管理" class="headerlink" title="插件化管理"></a>插件化管理</h2><p>对于音视频直播客户端来说，我们不但希望它可以处理音频数据、视频数据，而且还希望它可以分享屏幕、播放多媒体文件、共享白板……此外，既使是处理音视频，我们也希望它可以支持多种编解码格式，如音频除了可以支持Opus、AAC外，还可以支持G.711/G.722、iLBC、speex等；视频除了可能支持H264外，还可以支持H265、VP8、VP9、AV1等，这样它才能应用的更广泛。</p><p>实际上，这些音视频编解码器都有各自的优缺点，也有各自适用的范围。比如G.711/G.722主要用于电话系统，音视频直播客户端要想与电话系统对接，就要支持这种编解码格式；Opus主要用于实时通话；AAC主要应用于音乐类的应用，如钢琴教学等。所以，我们希望直播客户端能够支持尽可能多的编解码器，这样的直播客户端才足够强大。</p><p>如何才能做到这一点呢?最好的设计方案就是实现插件化管理。当你需要支持某个功能时，直接编写一个插件放上去即可；当不需要的时候，可以随时将插件拿下来，这样的设计方案灵活、安全、可靠。</p><p><img data-src="https://cdn.avdancedu.com/image/article/select_webrtc/plugin_arch.jpg" alt="图4"></p><center><font color=gray>（图4）</font></center>为了让直播客户端支持插件化管理，我对之前的架构图又做了调整。如（图4）所示。从中你可以看到，为了支持插件化管理，我将原来架构图中的音视频编解码器换成音视频编解码插件管理器，而各种音视频编解码器（Opus、AAC、iLBC......）都可以作为一个插件注册到其中。当你想使用某种类型的编码器时，可以通过参数进行控制，这样从音视频采集模块采集到的数据就会被送往对应的编码器进行编码；当接收接收到RTP格式的音视频数据时，又可以根据RTP头中的Payload Type来区分，将数据交由对应的解码器进行解码。经这样处理后，咱们的音视频直播客户端的功能就更强大了，应用范围也更广了。<p>这里我以音频编解码器为例，简要的向你介绍一下直播客户端增加插件管理前后的区别。客户端在增加插件管理之前，它只能使用一种音频编解码器，如Opus。因此，在一场直播活动中，所有参与直播的终端都只能使用同一种音频的编解码器（Opus）。这样看起来貌似也不会产生什么问题，是吧？不过，假如此时，我们想将一路电话语音接入到这场直播中（电话语音使用的编解码器为G.711/G.722），它就无能为力了；而有了插件管理情况就不同了，各终端可以根据接收到的音频数据类型调用不同的音频解码器进行解码，从而实现不同编解码器在同一场直播中互通的场景，这就是插件化管理给我们带来的好处。</p><h2 id="服务质量"><a href="#服务质量" class="headerlink" title="服务质量"></a>服务质量</h2><p>除了上面我介绍的几点外，要实现一个功能强大的、性能优越的、应用广泛的音视频直播客户端还有很多的工作要做，尤其将服务质量是大家特别关心的。如果直播客户端不能提供好的服务质量，那它就失去了商业价值。</p><p>实时通信中的服务质量指的是什么呢？它主要包括三个方面，一是通信时延小；二是同等网路条件下视频更清晰、流畅；三是同等网络条件下语音失真小。如何才能保障通信时延小、视频清晰、语音不失真呢？</p><p>这里的关键是网络。如果直播客户端可以保障用户有一条非常好的网络线路，在这条线路上传输的时延最小、不丢包、不乱序，那我们的音视频服务质量自然就上去了，对吧！</p><p>但我们都知道，网络的问题是最难解决的。出现丢包、抖动、乱序更是家常便饭。有的同学可以会说 TCP 不是已经解决了丢包、乱序这些问题吗？确实是，但它是以牺牲时延为代价的。当我们的网络比较优质时，TCP/UDP都可以用于实时传输，但大多数情况下，我们首选UDP，原因是在弱网环境下使用TCP会产生极大的延时。</p><p>要想弄清楚TCP为什么在弱网环境下会产生极大的延时，就要介绍一点TCP的机制的了。TCP为了保证不丢包，不乱序，采用了发送、确认、丢包、重传的机制。正常情况下，数据从一端传输到另一端是没有任何问题的，但当出现丢包时就会有较大的麻烦。如图所示。</p><p><img data-src="https://cdn.avdancedu.com/image/article/select_webrtc/loss_tcp.jpg" alt="图5"></p><center><font color=gray>（图5）</font></center>图中显示了多次丢包时的延迟情况：从客户端向服务端发送数据包，服务端需要返回ACK消息进行确认; 客户端收到确认消息后, 才能继续发送后面的数据（有滑窗时也是类似的）。每次客户端发完数据后，都会启动一个定时器，定时器的最短超时时间是200ms。如果因某种原因，在200毫秒客户端没有收到返回的ACK包，客户端会重发上一个包。由于TCP有退避机制，以防止频繁发送丢失的包，因此会将重发包的超时时间延长到400ms。如果重发包依然没有收到确认消息，则下一次重发的超时时间会延长到800ms。我们可以看到，连续几次丢包后，就会产生非常大的延迟，这就是TCP在弱网环境下不能使用的根本原因。<p>根据实时通信指标，超过 500ms 就不能称为实时通信了，因此在弱网情况下，绝对不能使用TCP协议。实时通信的指标如（图6）所示。</p><p><img data-src="https://cdn.avdancedu.com/image/article/select_webrtc/delays.jpg" alt="图6"></p><center><font color=gray>（图6）</font></center>通过（图6）中的表格可以看到，如果端到端延迟在200ms以内，说明整个通话是优质的，通话效果就像大家在同一个房间里聊天一样；300ms以内，大多数人很满意，400ms以内，有小部分人可以感觉到延迟，但互动基本不受影响；500ms以上时，延迟会明显影响互动，大部分人都不满意。所以最关键的一点是500ms，只有延迟低于500ms，才可以说是合格的实时互动系统。<p>通过上面的描述我们可以知道，如果我们想在自己的直播客户端中实现好的服务质量，任务还是非常艰巨的。当然，除了上面要实现的功能外，还有其它很多需要处理的细节。</p><h2 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h2><p>音视频不同步问题。音视频数据经网络传输后，由于网络抖动和延迟等问题，很可能造成音视频不同步。因此，你在实现音视频直播客户端时，需要增加音视频同步模块以保障音视频的同步。</p><p>回音问题。回音问题指的是，自己与其它人进行实时互动时，可以听到自己的回声。在实时音视频通信中，不光有回音问题，还有噪音、声音过小等问题，我们将它们统称为3A问题。这些问题都是非常棘手的。目前开源的项目中，只有WebRTC和Speex有开源的回音消除算法，而且WebRTC的回音消除算法还是目前世界上最顶级的。</p><p>音视频的实时性问题。要进行实时通信，网络质量尤为关键。但你应该也清楚，网络的物理层是很难保障网络服务质量的，必须在软件层加以控制才行。虽然大家常用的TCP协议有一套完整的保障网络质量的方案，但它在实时性方面表现不佳。换句话说，TCP是以牺牲实时性来保障网络服务质量的，而实时性又是音视频实时通信的命脉，这就导致TCP协议不能作为音视频实时传输的最佳选择了。因此，为了保证实时性，一般情况下实时直播应该首选UDP协议。但这样一来，我们就必须自己编写网络控制算法以保证网络质量了。</p><p>此外，还有网络拥塞、丢包、延时、抖动、混音……不胜枚举。可以说，要实现一个实时的音视频直播客户端有许许多多的问题要解决，这里我就不一一列举了。总之，通过上面的描述，我想你已经清楚要自己研发一套音视频直播客户端到底有多难了。</p><h2 id="WebRTC客户端架构"><a href="#WebRTC客户端架构" class="headerlink" title="WebRTC客户端架构"></a>WebRTC客户端架构</h2><p>实际上，在直播客户端架构一节我讲的所有功能，WebRTC都已经实现了。下面让我们看一下WebRTC架构图吧，如（图7）所示。</p><p><img data-src="https://cdn.avdancedu.com/image/article/select_webrtc/webrtc_arch.jpg" alt="图7"></p><center><font color=gray>（图7）</font></center>从WebRTC架构图中你可以了解到，它大体上可以分成四层：即接口层、Session层、核心引擎层和设备层。下面我就向你简要的介绍一下每一层的作用。<p>接口层包括两部分，一是Web层接口；二是Native层接口。也就是说，你既可以使用浏览器开发音视频直播客户端，也可以使用Native(C++、Android、OC等)开发音视频直播客户端。</p><p>Session层的主要作用是控制业务逻辑，如媒体协商、收集Candidate等，这些操作都是在Session层处理的；</p><p>核心引擎层包括的内容就比较多了。从大的方面说，它包括音频引擎、视频引擎和网络传输层。音频引擎层包括NetEQ、音频编解码器（如OPUS、iLBC)、3A等。视频引擎包括JitterBuffer、视频编解码器（VP8/VP9/H264)等。网络传输层包括SRTP、网络I/O多路复用、P2P等。以上这些内容中，本书重点介绍了网络相关的内容，它们分布在第三章音视频实时通信的本质、第六章WebRTC中的ICE实现、第九章RTP/RTCP协议详解、第十章WebRTC拥塞控制等几个章节中，由于篇幅的原因，其它内容我会陆续发布在我的个人主站<a href="https://avdancedu.com上。" target="_blank" rel="noopener">https://avdancedu.com上。</a></p><p>设备层主要与硬件打交道，它涉及的内容包括：在各终端设备上进行音频的采集与播放、视频的采集以及网络层等。这部分内容会在本书的最后一章 \textbf{WebRTC源码分析}中做详细介绍。</p><p>从上面的描述中你可以看到，在WebRTC架构的四层中，最复杂、最核心的是第三层，即引擎层，因此，这里我再对引擎层内部的关系做下简要介绍。引擎层包括三部分内容，分别是：音频引擎、视频引擎以及网络传输。其中音视引擎和视频引擎是相对比较独立的。不过，它们都需要与网络传输层（transport）打交道。也就是说，它们都需要将自己产生的数据通过网络传输层发送出去；同时，也需要通过网络传输层接收其它端发过来的数据。此外，音频引擎与视频引擎由于要进行音视频同步的原因，所以它们之间也存在着关联关系。</p><p><img data-src="https://cdn.avdancedu.com/image/article/select_webrtc/audio_arch.jpg" alt="图8"></p><center><font color=gray>（图8）</font></center>最后，我们再次以音频为例（如图8所示），来看一下WebRTC中的数据流是如何流转的吧。当WebRTC作为发送端时，它通过音频设备采集到音频数据后，先要进行3A处理，处理后的数据交由音频编码器编码，编码后由网络传输层将数据发送出去；另一方面，当网络传输层收到数据后，它要判断数据的类型是什么，如果是音频，它会将数据交给音频引擎模块处理，数据首先被放入到NetEQ模块做平滑处理及音频补偿处理，之后进行音频解码，最终将解码后的数据通过扬声器播放出来。视频的处理流程与音频的处理流程是类似的，这里我就不再赘述了。<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>通过上面对自研音视频客户端架构的描述以及WebRTC客户端架构的描述，相信在你心中，对WebRTC的优势已经非常清楚了。下面我再从性能、跨平台、音视频服务质量、稳定性等几个方面对两者做一下总结。如（图9）所示：</p><p><img data-src="https://cdn.avdancedu.com/image/article/select_webrtc/compare.jpg" alt="图9"></p><center><font color=gray>（图9）</font></center>（图9）告诉我们，WebRTC在实时音视频直播方面的优势是不言而喻的，又有Google的强大支持，这就是为什么大家都选择WebRTC的真正原因了。<h2 id="我的视频课"><a href="#我的视频课" class="headerlink" title="我的视频课"></a>我的视频课</h2><p><a href="https://coding.imooc.com/class/329.html" target="_blank" rel="noopener">WebRTC实时互动直播技术入门与实战 5G时代必备技能</a><br><a href="https://coding.imooc.com/class/387.html" target="_blank" rel="noopener">百万级高并发WebRTC流媒体服务器设计与开发</a><br><a href="https://coding.imooc.com/class/415.html" target="_blank" rel="noopener">编程必备基础-音视频小白系统入门课</a><br><a href="https://coding.imooc.com/class/496.html" target="_blank" rel="noopener">OpenCV入门到进阶：实战三大典型项目</a><br><a href="https://coding.imooc.com/class/279.html" target="_blank" rel="noopener">经典再升级-FFmpeg音视频核心技术全面精讲+实战</a></p><h2 id="我的新书"><a href="#我的新书" class="headerlink" title="我的新书"></a>我的新书</h2><p><img data-src="https://cdn.avdancedu.com/image/article/select_webrtc/webrtc_book.jpg" alt="WebRTC音视频实时互动技术--原理、实战与源码分析"></p><p>★本书深入浅出地对WebRTC技术进行了系统讲解，既有原理又有实战，从WebRTC是如何实现实时音视频通信的，到如何应用WebRTC库实现音视频通信，再到WebRTC源码的剖析，逐步展开讲解。此外，对WebRTC的传输系统进行了重点分析，相信读者通过本书可以一窥WebRTC传输的奥秘。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img data-src=&quot;https://cdn.avdancedu.com/image/article/select_webrtc/webrtc_win_event.jpg&quot; alt=&quot;&quot;&gt;&lt;br&gt;在网上经常看到有人说：“在线教育直播是用WebRTC做的”，“音视频会议是用WebRTC做的”……；“声网、腾讯、阿里……都使用的WebRTC”。但你有没有好奇，这些一线大厂为什么都要使用WebRTC呢？换句话说，WebRTC到底好在哪里呢？&lt;/p&gt;
&lt;p&gt;这个问题，对于长期做音视频实时通信的老手来说是不言而喻的；但对于新手，则是急切想知道，而又很难得到答案的问题。那么本文我将采用对比法，向你详细阐述一下WebRTC到底好在哪里。&lt;/p&gt;
&lt;p&gt;这次我们对比的指标包括：性能、易用性、可维护性、流行性、代码风格等多个方面。不过，要做这样的对比并非易事儿，首先要解决的难点是，目前市面上没有一款与WebRTC接近或有相似功能的开源库。这真成了无米之炊了！&lt;/p&gt;
&lt;p&gt;好在这点困难并难不倒我们，既然没有与之可比较的开源库，那我们就自己“造”一个，用自研系统与WebRTC作比较。评估一下自研系统与基于WebRTC开发的音视频客户端，哪个成本更低、质量更好。通过这样的对比，相信能让你更加了解WebRTC，知道其到底有多优秀了。&lt;/p&gt;
    
    </summary>
    
    
      <category term="WebRTC" scheme="https://blog.avdancedu.com/categories/WebRTC/"/>
    
    
      <category term="WebRTC" scheme="https://blog.avdancedu.com/tags/WebRTC/"/>
    
  </entry>
  
  <entry>
    <title>如何正确的部署mediasoup-demo</title>
    <link href="https://blog.avdancedu.com/3ab8cfd4/"/>
    <id>https://blog.avdancedu.com/3ab8cfd4/</id>
    <published>2022-11-19T06:52:00.000Z</published>
    <updated>2022-11-21T05:48:10.098Z</updated>
    
    <content type="html"><![CDATA[<p>现在发现很多同学部署mediasoup-demo时出现各种问题，最主要的原因是无法通过npm安装依赖包。几乎每天都有同学来问这类问题，解决的办法其实很简单，找个<strong>代理</strong>就好了。</p><p>但这又引来了同学们新的问题，哪种代理好？需要多少费用……</p><a id="more"></a><p>好吧，干脆我给大家做个docker吧，这样对于那些找不到代理，不想花钱的同学直接下载docker进行部署就好了。</p><p>使用docker部署mediasoup-demo的具体步骤如下：</p><ul><li>准备一台Ubuntu22.04的PC机</li><li>下载mediasoup-demo镜像</li><li>下载run.sh脚本</li><li>启动docker</li><li>启动mediasoup</li><li>测试</li></ul><h2 id="下载mediasoup-demo镜像"><a href="#下载mediasoup-demo镜像" class="headerlink" title="下载mediasoup-demo镜像"></a>下载mediasoup-demo镜像</h2><p>下载mediasoup-demo镜像的方法很简单，只要在你的Ubuntu系统下执行下面的命令即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo docker pull lc0060305&#x2F;mediasoup-demo:v5</span><br></pre></td></tr></table></figure><blockquote><p>需要注意的是，国内的云主机都对hub.docker.com的访问做了限制，可能无法从hub.docker.com下载docker镜像，或下载很慢，最好的方式当然是在国内找个docker镜像创库，把制作好的镜像放上去，但我没有找到特别好的免费的仓库。有同学有这方面资源的可以提供一下。在此表示感谢！</p></blockquote><h2 id="下载run-sh脚本"><a href="#下载run-sh脚本" class="headerlink" title="下载run.sh脚本"></a>下载run.sh脚本</h2><p>你可以从<a href="https://cdn.avdancedu.com/image/article/docker/v1/run.sh" target="_blank" rel="noopener">这里下载run.sh</a>，下载成功后可以将它保存在任意目录下。</p><h2 id="启动docker"><a href="#启动docker" class="headerlink" title="启动docker"></a>启动docker</h2><p>使用下面的命令来启动docker</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chmod +x run.sh</span><br><span class="line">sudo MEDIASOUP_ANNOUNCED_IP&#x3D;你的IP .&#x2F;run.sh</span><br></pre></td></tr></table></figure><blockquote><p>注意，上面的IP在不同的情况下需要填入不同的值。如果你是在云主机上部署的，则<strong>MEDIASOUP_ANNOUNCED_IP</strong>设置成你云主机的外网IP地址；如果你是在自己的主机上部署的，IP地址则需要填你主机的IP，它一般是以<code>192.</code>开头的。</p></blockquote><h2 id="启动mediasoup"><a href="#启动mediasoup" class="headerlink" title="启动mediasoup"></a>启动mediasoup</h2><p>上面的步骤执行成功后，我们需要启动mediasoup服务，启动的办法也很简单:</p><ul><li><p>首先执行下面的命令进入到docker中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker attach containerID</span><br></pre></td></tr></table></figure></li><li><p>之后，在/service目录下执行下面的命令即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">startservice.sh</span><br></pre></td></tr></table></figure></li><li><p>当服务启动好后，输入<code>ctrl+p, ctrl+q</code>退出docker</p></li></ul><p>到此，mediaosoup-demo就算部署好了。现在让我们来测试一下吧！</p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>在chrome 浏览器中输入<code>https://IP:3000</code>，如果一切顺利的话，你将能够看到mediasoup-demo中熟悉的背景，并必本地摄像头也被打开了。</p><p>然后复制页面地址，打开一个新标签页，现在两个页面应该就可以通信了。</p><blockquote><p>注意，我在测试时发现chrome 102 这个版本是可以通信的，而用最新的chrome会报错。该问题我已经提交给mediasoup官网，如果有进一步的消息我会及时进行更新。</p></blockquote><h2 id="下载老版本Chrome地址"><a href="#下载老版本Chrome地址" class="headerlink" title="下载老版本Chrome地址"></a>下载老版本Chrome地址</h2><p><a href="https://www.slimjet.com/chrome/google-chrome-old-version.php" target="_blank" rel="noopener">下载old Chrome</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;现在发现很多同学部署mediasoup-demo时出现各种问题，最主要的原因是无法通过npm安装依赖包。几乎每天都有同学来问这类问题，解决的办法其实很简单，找个&lt;strong&gt;代理&lt;/strong&gt;就好了。&lt;/p&gt;
&lt;p&gt;但这又引来了同学们新的问题，哪种代理好？需要多少费用……&lt;/p&gt;
    
    </summary>
    
    
      <category term="WebRTC" scheme="https://blog.avdancedu.com/categories/WebRTC/"/>
    
      <category term="mediasoup" scheme="https://blog.avdancedu.com/categories/WebRTC/mediasoup/"/>
    
    
      <category term="WebRTC" scheme="https://blog.avdancedu.com/tags/WebRTC/"/>
    
      <category term="mediasoup" scheme="https://blog.avdancedu.com/tags/mediasoup/"/>
    
      <category term="docker" scheme="https://blog.avdancedu.com/tags/docker/"/>
    
  </entry>
  
</feed>
