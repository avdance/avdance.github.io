<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0"><link rel="icon" type="image/png" sizes="32x32" href="/images/avdance32_32.ico"><link rel="icon" type="image/png" sizes="16x16" href="/images/avdance16_16.ico"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css"><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"blog.avdancedu.com",root:"/",scheme:"Gemini",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!1,show_result:!1,style:null},back2top:{enable:!0,sidebar:!1,scrollpercent:!1},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!1,lazyload:!0,pangu:!1,comments:{style:"tabs",active:"valine",storage:!0,lazyload:!1,nav:null,activeClass:"valine"},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!1,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="这两天 Facebook AI Research (FAIR) 团队开发的一种新的图像分割模型，名为 Segment Anything。该模型使用了一种新的方法，可以在不需要大量标注数据的情况下，对图像中的任何物体进行分割。这种方法可以帮助计算机视觉领域的研究人员和开发人员更轻松地训练模型，从而提高计算机视觉应用程序的性能。"><meta property="og:type" content="article"><meta property="og:title" content="FaceBook最新的图像分割模型SegmentAnything到底有多厉害？"><meta property="og:url" content="https://blog.avdancedu.com/cd01af8d/index.html"><meta property="og:site_name" content="音视跳动科技"><meta property="og:description" content="这两天 Facebook AI Research (FAIR) 团队开发的一种新的图像分割模型，名为 Segment Anything。该模型使用了一种新的方法，可以在不需要大量标注数据的情况下，对图像中的任何物体进行分割。这种方法可以帮助计算机视觉领域的研究人员和开发人员更轻松地训练模型，从而提高计算机视觉应用程序的性能。"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2023-04-06T06:15:40.000Z"><meta property="article:modified_time" content="2023-04-12T02:07:28.106Z"><meta property="article:author" content="音视跳动"><meta property="article:tag" content="AI"><meta name="twitter:card" content="summary"><link rel="canonical" href="https://blog.avdancedu.com/cd01af8d/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>FaceBook最新的图像分割模型SegmentAnything到底有多厉害？ | 音视跳动科技</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><link rel="alternate" href="/atom.xml" title="音视跳动科技" type="application/atom+xml"></head><body itemscope itemtype="https://schema.org/WebPage"><div class="container"><div class="headband"></div><div id="needsharebutton-float"><span class="btn"><i class="fa fa-share-alt" aria-hidden="true"></i></span></div><header class="header" itemscope itemtype="https://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">音视跳动科技</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">传播最前沿的科技知识！</p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-home"></i> 首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i> 标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i> 分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i> 归档</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i> 关于</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i> 搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"> <input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span>0%</span></div> <a href="https://github.com/avdance" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115 130 115 142 142 250 250 250 0Z"></path><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4L133.7 101.6C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="https://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://blog.avdancedu.com/cd01af8d/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="image" content="/images/avdancelogo.jpg"><meta itemprop="name" content="音视跳动"><meta itemprop="description" content="传输最前沿的科技知识，学习音视频的圣地！ffmpeg, webrtc, H264, AAC"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="音视跳动科技"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"> FaceBook最新的图像分割模型SegmentAnything到底有多厉害？</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2023-04-06 14:15:40" itemprop="dateCreated datePublished" datetime="2023-04-06T14:15:40+08:00">2023-04-06</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2023-04-12 10:07:28" itemprop="dateModified" datetime="2023-04-12T10:07:28+08:00">2023-04-12</time></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a></span></span><span id="/cd01af8d/" class="post-meta-item leancloud_visitors" data-flag-title="FaceBook最新的图像分割模型SegmentAnything到底有多厉害？" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i></span> <span class="post-meta-item-text">阅读次数：</span><span class="leancloud-visitors-count"></span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-comment-o"></i></span> <span class="post-meta-item-text">Valine：</span><a title="valine" href="/cd01af8d/#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/cd01af8d/" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i></span> <span class="post-meta-item-text">本文字数：</span> <span>2.6k</span></span></div></header><div class="post-body" itemprop="articleBody"><p>这两天 Facebook AI Research (FAIR) 团队开发的一种新的图像分割模型，名为 <strong>Segment Anything</strong>。该模型使用了一种新的方法，可以在不需要大量标注数据的情况下，对图像中的任何物体进行分割。这种方法可以帮助计算机视觉领域的研究人员和开发人员更轻松地训练模型，从而提高计算机视觉应用程序的性能。</p><span id="more"></span><p>如果您想了解更多关于“Segment Anything”模型的信息，可以查看<a target="_blank" rel="noopener" href="https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/">这篇文章</a>。</p><h2 id="SegmentAnything是什么？"><a href="#SegmentAnything是什么？" class="headerlink" title="SegmentAnything是什么？"></a>SegmentAnything是什么？</h2><p><strong>Segment Anything</strong> 模型是一种新的图像分割模型，它可以在不需要大量标注数据的情况下，对图像中的任何物体进行分割。这种方法可以帮助计算机视觉领域的研究人员和开发人员更轻松地训练模型，从而提高计算机视觉应用程序的性能。</p><p><strong>Segment Anything</strong>模型使用了一种名为“自监督学习”的方法，该方法可以在不需要大量标注数据的情况下训练模型。该模型使用了一个名为“Contrastive Predictive Coding (CPC)”的算法，该算法可以从未标记的图像中学习到有用的特征，并将这些特征用于图像分割任务。</p><p><strong>Segment Anything</strong>模型可以用于许多应用场景，例如：</p><ul><li><p>自动驾驶汽车：自动驾驶汽车需要能够识别道路、车辆和行人等物体，并对它们进行分割。使用<strong>Segment Anything</strong>模型可以更准确地进行物体分割，从而提高自动驾驶汽车的性能。</p></li><li><p>医学图像分析：医学图像通常包含许多不同类型的组织和器官。使用<strong>Segment Anything</strong>模型可以更准确地对这些组织和器官进行分割，从而帮助医生更好地诊断疾病。</p></li><li><p>视频监控：视频监控系统需要能够识别和跟踪不同的对象，并对它们进行分割。使用<strong>Segment Anything</strong>模型可以更准确地进行对象分割，从而提高视频监控系统的性能。</p></li></ul><h2 id="与传统图像分割方法相比SegmentAnything模型的优势和不同？"><a href="#与传统图像分割方法相比SegmentAnything模型的优势和不同？" class="headerlink" title="与传统图像分割方法相比SegmentAnything模型的优势和不同？"></a>与传统图像分割方法相比SegmentAnything模型的优势和不同？</h2><p>与传统图像分割方法相比，<strong>Segment Anything</strong>模型的优势和不同之处主要有以下几点：</p><ul><li><p>不需要大量标注数据：传统的图像分割方法需要大量标注数据才能训练模型，而<strong>Segment Anything</strong>模型可以在不需要大量标注数据的情况下训练模型。</p></li><li><p>可以对任何物体进行分割：传统的图像分割方法通常只能对特定类型的物体进行分割，而<strong>Segment Anything</strong>模型可以对图像中的任何物体进行分割。</p></li><li><p>更准确：与传统的图像分割方法相比，<strong>Segment Anything</strong>模型可以更准确地对图像中的物体进行分割。</p></li><li><p>更快速：由于<strong>Segment Anything</strong>模型不需要大量标注数据，因此可以更快地训练模型。</p></li></ul><p>通过使用<strong>Segment Anything</strong>模型，计算机视觉领域的研究人员和开发人员可以更轻松地训练模型，并提高计算机视觉应用程序的性能。</p><h2 id="如何使用Segment-Anything模型-？"><a href="#如何使用Segment-Anything模型-？" class="headerlink" title="如何使用Segment Anything模型 ？"></a>如何使用Segment Anything模型 ？</h2><p><strong>Segment Anything</strong>可以一键分割和屏蔽任何照片或视频中的任何对象，包括训练期间没有看到的对象和图像类型。同时还发布了配套的数据集，比现有的数据集大400倍。它从输入提示中产生高质量的物体遮罩，用来为图像中的所有物体产生遮罩。它已经在一个由1100万张图像和11亿个遮罩组成的数据集上进行了训练，并在各种分割任务中具有强大的性能。</p><p>如果您想使用Segment Anything模型进行图像分割，可以使用Facebook提供的Segment Anything库。该库是一个PyTorch库，提供了许多预训练模型，包括Segment Anything模型。您可以使用这些预训练模型来进行图像分割，并将其集成到计算机视觉应用程序中。</p><p>这里有个示例代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> BytesIO</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the model</span></span><br><span class="line">model = torch.hub.load(<span class="string">&quot;facebookresearch/detectron2&quot;</span>,<span class="string">&quot;mask_rcnn_R_50_FPN_3&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Download the image from URL</span></span><br><span class="line">url = <span class="string">&quot;https://images.unsplash.com/photo-1521747116042-5a810fda9664&quot;</span></span><br><span class="line">response = requests.get(url)</span><br><span class="line">img = Image.<span class="built_in">open</span>(BytesIO(response.content))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run the model on the image</span></span><br><span class="line">outputs = model(img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Visualize the results</span></span><br><span class="line">v = Visualizer(img[:, :, ::-<span class="number">1</span>], MetadataCatalog.get(model.cfg.DATASETS.TRAIN[<span class="number">0</span>]), scale=<span class="number">1.2</span>)</span><br><span class="line">out = v.draw_instance_predictions(outputs[&amp;quot;instances&amp;quot;].to(&amp;quot;cpu&amp;quot;))</span><br><span class="line">Image.fromarray(out.get_image()[:, :, ::-<span class="number">1</span>])</span><br></pre></td></tr></table></figure><p>这段代码将从URL下载一张图片，然后使用Facebook提供的预训练模型进行图像分割。最后，它将显示分割结果。</p><h2 id="Segment-Anything模型未来发展方向"><a href="#Segment-Anything模型未来发展方向" class="headerlink" title="Segment Anything模型未来发展方向"></a>Segment Anything模型未来发展方向</h2><p>Segment Anything模型的未来发展方向和应用场景是非常广泛的。该模型可以用于许多计算机视觉应用程序，例如自动驾驶汽车、智能家居、安全监控、医疗图像分析等。此外，该模型还可以用于图像编辑和视频编辑，例如删除不需要的对象、更改背景等。这些应用程序将使我们的生活更加便利和安全。</p><p>Segment Anything模型的发布也可能会对计算机视觉行业产生重大影响。它可以帮助研究人员更好地理解图像分割问题，并提供一种新的方法来解决这个问题。此外，它还可以促进计算机视觉领域的进一步研究和发展</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>Segment Anything模型的出现是CV界的一个重要里程碑，为人们提供了一把利器，这会技术革命会大大加速社会的变革。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">graph TD;</span><br><span class="line">    A[用户输入文本] --&gt;B(数据预处理);</span><br><span class="line">    B --&gt; C(GPT模型计算);</span><br><span class="line">    C --&gt; D(结果处理);</span><br><span class="line">    D --&gt; E(输出回应);</span><br><span class="line">    E --&gt; F[用户界面]</span><br></pre></td></tr></table></figure></div><div class="reward-container"><div></div> <button onclick='var qr=document.getElementById("qr");qr.style.display="none"===qr.style.display?"block":"none"'> 打赏</button><div id="qr" style="display:none"><div style="display:inline-block"> <img src="https://cdn.avdancedu.com/image/next/wechat.jpeg" alt="音视跳动 微信支付"><p>微信支付</p></div><div style="display:inline-block"> <img src="https://cdn.avdancedu.com/image/next/alipay.jpeg" alt="音视跳动 支付宝"><p>支付宝</p></div></div></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> 音视跳动-李超 [avdance@163.com]</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="https://blog.avdancedu.com/cd01af8d/" title="FaceBook最新的图像分割模型SegmentAnything到底有多厉害？">https://blog.avdancedu.com/cd01af8d/</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class="followme"><p>欢迎关注我的其它发布渠道</p><div class="social-list"><div class="social-item"><a target="_blank" class="social-link" href="https://cdn.avdancedu.com/image/next/WeChat.jpeg"><span class="icon"><i class="fa fa-wechat"></i></span> <span class="label">WeChat</span></a></div><div class="social-item"><a target="_blank" class="social-link" href="/atom.xml"><span class="icon"><i class="fa fa-rss"></i></span> <span class="label">RSS</span></a></div></div></div><footer class="post-footer"><div class="post-tags"><a href="/tags/AI/" rel="tag"><i class="fa fa-tag"></i> AI</a></div><div class="post-nav"><div class="post-nav-item"><a href="/eaff035c/" rel="prev" title="使用Mac系统下的GPU搭建机器学习环境"><i class="fa fa-chevron-left"></i> 使用Mac系统下的GPU搭建机器学习环境</a></div><div class="post-nav-item"> <a href="/379d38e0/" rel="next" title="如何打造自己的专属GPT">如何打造自己的专属GPT<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="valine-comments"></div><script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span><span class="toggle-line toggle-line-middle"></span><span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc"> 文章目录</li><li class="sidebar-nav-overview"> 站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#SegmentAnything%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">1.</span> <span class="nav-text">SegmentAnything是什么？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%8E%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E6%96%B9%E6%B3%95%E7%9B%B8%E6%AF%94SegmentAnything%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BC%98%E5%8A%BF%E5%92%8C%E4%B8%8D%E5%90%8C%EF%BC%9F"><span class="nav-number">2.</span> <span class="nav-text">与传统图像分割方法相比SegmentAnything模型的优势和不同？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Segment-Anything%E6%A8%A1%E5%9E%8B-%EF%BC%9F"><span class="nav-number">3.</span> <span class="nav-text">如何使用Segment Anything模型 ？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Segment-Anything%E6%A8%A1%E5%9E%8B%E6%9C%AA%E6%9D%A5%E5%8F%91%E5%B1%95%E6%96%B9%E5%90%91"><span class="nav-number">4.</span> <span class="nav-text">Segment Anything模型未来发展方向</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B0%8F%E7%BB%93"><span class="nav-number">5.</span> <span class="nav-text">小结</span></a></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="https://schema.org/Person"> <img class="site-author-image" itemprop="image" alt="音视跳动" src="/images/avdancelogo.jpg"><p class="site-author-name" itemprop="name">音视跳动</p><div class="site-description" itemprop="description">传输最前沿的科技知识，学习音视频的圣地！ffmpeg, webrtc, H264, AAC</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">67</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">26</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">44</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/avdance" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;avdance" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i> GitHub</a></span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/garrylea/posts" title="ZhiHu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;garrylea&#x2F;posts" rel="noopener" target="_blank"><i class="fa fa-fw fa-zhihu"></i> ZhiHu</a></span></div></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="beian"><a href="https://www.beian.miit.gov.cn/" rel="noopener" target="_blank">京ICP备19056322号-1</a> <img src="/images/beianico.png" style="display:inline-block"><a href="https://www.beian.gov.cn/portal/registerSystemInfo?recordcode=11011102001366" rel="noopener" target="_blank">京公网安备11011102001366号</a></div><div class="copyright"> &copy; <span itemprop="copyrightYear">2023</span><span class="with-love"><i class="fa fa-user"></i></span> <span class="author" itemprop="copyrightHolder">李超</span> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-area-chart"></i></span> <span title="站点总字数">271k</span></div><script>
  (function() {
    function leancloudSelector(url) {
      url = encodeURI(url);
      return document.getElementById(url).querySelector('.leancloud-visitors-count');
    }

    function addCount(Counter) {
      var visitors = document.querySelector('.leancloud_visitors');
      var url = decodeURI(visitors.id);
      var title = visitors.dataset.flagTitle;

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url })))
        .then(response => response.json())
        .then(({ results }) => {
          if (results.length > 0) {
            var counter = results[0];
            leancloudSelector(url).innerText = counter.time + 1;
            Counter('put', '/classes/Counter/' + counter.objectId, { time: { '__op': 'Increment', 'amount': 1 } })
              .catch(error => {
                console.error('Failed to save visitor count', error);
              });
          } else {
              Counter('post', '/classes/Counter', { title, url, time: 1 })
                .then(response => response.json())
                .then(() => {
                  leancloudSelector(url).innerText = 1;
                })
                .catch(error => {
                  console.error('Failed to create', error);
                });
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    function showTime(Counter) {
      var visitors = document.querySelectorAll('.leancloud_visitors');
      var entries = [...visitors].map(element => {
        return decodeURI(element.id);
      });

      Counter('get', '/classes/Counter?where=' + encodeURIComponent(JSON.stringify({ url: { '$in': entries } })))
        .then(response => response.json())
        .then(({ results }) => {
          for (let url of entries) {
            let target = results.find(item => item.url === url);
            leancloudSelector(url).innerText = target ? target.time : 0;
          }
        })
        .catch(error => {
          console.error('LeanCloud Counter Error', error);
        });
    }

    let { app_id, app_key, server_url } = {"enable":true,"app_id":"Cu6h7B3RnNt3uEMrRWpVlIU6-gzGzoHsz","app_key":"5dKv9XFD2w3gjJnb0xnWIIWz","server_url":"https://leancloud.cn","security":false};
    function fetchData(api_server) {
      var Counter = (method, url, data) => {
        return fetch(`${api_server}/1.1${url}`, {
          method,
          headers: {
            'X-LC-Id'     : app_id,
            'X-LC-Key'    : app_key,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(data)
        });
      };
      if (CONFIG.page.isPost) {
        //if (CONFIG.hostname !== location.hostname) return;
        addCount(Counter);
      } else if (document.querySelectorAll('.post-title-link').length >= 1) {
        showTime(Counter);
      }
    }

    let api_server = app_id.slice(-9) !== '-MdYXbMMI' ? server_url : `https://${app_id.slice(0, 8).toLowerCase()}.api.lncldglobal.com`;

    if (api_server) {
      fetchData(api_server);
    } else {
      fetch('https://app-router.leancloud.cn/2/route?appId=' + app_id)
        .then(response => response.json())
        .then(({ api_server }) => {
          fetchData('https://' + api_server);
        });
    }
  })();
</script></div></footer></div><script src="/lib/anime.min.js"></script><script src="/lib/lozad.min.js"></script><script src="/js/utils.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script><script>AV.initialize("Cu6h7B3RnNt3uEMrRWpVlIU6-gzGzoHsz","5dKv9XFD2w3gjJnb0xnWIIWz")</script><script>function showTime(e){var t=new AV.Query(e),c=[],u=$(".leancloud_visitors");u.each(function(){c.push($(this).attr("id").trim())}),t.containedIn("url",c),t.find().done(function(e){var t=".leancloud-visitors-count";if(0!==e.length){for(var n=0;n<e.length;n++){var o=e[n],i=o.get("url"),s=o.get("time"),r=document.getElementById(i);$(r).find(t).text(s)}for(n=0;n<c.length;n++){i=c[n],r=document.getElementById(i);var l=$(r).find(t);""==l.text()&&l.text(0)}}else u.find(t).text(0)}).fail(function(e,t){console.log("Error: "+t.code+" "+t.message)})}function addCount(i){var e=$(".leancloud_visitors"),s=e.attr("id").trim(),r=e.attr("data-flag-title").trim(),t=new AV.Query(i);t.equalTo("url",s),t.find({success:function(e){if(0<e.length){var t=e[0];t.fetchWhenSave(!0),t.increment("time"),t.save(null,{success:function(e){$(document.getElementById(s)).find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to save Visitor num, with error message: "+t.message)}})}else{var n=new i,o=new AV.ACL;o.setPublicReadAccess(!0),o.setPublicWriteAccess(!0),n.setACL(o),n.set("title",r),n.set("url",s),n.set("time",1),n.save(null,{success:function(e){$(document.getElementById(s)).find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to create")}})}},error:function(e){console.log("Error:"+e.code+" "+e.message)}})}$(function(){var e=AV.Object.extend("Counter");1==$(".leancloud_visitors").length?addCount(e):1<$(".post-title-link").length&&showTime(e)})</script><link rel="stylesheet" href="/lib/needsharebutton/needsharebutton.min.css"><script src="/lib/needsharebutton/needsharebutton.min.js"></script><script>flOptions={iconStyle:"box",boxForm:"horizontal",position:"topRight",networks:"Weibo,Wechat,QQZone"},new needShareButton("#needsharebutton-float",flOptions)</script><script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('/lib/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'Cu6h7B3RnNt3uEMrRWpVlIU6-gzGzoHsz',
      appKey     : '5dKv9XFD2w3gjJnb0xnWIIWz',
      placeholder: "畅所欲言？",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script></body></html>